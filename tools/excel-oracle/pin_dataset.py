#!/usr/bin/env python3
"""
Pin an Excel oracle dataset for CI.

Typical flow on a Windows machine with Excel installed:

1) Generate oracle data:
   powershell -ExecutionPolicy Bypass -File tools/excel-oracle/run-excel-oracle.ps1 `
     -CasesPath tests/compatibility/excel-oracle/cases.json `
     -OutPath  tests/compatibility/excel-oracle/datasets/excel-oracle.json

2) Pin it (optionally versioned):
   python tools/excel-oracle/pin_dataset.py \
     --dataset tests/compatibility/excel-oracle/datasets/excel-oracle.json \
     --pinned tests/compatibility/excel-oracle/datasets/excel-oracle.pinned.json \
     --versioned-dir tests/compatibility/excel-oracle/datasets/versioned

The pinned dataset can be committed, allowing CI to validate engine behavior
even on Windows runners without Excel installed.
"""

from __future__ import annotations

import argparse
import json
import re
import shutil
import urllib.parse
from pathlib import Path
from typing import Any


_SYNTHETIC_BASELINE_NOTE = (
    "Synthetic CI baseline (not generated by Excel). Generated from crates/formula-excel-oracle "
    "(formula-engine) for the full corpus. Regenerate with tools/excel-oracle/run-excel-oracle.ps1 "
    "on Windows + Excel and pin via tools/excel-oracle/pin_dataset.py. For incremental parity work "
    "(e.g. patching only odd-coupon bond edge cases), prefer overwriting specific case IDs in the "
    "pinned dataset via tools/excel-oracle/patch-pinned-dataset-with-excel.ps1."
)


def _load_json(path: Path) -> Any:
    with path.open("r", encoding="utf-8") as f:
        return json.load(f)


def _sanitize_fragment(text: str) -> str:
    # Keep filenames portable and reasonably readable.
    safe = re.sub(r"[^A-Za-z0-9_.-]+", "_", text.strip())
    safe = re.sub(r"_+", "_", safe).strip("_")
    return safe or "unknown"


def _stable_case_set_path_string(*, repo_root: Path, raw: object) -> str | None:
    """Return a portable, privacy-safe caseSet.path string.

    The Excel-oracle tools often get invoked via wrapper scripts that pass absolute paths (including
    Windows paths like `C:\\Users\\Alice\\repo\\tests\\...`). If pinned datasets (or patch metadata)
    are committed, those machine-specific paths should never land in git.

    Prefer a repo-relative suffix when possible; otherwise fall back to the basename.
    """

    if raw is None:
        return None
    raw_str = str(raw).strip()
    if not raw_str:
        return None

    normalized = raw_str.replace("\\", "/")
    parsed = urllib.parse.urlparse(normalized)
    is_uri_like = bool(parsed.scheme and ":" in normalized)

    def _extract_repo_relative_suffix(path_str: str) -> str | None:
        lowered = path_str.casefold()
        for marker in ("/tests/", "/tools/", "/crates/", "/shared/"):
            idx = lowered.rfind(marker)
            if idx != -1:
                return path_str[idx + 1 :].lstrip("/")
        return None

    # Try the simple case first: current-platform absolute paths.
    try:
        p = Path(raw_str)
    except Exception:
        p = None

    if p is not None and p.is_absolute():
        try:
            rel = p.resolve().relative_to(repo_root.resolve())
            return rel.as_posix()
        except Exception:
            pass

    # Windows absolute paths (drive letter / UNC) can show up even when running this script on a
    # non-Windows machine (e.g. patching a pinned dataset on Linux using a results file generated
    # on a Windows Excel runner).
    suffix = _extract_repo_relative_suffix(normalized)
    if suffix:
        return suffix

    # Already-relative path: just normalize slashes.
    if not (
        normalized.startswith("/")
        or re.match(r"^[A-Za-z]:/", normalized)
        or normalized.startswith("//")
        or is_uri_like
    ):
        return normalized

    # Absolute path we can't map into the repo: keep only the basename.
    return Path(normalized).name


def _write_json(path: Path, payload: Any) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("w", encoding="utf-8", newline="\n") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2, sort_keys=False)
        f.write("\n")


def main() -> int:
    p = argparse.ArgumentParser()
    p.add_argument("--dataset", required=True, help="Path to generated oracle dataset JSON")
    p.add_argument(
        "--pinned",
        default="tests/compatibility/excel-oracle/datasets/excel-oracle.pinned.json",
        help="Where to copy the dataset for CI to consume (default: %(default)s)",
    )
    p.add_argument(
        "--versioned-dir",
        default="",
        help="If set, also write a version-tagged copy into this directory.",
    )
    p.add_argument(
        "--dry-run",
        action="store_true",
        help="Validate the dataset and print the destination paths without writing any files.",
    )
    args = p.parse_args()

    dataset_path = Path(args.dataset)
    pinned_path = Path(args.pinned)
    versioned_dir = Path(args.versioned_dir) if args.versioned_dir else None

    repo_root = Path(__file__).resolve().parents[2]

    payload = _load_json(dataset_path)
    source = payload.get("source", {})
    case_set = payload.get("caseSet", {})

    if not isinstance(source, dict):
        raise SystemExit("Dataset 'source' must be an object.")

    source_kind = source.get("kind")
    if source_kind == "excel":
        # `run-excel-oracle.ps1` always includes these properties from the Excel COM object.
        # Enforce that they're present so we don't accidentally pin a synthetic dataset that
        # simply sets `source.kind = \"excel\"`.
        for key in ("version", "build", "operatingSystem"):
            value = source.get(key)
            if not isinstance(value, str) or not value.strip() or value.strip().lower() == "unknown":
                raise SystemExit(
                    "Refusing to pin dataset missing Excel metadata. "
                    f"Expected source.{key} to be a non-empty string from real Excel; got {value!r}."
                )
    elif source_kind == "formula-engine":
        # CI environments typically cannot run real Excel, but we still want the hash/count plumbing
        # in `compare.py` to stay alive. Allow pinning an engine-generated dataset by re-tagging the
        # source metadata as a synthetic baseline.
        engine_source = dict(source)
        payload["source"] = {
            "kind": "excel",
            "version": "unknown",
            "build": "unknown",
            "operatingSystem": "unknown",
            "note": _SYNTHETIC_BASELINE_NOTE,
            "syntheticSource": engine_source,
        }
        source = payload["source"]
    else:
        raise SystemExit(
            "Refusing to pin dataset that does not come from real Excel. "
            "To pin the synthetic CI baseline, pass a dataset generated by "
            "`crates/formula-excel-oracle` (source.kind == 'formula-engine'). "
            f"source.kind={source_kind!r}"
        )

    # `run-excel-oracle.ps1` always includes these properties from the Excel COM object.
    # Enforce that they're present so we don't accidentally pin a synthetic dataset that
    # simply sets `source.kind = \"excel\"`.
    excel_version = _sanitize_fragment(str(source.get("version", "unknown")))
    excel_build = _sanitize_fragment(str(source.get("build", "unknown")))
    cases_sha = _sanitize_fragment(str(case_set.get("sha256", "unknown")))

    if isinstance(case_set, dict) and "path" in case_set:
        stable_path = _stable_case_set_path_string(repo_root=repo_root, raw=case_set.get("path"))
        if stable_path:
            case_set["path"] = stable_path

    versioned_name = f"excel-{excel_version}-build-{excel_build}-cases-{cases_sha[:8]}.json"
    versioned_path = (versioned_dir / versioned_name) if versioned_dir is not None else None

    if args.dry_run:
        print("Dry run: pin_dataset")
        print(f"dataset: {dataset_path.as_posix()}")
        print(f"pinned:  {pinned_path.as_posix()}")
        if versioned_path is not None:
            print(f"versioned: {versioned_path.as_posix()}")
        else:
            print("versioned: <skipped>")
        return 0

    _write_json(pinned_path, payload)
    print(f"Pinned dataset -> {pinned_path.as_posix()}")

    if versioned_dir is not None:
        versioned_dir.mkdir(parents=True, exist_ok=True)
        assert versioned_path is not None
        shutil.copyfile(pinned_path, versioned_path)
        print(f"Versioned copy -> {versioned_path.as_posix()}")

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
