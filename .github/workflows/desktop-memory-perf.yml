name: Desktop idle memory (history)

on:
  workflow_dispatch:
    inputs:
      memoryRuns:
        description: "Number of idle-memory iterations (default: 3)"
        required: false
        default: "3"
        type: string
      memoryTimeoutMs:
        description: "Per-memory-run timeout in milliseconds (default: 30000)"
        required: false
        default: "30000"
        type: string
      memorySettleMs:
        description: "Idle-memory settle delay after TTI in milliseconds (default: 5000)"
        required: false
        default: "5000"
        type: string
  schedule:
    # Daily (UTC). Keeps idle memory trends visible without gating PRs.
    - cron: "0 7 * * *"

permissions:
  contents: read

concurrency:
  # Avoid overlapping scheduled runs (desktop builds are expensive).
  group: desktop-memory-perf-${{ github.ref }}
  cancel-in-progress: false

env:
  # Keep Node pinned to the same major as CI/release workflows to reduce drift in scripts/build tooling.
  NODE_VERSION: 22
  # Keep in sync with release.yml/ci.yml so this workflow doesn't break when wasm-pack publishes
  # a new incompatible version.
  WASM_PACK_VERSION: 0.13.1
  # Opt-in: bundle Pyodide assets into `apps/desktop/dist` (otherwise Pyodide is downloaded
  # on-demand at runtime and cached in the app data directory).
  FORMULA_BUNDLE_PYODIDE_ASSETS: ${{ vars.FORMULA_BUNDLE_PYODIDE_ASSETS }}
  # This workflow is for tracking/visibility, not gating. Force enforcement off even if repo/organization
  # variables set these for other workflows.
  FORMULA_ENFORCE_DESKTOP_MEMORY_BENCH: "0"
  # Defaults for `workflow_dispatch` inputs. (Scheduled runs will always use these.)
  DESKTOP_MEMORY_RUNS: 3
  DESKTOP_MEMORY_TIMEOUT_MS: 30000
  DESKTOP_MEMORY_SETTLE_MS: 5000

jobs:
  measure:
    name: Desktop idle memory (Linux)
    # Avoid spending compute on scheduled runs in forks.
    if: github.event_name != 'schedule' || github.repository == 'wilson-anysphere/formula'
    runs-on: ubuntu-24.04
    timeout-minutes: 30

    steps:
      - name: Checkout
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v4

      - name: Setup pnpm
        uses: pnpm/action-setup@41ff72655975bd51cab0327fa583b6e92b6d3061 # v4
        with:
          # Pin pnpm patch version for deterministic builds (keep in sync with package.json).
          version: 9.0.0

      - name: Setup Node
        uses: actions/setup-node@6044e13b5dc448c55e2357c09f80417699197238 # v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: pnpm
          cache-dependency-path: pnpm-lock.yaml

      - name: Setup Rust toolchain (pinned + wasm32)
        uses: dtolnay/rust-toolchain@e97e2d8cc328f1b50210efc529dca0028893a2d9 # v1
        with:
          toolchain: 1.92.0
          targets: wasm32-unknown-unknown

      - name: Rust cache
        uses: Swatinem/rust-cache@779680da715d629ac1d338a641029a2f4372abb5 # v2

      # Our dev scripts default to a repo-local CARGO_HOME to avoid cross-agent contention on shared
      # ~/.cargo. In GitHub Actions we prefer the default CARGO_HOME so the shared cache action works.
      - name: Use shared Cargo home for CI caching
        run: echo "CARGO_HOME=$HOME/.cargo" >> "$GITHUB_ENV"

      - name: Install Linux dependencies (Tauri/WebView + Xvfb)
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libgtk-3-dev \
            libwebkit2gtk-4.1-dev \
            libayatana-appindicator3-dev \
            librsvg2-dev \
            libssl-dev \
            patchelf \
            xvfb

      - name: Install JS dependencies
        env:
          # This workflow does not run Playwright tests, so skip the ~GB browser downloads performed by
          # `@playwright/test`'s postinstall script.
          PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD: "1"
        # Prefer cached pnpm store entries to reduce network flakiness on reruns.
        run: pnpm install --frozen-lockfile --prefer-offline
 
      - name: Apply workflow_dispatch perf overrides
        if: github.event_name == 'workflow_dispatch'
        shell: bash
        env:
          INPUT_MEMORY_RUNS: ${{ github.event.inputs.memoryRuns }}
          INPUT_MEMORY_TIMEOUT_MS: ${{ github.event.inputs.memoryTimeoutMs }}
          INPUT_MEMORY_SETTLE_MS: ${{ github.event.inputs.memorySettleMs }}
        run: |
          set -euo pipefail
          
          trim() {
            local s="$1"
            # ltrim
            s="${s#"${s%%[![:space:]]*}"}"
            # rtrim
            s="${s%"${s##*[![:space:]]}"}"
            printf '%s' "$s"
          }
          
          write_int_override() {
            local env_key="$1"
            local input_name="$2"
            local raw="$3"
            local min="$4"
            local value
            value="$(trim "${raw}")"
            if [[ -z "$value" ]]; then
              return 0
            fi
            if ! [[ "$value" =~ ^[0-9]+$ ]]; then
              echo "::error::workflow_dispatch input '${input_name}' must be an integer (got: '${value}')" >&2
              exit 1
            fi
            if (( value < min )); then
              echo "::error::workflow_dispatch input '${input_name}' must be >= ${min} (got: '${value}')" >&2
              exit 1
            fi
            echo "${env_key}=${value}" >> "$GITHUB_ENV"
          }
          
          write_int_override "DESKTOP_MEMORY_RUNS" "memoryRuns" "$INPUT_MEMORY_RUNS" 1
          write_int_override "DESKTOP_MEMORY_TIMEOUT_MS" "memoryTimeoutMs" "$INPUT_MEMORY_TIMEOUT_MS" 1
          write_int_override "DESKTOP_MEMORY_SETTLE_MS" "memorySettleMs" "$INPUT_MEMORY_SETTLE_MS" 0

      - name: Cache wasm-pack binary
        id: wasm-pack-cache
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v4
        with:
          path: ~/.cargo/bin/wasm-pack
          key: wasm-pack-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-

      - name: Cache wasm-pack tool downloads (Linux)
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v4
        with:
          # wasm-pack downloads wasm-bindgen + binaryen (wasm-opt) into this cache dir.
          path: ~/.cache/.wasm-pack
          key: wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-

      - name: Install wasm-pack (required for @formula/engine WASM build)
        if: steps.wasm-pack-cache.outputs.cache-hit != 'true'
        # Use --force so cache restore-keys (or other CI caches) can't strand a stale/untracked
        # wasm-pack binary that would otherwise block `cargo install` from overwriting it.
        run: cargo install wasm-pack --version ${{ env.WASM_PACK_VERSION }} --locked --force

      - name: Verify wasm-pack version
        shell: bash
        run: |
          set -euo pipefail
          expected="${WASM_PACK_VERSION}"
          actual="$(wasm-pack --version | tr -d '\r' | awk '{print $2}')"
          if [[ "${actual}" != "${expected}" ]]; then
            echo "Expected wasm-pack ${expected}, but found ${actual}." >&2
            exit 1
          fi

      - name: Detect Pyodide version (for caching)
        id: pyodide
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1'
        shell: bash
        run: |
          set -euo pipefail
          version="$(node -e "const fs=require('node:fs'); const src=fs.readFileSync('apps/desktop/scripts/ensure-pyodide-assets.mjs','utf8'); const m=src.match(/const\\s+PYODIDE_VERSION\\s*=\\s*['\\\"]([^'\\\"]+)['\\\"]/); if(!m) throw new Error('PYODIDE_VERSION not found'); process.stdout.write(m[1]);")"
          echo "version=${version}" >> "$GITHUB_OUTPUT"

      - name: Restore Pyodide asset cache
        id: pyodide-cache
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1'
        uses: actions/cache/restore@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v4
        with:
          path: apps/desktop/public/pyodide/v${{ steps.pyodide.outputs.version }}/full/
          key: pyodide-${{ runner.os }}-${{ steps.pyodide.outputs.version }}-${{ hashFiles('apps/desktop/scripts/ensure-pyodide-assets.mjs') }}

      - name: Ensure Pyodide assets are present
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1'
        run: node apps/desktop/scripts/ensure-pyodide-assets.mjs

      - name: Save Pyodide asset cache
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1' && steps.pyodide-cache.outputs.cache-hit != 'true'
        uses: actions/cache/save@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v4
        with:
          path: apps/desktop/public/pyodide/v${{ steps.pyodide.outputs.version }}/full/
          key: pyodide-${{ runner.os }}-${{ steps.pyodide.outputs.version }}-${{ hashFiles('apps/desktop/scripts/ensure-pyodide-assets.mjs') }}

      - name: Build desktop frontend assets (Vite + WASM)
        run: pnpm build:desktop

      - name: Build desktop binary (release, desktop feature)
        shell: bash
        env:
          # `scripts/cargo_agent.sh` defaults `CARGO_PROFILE_RELEASE_CODEGEN_UNITS` based on its job count
          # for stability on multi-agent hosts. Override so this benchmark builds a binary matching the
          # repo's Cargo.toml release profile (codegen-units = 1), aligning perf data with shipped
          # release artifacts.
          CARGO_PROFILE_RELEASE_CODEGEN_UNITS: "1"
        run: |
          set -euo pipefail
          # The desktop shell crate was historically named `formula-desktop-tauri`;
          # it has since been renamed to `desktop` in some branches. Build whichever exists.
          pkg="desktop"
          if cargo metadata --no-deps --format-version=1 | grep -q '"name":"formula-desktop-tauri"'; then
            pkg="formula-desktop-tauri"
          fi
          bash scripts/cargo_agent.sh build \
            -p "${pkg}" \
            --features desktop \
            --bin formula-desktop \
            --release \
            --locked

      - name: Run idle memory benchmark
        id: memory
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p perf-artifacts
          node scripts/run-node-ts.mjs apps/desktop/tests/performance/desktop-memory-runner.ts \
            --runs "${DESKTOP_MEMORY_RUNS}" \
            --timeout-ms "${DESKTOP_MEMORY_TIMEOUT_MS}" \
            --settle-ms "${DESKTOP_MEMORY_SETTLE_MS}" \
            --json perf-artifacts/desktop-memory-metrics.json \
            --allow-ci 2>&1 | tee perf-artifacts/desktop-memory.log

      - name: Summarize + convert to benchmark-action format
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p perf-artifacts
          node - <<'NODE'
          const fs = require("node:fs");
          const path = require("node:path");
          
          const inputPath = path.resolve("perf-artifacts/desktop-memory-metrics.json");
          const outputPath = path.resolve("perf-artifacts/benchmark-results.desktop-memory.json");
          
          function fmt(n, digits = 1) {
            if (typeof n !== "number" || !Number.isFinite(n)) return "n/a";
            return n.toFixed(digits);
          }
          
          function appendSummary(lines) {
            const summaryPath = process.env.GITHUB_STEP_SUMMARY;
            if (!summaryPath) return;
            fs.appendFileSync(summaryPath, lines.join("\n") + "\n", "utf8");
          }
          
          if (!fs.existsSync(inputPath)) {
            const rel = path.relative(process.cwd(), inputPath);
            console.error(`[desktop-memory-perf] Missing ${rel}; memory runner likely failed before writing JSON.`);
            appendSummary([
              "## Desktop idle memory (Linux)",
              "",
              `:warning: Missing \`${rel}\` (runner failed before writing JSON).`,
              "",
            ]);
            process.exit(1);
          }
          
          let data;
          try {
            data = JSON.parse(fs.readFileSync(inputPath, "utf8"));
          } catch (err) {
            const rel = path.relative(process.cwd(), inputPath);
            console.error(
              `[desktop-memory-perf] Failed to parse ${rel}: ${err instanceof Error ? err.message : String(err)}`,
            );
            appendSummary([
              "## Desktop idle memory (Linux)",
              "",
              `:warning: Failed to parse \`${rel}\`: ${err instanceof Error ? err.message : String(err)}`,
              "",
            ]);
            process.exit(1);
          }
          
          const p50 = data?.summary?.rssMb?.p50;
          const p95 = data?.summary?.rssMb?.p95;
          const target = data?.summary?.rssMb?.targetMb ?? data?.targetMb;
          const runs = data?.summary?.runs ?? data?.runs;
          const measurement = data?.measurement ?? "rss";

          if (typeof p95 !== "number" || !Number.isFinite(p95)) {
            const rel = path.relative(process.cwd(), inputPath);
            console.error(`[desktop-memory-perf] Missing p95 RSS value in ${rel}; cannot publish benchmark history.`);
            appendSummary([
              "## Desktop idle memory (Linux)",
              "",
              `:warning: Missing p95 RSS value in \`${rel}\`; cannot publish benchmark history.`,
              "",
            ]);
            process.exit(1);
          }
          
          // Convert the runner summary into `benchmark-action` customSmallerIsBetter format.
          // Keep the metric names stable for historical tracking in gh-pages.
          const results = [
            {
              name: "desktop.memory.idle_rss_mb.p95",
              unit: "mb",
              value: p95,
            },
          ];
          if (typeof p50 === "number" && Number.isFinite(p50)) {
            results.push({
              name: "desktop.memory.idle_rss_mb.p50",
              unit: "mb",
              value: p50,
            });
          }
          fs.writeFileSync(outputPath, JSON.stringify(results, null, 2), "utf8");
          
          const numericTarget = typeof target === "number" && Number.isFinite(target) ? target : null;
          const status =
            numericTarget != null && typeof p95 === "number" && Number.isFinite(p95) ? (p95 <= numericTarget ? "PASS" : "FAIL") : "n/a";
          const delta =
            numericTarget != null && typeof p95 === "number" && Number.isFinite(p95) ? p95 - numericTarget : null;

          appendSummary([
            "## Desktop idle memory (Linux)",
            "",
            `Runs: \`${runs ?? "n/a"}\`  Measurement: \`${measurement}\`  Status: \`${status}\`${
              delta != null && Number.isFinite(delta) ? ` (Î”=${delta >= 0 ? "+" : ""}${delta.toFixed(1)}MB)` : ""
            }`,
            "",
            "| Metric | p50 (MB) | p95 (MB) | Target (MB) |",
            "|---|---:|---:|---:|",
            `| idle RSS | ${fmt(p50, 1)} | ${fmt(p95, 1)} | ${fmt(target, 0)} |`,
            "",
          ]);
          NODE

      - name: Upload desktop memory artifacts
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v4
        with:
          name: desktop-memory-perf
          if-no-files-found: warn
          path: |
            perf-artifacts/*.json
            perf-artifacts/*.log

  publish:
    name: Publish desktop memory history (gh-pages)
    needs: measure
    runs-on: ubuntu-24.04
    timeout-minutes: 10
    concurrency:
      # Avoid concurrent gh-pages pushes from multiple benchmark workflows (platform matrix, perf, etc).
      group: benchmark-gh-pages-publish
      cancel-in-progress: false
    permissions:
      actions: read
      contents: write
    # Only scheduled runs on main should update gh-pages history.
    # Publish whenever we have benchmark results for a scheduled run on main, even if the measure job failed,
    # so flaky runs can still contribute data for debugging when artifacts are present.
    if: always() && github.repository == 'wilson-anysphere/formula' && github.ref == 'refs/heads/main' && github.event_name == 'schedule'
    steps:
      - name: Checkout
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v4

      - name: Download desktop memory artifacts
        continue-on-error: true
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v4
        with:
          name: desktop-memory-perf
          path: artifacts/desktop-memory-perf

      - name: Check benchmark results (skip publish when empty)
        id: bench
        shell: bash
        run: |
          set -euo pipefail
          path="artifacts/desktop-memory-perf/perf-artifacts/benchmark-results.desktop-memory.json"
          if [ ! -f "$path" ]; then
            echo "::notice::Missing ${path}; skipping gh-pages publish."
            echo "publish=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          if ! count="$(node -e 'const fs=require(\"fs\");const p=process.argv[1];const v=JSON.parse(fs.readFileSync(p,\"utf8\"));console.log(Array.isArray(v)?v.length:0);' "$path")"; then
            echo "::notice::Failed to parse ${path}; skipping gh-pages publish."
            echo "publish=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          if ! [[ "$count" =~ ^[0-9]+$ ]] || [ "$count" -lt 1 ]; then
            echo "::notice::Benchmark results file is empty; skipping gh-pages publish."
            echo "publish=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          echo "publish=true" >> "$GITHUB_OUTPUT"

      - name: Publish benchmark results (non-gating)
        if: steps.bench.outputs.publish == 'true'
        continue-on-error: true
        uses: benchmark-action/github-action-benchmark@4bdcce38c94cec68da58d012ac24b7b1155efe8b # v1
        with:
          tool: customSmallerIsBetter
          output-file-path: artifacts/desktop-memory-perf/perf-artifacts/benchmark-results.desktop-memory.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          alert-threshold: '120%'
          comment-on-alert: false
          fail-on-alert: false
