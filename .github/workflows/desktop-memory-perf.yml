name: Desktop idle memory (history)

on:
  workflow_dispatch:
  schedule:
    # Daily (UTC). Keeps idle memory trends visible without gating PRs.
    - cron: "0 7 * * *"

permissions:
  contents: read

concurrency:
  # Avoid overlapping scheduled runs (desktop builds are expensive).
  group: desktop-memory-perf-${{ github.ref }}
  cancel-in-progress: false

env:
  # Keep Node pinned to the same major as CI/release workflows to reduce drift in scripts/build tooling.
  NODE_VERSION: 22
  # Keep in sync with release.yml/ci.yml so this workflow doesn't break when wasm-pack publishes
  # a new incompatible version.
  WASM_PACK_VERSION: 0.13.1
  # This workflow is for tracking/visibility, not gating. Force enforcement off even if repo/organization
  # variables set these for other workflows.
  FORMULA_ENFORCE_DESKTOP_MEMORY_BENCH: "0"

jobs:
  measure:
    name: Desktop idle memory (Linux)
    # Avoid spending compute on scheduled runs in forks.
    if: github.event_name != 'schedule' || github.repository == 'wilson-anysphere/formula'
    runs-on: ubuntu-24.04
    timeout-minutes: 30

    steps:
      - name: Checkout
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Setup pnpm
        uses: pnpm/action-setup@41ff72655975bd51cab0327fa583b6e92b6d3061 # v4
        with:
          # Pin pnpm patch version for deterministic builds (keep in sync with package.json).
          version: 9.0.0

      - name: Setup Node
        uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: pnpm
          cache-dependency-path: pnpm-lock.yaml

      - name: Setup Rust toolchain (pinned + wasm32)
        uses: dtolnay/rust-toolchain@e97e2d8cc328f1b50210efc529dca0028893a2d9 # v1
        with:
          toolchain: 1.92.0
          targets: wasm32-unknown-unknown

      - name: Rust cache
        uses: Swatinem/rust-cache@779680da715d629ac1d338a641029a2f4372abb5 # v2

      # Our dev scripts default to a repo-local CARGO_HOME to avoid cross-agent contention on shared
      # ~/.cargo. In GitHub Actions we prefer the default CARGO_HOME so the shared cache action works.
      - name: Use shared Cargo home for CI caching
        run: echo "CARGO_HOME=$HOME/.cargo" >> "$GITHUB_ENV"

      - name: Install Linux dependencies (Tauri/WebView + Xvfb)
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libgtk-3-dev \
            libwebkit2gtk-4.1-dev \
            libayatana-appindicator3-dev \
            librsvg2-dev \
            libssl-dev \
            patchelf \
            xvfb

      - name: Install JS dependencies
        env:
          # This workflow does not run Playwright tests, so skip the ~GB browser downloads performed by
          # `@playwright/test`'s postinstall script.
          PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD: "1"
        # Prefer cached pnpm store entries to reduce network flakiness on reruns.
        run: pnpm install --frozen-lockfile --prefer-offline

      - name: Cache wasm-pack binary
        id: wasm-pack-cache
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: ~/.cargo/bin/wasm-pack
          key: wasm-pack-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-

      - name: Cache wasm-pack tool downloads (Linux)
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          # wasm-pack downloads wasm-bindgen + binaryen (wasm-opt) into this cache dir.
          path: ~/.cache/.wasm-pack
          key: wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-

      - name: Install wasm-pack (required for @formula/engine WASM build)
        if: steps.wasm-pack-cache.outputs.cache-hit != 'true'
        # Use --force so cache restore-keys (or other CI caches) can't strand a stale/untracked
        # wasm-pack binary that would otherwise block `cargo install` from overwriting it.
        run: cargo install wasm-pack --version ${{ env.WASM_PACK_VERSION }} --locked --force

      - name: Verify wasm-pack version
        shell: bash
        run: |
          set -euo pipefail
          expected="${WASM_PACK_VERSION}"
          actual="$(wasm-pack --version | tr -d '\r' | awk '{print $2}')"
          if [[ "${actual}" != "${expected}" ]]; then
            echo "Expected wasm-pack ${expected}, but found ${actual}." >&2
            exit 1
          fi

      - name: Detect Pyodide version (for caching)
        id: pyodide
        shell: bash
        run: |
          set -euo pipefail
          version="$(node -p 'const fs=require("fs");const src=fs.readFileSync("apps/desktop/scripts/ensure-pyodide-assets.mjs","utf8");const m=src.match(/const\s+PYODIDE_VERSION\s*=\s*[\"\x27]([^\"\x27]+)[\"\x27]/);if(!m){throw new Error("PYODIDE_VERSION not found in ensure-pyodide-assets.mjs");}m[1];')"
          echo "version=$version" >> "$GITHUB_OUTPUT"

      - name: Restore Pyodide asset cache
        id: pyodide-cache
        uses: actions/cache/restore@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: apps/desktop/public/pyodide/v${{ steps.pyodide.outputs.version }}/full/
          key: pyodide-${{ runner.os }}-${{ steps.pyodide.outputs.version }}-${{ hashFiles('apps/desktop/scripts/ensure-pyodide-assets.mjs') }}

      - name: Ensure Pyodide assets are present (populate cache on miss)
        shell: bash
        run: node apps/desktop/scripts/ensure-pyodide-assets.mjs

      - name: Save Pyodide asset cache
        if: steps.pyodide-cache.outputs.cache-hit != 'true'
        # Cache saves can race with other workflows (CI/perf/etc.) when the Pyodide version or ensure
        # script hash changes. Cache save conflicts are expected; don't fail this run.
        continue-on-error: true
        uses: actions/cache/save@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: apps/desktop/public/pyodide/v${{ steps.pyodide.outputs.version }}/full/
          key: pyodide-${{ runner.os }}-${{ steps.pyodide.outputs.version }}-${{ hashFiles('apps/desktop/scripts/ensure-pyodide-assets.mjs') }}

      - name: Build desktop frontend assets (Vite + WASM)
        run: pnpm build:desktop

      - name: Build desktop binary (release, desktop feature)
        shell: bash
        env:
          # `scripts/cargo_agent.sh` defaults `CARGO_PROFILE_RELEASE_CODEGEN_UNITS` based on its job count
          # for stability on multi-agent hosts. Override so this benchmark builds a binary matching the
          # repo's Cargo.toml release profile (codegen-units = 1), aligning perf data with shipped
          # release artifacts.
          CARGO_PROFILE_RELEASE_CODEGEN_UNITS: "1"
        run: |
          set -euo pipefail
          # The desktop shell crate was historically named `formula-desktop-tauri`;
          # it has since been renamed to `desktop` in some branches. Build whichever exists.
          pkg="desktop"
          if cargo metadata --no-deps --format-version=1 | grep -q '"name":"formula-desktop-tauri"'; then
            pkg="formula-desktop-tauri"
          fi
          bash scripts/cargo_agent.sh build \
            -p "${pkg}" \
            --features desktop \
            --bin formula-desktop \
            --release \
            --locked

      - name: Run idle memory benchmark (3 runs)
        id: memory
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p perf-artifacts
          node scripts/run-node-ts.mjs apps/desktop/tests/performance/desktop-memory-runner.ts \
            --runs 3 \
            --timeout-ms 30000 \
            --settle-ms 5000 \
            --json perf-artifacts/desktop-memory-metrics.json \
            --allow-ci 2>&1 | tee perf-artifacts/desktop-memory.log

      - name: Summarize + convert to benchmark-action format
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p perf-artifacts
          node - <<'NODE'
          const fs = require("node:fs");
          const path = require("node:path");
          
          const inputPath = path.resolve("perf-artifacts/desktop-memory-metrics.json");
          const outputPath = path.resolve("perf-artifacts/benchmark-results.desktop-memory.json");
          
          function fmt(n, digits = 1) {
            if (typeof n !== "number" || !Number.isFinite(n)) return "n/a";
            return n.toFixed(digits);
          }
          
          function appendSummary(lines) {
            const summaryPath = process.env.GITHUB_STEP_SUMMARY;
            if (!summaryPath) return;
            fs.appendFileSync(summaryPath, lines.join("\n") + "\n", "utf8");
          }
          
          if (!fs.existsSync(inputPath)) {
            const rel = path.relative(process.cwd(), inputPath);
            console.error(`[desktop-memory-perf] Missing ${rel}; memory runner likely failed before writing JSON.`);
            appendSummary([
              "## Desktop idle memory (Linux)",
              "",
              `:warning: Missing \`${rel}\` (runner failed before writing JSON).`,
              "",
            ]);
            process.exit(1);
          }
          
          let data;
          try {
            data = JSON.parse(fs.readFileSync(inputPath, "utf8"));
          } catch (err) {
            const rel = path.relative(process.cwd(), inputPath);
            console.error(
              `[desktop-memory-perf] Failed to parse ${rel}: ${err instanceof Error ? err.message : String(err)}`,
            );
            appendSummary([
              "## Desktop idle memory (Linux)",
              "",
              `:warning: Failed to parse \`${rel}\`: ${err instanceof Error ? err.message : String(err)}`,
              "",
            ]);
            process.exit(1);
          }
          
          const p50 = data?.summary?.rssMb?.p50;
          const p95 = data?.summary?.rssMb?.p95;
          const target = data?.summary?.rssMb?.targetMb ?? data?.targetMb;
          const runs = data?.summary?.runs ?? data?.runs;
          const measurement = data?.measurement ?? "rss";

          if (typeof p95 !== "number" || !Number.isFinite(p95)) {
            const rel = path.relative(process.cwd(), inputPath);
            console.error(`[desktop-memory-perf] Missing p95 RSS value in ${rel}; cannot publish benchmark history.`);
            appendSummary([
              "## Desktop idle memory (Linux)",
              "",
              `:warning: Missing p95 RSS value in \`${rel}\`; cannot publish benchmark history.`,
              "",
            ]);
            process.exit(1);
          }
          
          // Convert the runner summary into `benchmark-action` customSmallerIsBetter format.
          // Keep the metric names stable for historical tracking in gh-pages.
          const results = [
            {
              name: "desktop.memory.idle_rss_mb.p95",
              unit: "mb",
              value: p95,
            },
          ];
          if (typeof p50 === "number" && Number.isFinite(p50)) {
            results.push({
              name: "desktop.memory.idle_rss_mb.p50",
              unit: "mb",
              value: p50,
            });
          }
          fs.writeFileSync(outputPath, JSON.stringify(results, null, 2), "utf8");
          
          const numericTarget = typeof target === "number" && Number.isFinite(target) ? target : null;
          const status =
            numericTarget != null && typeof p95 === "number" && Number.isFinite(p95) ? (p95 <= numericTarget ? "PASS" : "FAIL") : "n/a";
          const delta =
            numericTarget != null && typeof p95 === "number" && Number.isFinite(p95) ? p95 - numericTarget : null;

          appendSummary([
            "## Desktop idle memory (Linux)",
            "",
            `Runs: \`${runs ?? "n/a"}\`  Measurement: \`${measurement}\`  Status: \`${status}\`${
              delta != null && Number.isFinite(delta) ? ` (Î”=${delta >= 0 ? "+" : ""}${delta.toFixed(1)}MB)` : ""
            }`,
            "",
            "| Metric | p50 (MB) | p95 (MB) | Target (MB) |",
            "|---|---:|---:|---:|",
            `| idle RSS | ${fmt(p50, 1)} | ${fmt(p95, 1)} | ${fmt(target, 0)} |`,
            "",
          ]);
          NODE

      - name: Upload desktop memory artifacts
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: desktop-memory-perf
          if-no-files-found: warn
          path: |
            perf-artifacts/*.json
            perf-artifacts/*.log

  publish:
    name: Publish desktop memory history (gh-pages)
    needs: measure
    runs-on: ubuntu-24.04
    timeout-minutes: 10
    concurrency:
      # Avoid concurrent gh-pages pushes from multiple benchmark workflows (platform matrix, perf, etc).
      group: benchmark-gh-pages-publish
      cancel-in-progress: false
    permissions:
      actions: read
      contents: write
    # Only scheduled runs on main should update gh-pages history.
    if: github.repository == 'wilson-anysphere/formula' && github.ref == 'refs/heads/main' && github.event_name == 'schedule' && needs.measure.result == 'success'
    steps:
      - name: Checkout
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Download desktop memory artifacts
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4
        with:
          name: desktop-memory-perf
          path: artifacts/desktop-memory-perf

      - name: Publish benchmark results (non-gating)
        continue-on-error: true
        uses: benchmark-action/github-action-benchmark@4bdcce38c94cec68da58d012ac24b7b1155efe8b # v1
        with:
          tool: customSmallerIsBetter
          output-file-path: artifacts/desktop-memory-perf/perf-artifacts/benchmark-results.desktop-memory.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          alert-threshold: '120%'
          comment-on-alert: false
          fail-on-alert: false
