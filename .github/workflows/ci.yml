name: CI

on:
  push:
    branches: [main]
  pull_request:

env:
  # Pin CI Node.js major (keep in sync with release.yml) to reduce drift between
  # what CI tests and what tagged releases build.
  NODE_VERSION: 22
  # Keep in sync with release.yml so CI catches WASM toolchain issues early.
  WASM_PACK_VERSION: 0.13.1
  # Keep in sync with the `tauri` dependency pinned in Cargo.lock (and the pinned
  # TAURI_CLI_VERSION in release.yml) so CI catches toolchain drift early.
  TAURI_CLI_VERSION: 2.9.5
  # Opt-in: bundle Pyodide assets into `apps/desktop/dist` (otherwise Pyodide is downloaded
  # on-demand at runtime and cached in the app data directory).
  FORMULA_BUNDLE_PYODIDE_ASSETS: ${{ vars.FORMULA_BUNDLE_PYODIDE_ASSETS }}

jobs:
  conflict-marker-guard:
    name: "Guard: no merge conflict markers"
    # Pin runner image versions for reproducibility. GitHub's `ubuntu-latest` alias
    # moves over time, which can introduce unexpected breakages even in lightweight
    # guard jobs. Update deliberately after validating newer runner images:
    # https://github.com/actions/runner-images
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4
      - name: Fail if merge conflict markers are present
        run: bash scripts/ci/check-merge-conflict-markers.sh
      - name: "Guard: TOML files parse cleanly"
        run: python3 scripts/ci/check-toml-validity.py
      - name: "Guard: workflow actions are pinned to commit SHAs"
        run: bash scripts/ci/check-gha-action-sha-pins.sh .github/workflows
      - name: "Guard: Rust toolchain pins match rust-toolchain.toml"
        run: bash scripts/ci/check-rust-toolchain-pins.sh
      - name: "Guard: workflows avoid moving *-latest runner labels"
        run: bash scripts/ci/check-gha-runner-pins.sh .github/workflows
      - name: "Guard: workflow name fields with ':' must be quoted"
        run: bash scripts/ci/check-workflow-step-name-colons.sh
      - name: "Guard: Node version pins match release workflow"
        run: bash scripts/ci/check-node-version-pins.sh
      - name: "Guard: pnpm version pins match package.json + release workflow"
        run: bash scripts/ci/check-pnpm-version-pins.sh
      - name: "Guard: wasm-pack pins match release workflow"
        run: bash scripts/ci/check-wasm-pack-version-pins.sh
      - name: "Guard: Tauri CLI pins match release workflow"
        run: bash scripts/ci/check-tauri-cli-version-pins.sh
      - name: "Guard: benchmark gh-pages publishes are serialized"
        run: bash scripts/ci/check-benchmark-gh-pages-concurrency.sh .github/workflows
      - name: "Guard: desktop installer artifact size reporter JSON output"
        run: python3 -m unittest scripts/test_desktop_bundle_size_report_json.py
      - name: "Guard: lightweight desktop size reporter JSON output"
        run: python3 -m unittest scripts/test_desktop_size_report_json.py
      - name: "Guard: desktop binary size reporter JSON output"
        run: python3 -m unittest scripts/test_desktop_binary_size_report_json.py

  release-manifest-tests:
    name: Desktop release manifest scripts (node:test)
    needs: conflict-marker-guard
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4
      - name: Setup Node
        uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4
        with:
          node-version: ${{ env.NODE_VERSION }}
      - name: "Guard: locale function sources are normalized"
        run: node scripts/normalize-locale-function-sources.js --check
      - name: "Guard: locale function TSVs are up to date"
        # Force deterministic header date so this guard can't fail due to environment drift.
        run: SOURCE_DATE_EPOCH=0 node scripts/generate-locale-function-tsv.js --check
      - name: "Guard: locale error TSVs are up to date"
        run: node scripts/generate-locale-error-tsvs.mjs --check
      - name: Run manifest unit tests (fast, dependency-free)
        run: node --test scripts/__tests__/release-manifest.test.mjs
      - name: Desktop URL scheme + file association preflight (tauri.conf.json/Info.plist)
        run: node scripts/check-desktop-url-scheme.mjs
      - name: Run desktop bundle validator unit tests (fast, dependency-free)
        run: |
          node --test \
            scripts/check-desktop-url-scheme.test.js \
            scripts/verify-linux-desktop-integration.test.js \
            scripts/verify-macos-bundle-associations.test.js \
            scripts/validate-linux-appimage.test.js \
            scripts/validate-linux-deb.test.js \
            scripts/validate-linux-rpm.test.js \
            scripts/validate-macos-bundle.test.js \
            scripts/validate-windows-bundles.test.js \
            scripts/ci/check-desktop-compliance-artifacts.test.js \
            scripts/ci/generate-release-checksums.test.js \
            scripts/ci/check-gha-action-sha-pins.test.js \
            scripts/ci/check-gha-runner-pins.test.js \
            scripts/ci/check-benchmark-gh-pages-concurrency.test.js \
            scripts/ci/check-toml-validity.test.js \
            scripts/ci/check-workflow-step-name-colons.test.js \
            scripts/ci/check-rust-toolchain-pins.test.js \
            scripts/ci/check-rustup-toolchain-cleared.test.js \
            scripts/ci/check-node-version-pins.test.js \
            scripts/ci/check-pnpm-version-pins.test.js \
            scripts/ci/check-wasm-pack-version-pins.test.js \
            scripts/ci/check-tauri-cli-version-pins.test.js \
            scripts/ci/check-merge-conflict-markers.test.js \
            scripts/ci/check-desktop-pyodide-bundling.test.js \
            scripts/ci/check-pyodide-cache.test.js \
            scripts/__tests__/release-workflow-windows-bundle-validation.test.js \
            scripts/__tests__/release-workflow-macos-updater-archive.test.js \
            scripts/__tests__/release-workflow-macos-updater-archive-sigs.test.js \
            scripts/__tests__/release-workflow-asset-bucketing.test.js \
            scripts/__tests__/release-smoke-test.test.js \
            scripts/__tests__/desktop-bundle-dry-run-windows-bundle-validation.test.js \
            scripts/__tests__/desktop-bundle-size-workflow-strip-check.test.js \
            scripts/__tests__/windows-arm64-smoke-windows-bundle-validation.test.js

      - name: "Guard: desktop Linux packaging compliance config (LICENSE/NOTICE/MIME)"
        run: node scripts/ci/check-desktop-compliance-artifacts.mjs

      - name: "Guard: Linux runtime dependency metadata in tauri.conf.json"
        run: node --test scripts/ci/tauri-linux-runtime-deps.test.js

  xlsx-roundtrip:
    name: XLSX round-trip fixtures
    needs: conflict-marker-guard
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4
      - uses: dtolnay/rust-toolchain@e97e2d8cc328f1b50210efc529dca0028893a2d9 # v1
        with:
          toolchain: 1.92.0
      - name: Run xlsx-diff tests (includes fixture harness)
        run: cargo test -p xlsx-diff --locked
      - name: Run formula-xlsx tests
        run: cargo test -p formula-xlsx --locked
      - name: Run formula-xls tests
        run: cargo test -p formula-xls --locked
      - name: Run formula-io tests
        run: cargo test -p formula-io --locked

  desktop-backend-tests:
    name: Desktop backend (Rust) tests
    needs: conflict-marker-guard
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4
      - uses: dtolnay/rust-toolchain@e97e2d8cc328f1b50210efc529dca0028893a2d9 # v1
        with:
          toolchain: 1.92.0
      # Our dev scripts default to a repo-local CARGO_HOME to avoid cross-agent
      # contention on shared ~/.cargo. In GitHub Actions we prefer the default
      # CARGO_HOME so cargo installs and builds share the same cache.
      - name: Use shared Cargo home for CI caching
        run: echo "CARGO_HOME=$HOME/.cargo" >> "$GITHUB_ENV"
      - name: Run desktop backend tests (no WebView toolchain)
        # NOTE: Do NOT enable the `desktop` feature here. That feature pulls in
        # the system WebView toolchain (gtk/webkit2gtk) on Linux, which is not
        # required for backend unit/integration tests.
        run: |
          # The desktop backend crate was historically named `formula-desktop-tauri`;
          # it has since been renamed to `desktop`. Run whichever exists so CI
          # keeps covering backend logic without requiring the WebView toolchain.
          if cargo metadata --no-deps --format-version=1 | grep -q '"name":"formula-desktop-tauri"'; then
            cargo test -p formula-desktop-tauri --locked
          else
            cargo test -p desktop --locked
          fi

  excel-oracle-compat:
    name: Excel oracle compatibility (pinned)
    needs: conflict-marker-guard
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4
      - uses: dtolnay/rust-toolchain@e97e2d8cc328f1b50210efc529dca0028893a2d9 # v1
        with:
          toolchain: 1.92.0
      # Our dev scripts default to a repo-local CARGO_HOME to avoid cross-agent
      # contention on shared ~/.cargo. In GitHub Actions we prefer the default
      # CARGO_HOME so cargo installs and builds share the same cache.
      - name: Use shared Cargo home for CI caching
        run: echo "CARGO_HOME=$HOME/.cargo" >> "$GITHUB_ENV"
      - uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version: "3.11"
      - name: Run excel-oracle python unit tests
        run: python -m unittest discover -s tools/excel-oracle/tests
      - name: Run excel-oracle corpus coverage guards
        run: cargo test -p formula-engine --test excel_oracle_coverage --test function_catalog_sync --test locale_function_tsv_completeness --locked
      - name: Run compatibility gate (engine vs pinned Excel dataset)
        run: python tools/excel-oracle/compat_gate.py
      - name: Publish compatibility summary
        if: always()
        run: |
          if [ -f tests/compatibility/excel-oracle/reports/summary.md ]; then
            cat tests/compatibility/excel-oracle/reports/summary.md >> "$GITHUB_STEP_SUMMARY"
          fi
      - name: Upload excel-oracle artifacts
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: excel-oracle-compat
          path: |
            tests/compatibility/excel-oracle/datasets/engine-results.json
            tests/compatibility/excel-oracle/reports/mismatch-report.json
            tests/compatibility/excel-oracle/reports/summary.md

  web:
    name: Web + desktop builds
    needs: conflict-marker-guard
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Setup pnpm
        uses: pnpm/action-setup@41ff72655975bd51cab0327fa583b6e92b6d3061 # v4
        with:
          version: 9.0.0

      - name: Setup Node
        uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: pnpm
          cache-dependency-path: pnpm-lock.yaml

      - name: Setup Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version: "3.11"
      
      - name: Setup Rust toolchain (wasm32)
        uses: dtolnay/rust-toolchain@e97e2d8cc328f1b50210efc529dca0028893a2d9 # v1
        with:
          toolchain: 1.92.0
          targets: wasm32-unknown-unknown

      # Our dev scripts default to a repo-local CARGO_HOME to avoid cross-agent
      # contention on shared ~/.cargo. In GitHub Actions we prefer the default
      # CARGO_HOME so cargo installs and wasm-pack builds share the same cache.
      - name: Use shared Cargo home for CI caching
        run: echo "CARGO_HOME=$HOME/.cargo" >> "$GITHUB_ENV"
      - name: Cache Rust builds
        uses: Swatinem/rust-cache@779680da715d629ac1d338a641029a2f4372abb5 # v2

      - name: Check formula-engine builds for wasm32
        run: cargo check -p formula-engine --target wasm32-unknown-unknown --all-targets --locked

      - name: Check formula-engine builds for wasm32 (no default features)
        run: cargo check -p formula-engine --target wasm32-unknown-unknown --no-default-features --all-targets --locked

      - name: Check formula-vba builds for wasm32
        run: cargo check -p formula-vba --target wasm32-unknown-unknown --all-targets --locked

      - name: Check formula-offcrypto builds for wasm32
        run: cargo check -p formula-offcrypto --target wasm32-unknown-unknown --all-targets --locked

      - name: Check formula-wasm builds for wasm32
        run: cargo check -p formula-wasm --target wasm32-unknown-unknown --all-targets --locked

      - name: Cache wasm-pack binary
        id: wasm-pack-cache
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: ~/.cargo/bin/wasm-pack
          # Include the Rust toolchain pin so Rust upgrades force rebuilding the cached binary.
          key: wasm-pack-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-
            # Backwards-compat: allow restoring caches created before we aligned the key format
            # with release/perf workflows (which did not include the extra `rust-` segment).
            wasm-pack-${{ runner.os }}-${{ runner.arch }}-rust-${{ hashFiles('rust-toolchain.toml') }}-

      - name: Cache wasm-pack tool downloads (Linux)
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          # wasm-pack downloads wasm-bindgen + binaryen (wasm-opt) into this cache dir.
          path: ~/.cache/.wasm-pack
          key: wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-

      - name: Install wasm-pack
        if: steps.wasm-pack-cache.outputs.cache-hit != 'true'
        # Pinned to match the tagged release workflow so CI catches WASM toolchain
        # incompatibilities before we cut a release.
        # Use --force so cache restore-keys (or other CI caches) can't strand a stale/untracked
        # wasm-pack binary that would otherwise block `cargo install` from overwriting it.
        run: cargo install wasm-pack --version ${{ env.WASM_PACK_VERSION }} --locked --force

      - name: Verify wasm-pack version
        shell: bash
        run: |
          set -euo pipefail
          expected="${WASM_PACK_VERSION}"
          actual="$(wasm-pack --version | tr -d '\r' | awk '{print $2}')"
          if [[ "${actual}" != "${expected}" ]]; then
            echo "Expected wasm-pack ${expected}, but found ${actual}." >&2
            exit 1
          fi

      - name: Build WASM bundle (wasm-pack)
        # Build before `pnpm install` so we fail fast on Rust/WASM toolchain issues
        # without paying the JS dependency install cost.
        run: node packages/engine/scripts/build-wasm.mjs

      - name: Run formula-wasm wasm-bindgen tests (node)
        # Ensure our wasm-bindgen exports (including optional engines like formula-dax)
        # remain usable in JS runtimes.
        run: wasm-pack test --node crates/formula-wasm --release

      - name: Build formula-wasm Node bundle (pkg-node)
        # `packages/engine` unit tests load the wasm bundle through this script (CommonJS `--target nodejs`)
        # and it's easy for it to regress without an explicit CI invocation.
        run: node scripts/build-formula-wasm-node.mjs

      - name: Smoke-check WASM assets (no pnpm install)
        run: node packages/engine/scripts/smoke-wasm.mjs

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Lint (Node-free desktop renderer guard)
        run: pnpm -w lint

      - name: Build web
        run: pnpm build:web

      - name: Report frontend asset download size (web)
        env:
          # Optional: define these as GitHub Actions "Variables" to enable gating without
          # changing the workflow.
          FORMULA_ENFORCE_FRONTEND_ASSET_SIZE: ${{ vars.FORMULA_ENFORCE_FRONTEND_ASSET_SIZE }}
          FORMULA_FRONTEND_ASSET_SIZE_LIMIT_MB: ${{ vars.FORMULA_FRONTEND_ASSET_SIZE_LIMIT_MB }}
          FORMULA_FRONTEND_ASSET_SIZE_COMPRESSION: ${{ vars.FORMULA_FRONTEND_ASSET_SIZE_COMPRESSION }}
        run: node scripts/frontend_asset_size_report.mjs --dist apps/web/dist --json-out web-frontend-asset-size-report.json

      - name: Upload frontend asset size report (web, JSON)
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: web-frontend-asset-size-report
          path: web-frontend-asset-size-report.json
          if-no-files-found: ignore

      - name: Detect Pyodide version (for caching)
        id: pyodide
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1'
        shell: bash
        run: |
          set -euo pipefail
          version="$(node -e "const fs=require('node:fs'); const src=fs.readFileSync('apps/desktop/scripts/ensure-pyodide-assets.mjs','utf8'); const m=src.match(/const\\s+PYODIDE_VERSION\\s*=\\s*['\\\"]([^'\\\"]+)['\\\"]/); if(!m) throw new Error('PYODIDE_VERSION not found'); process.stdout.write(m[1]);")"
          echo "version=${version}" >> "$GITHUB_OUTPUT"

      - name: Restore Pyodide asset cache
        id: pyodide-cache
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1'
        uses: actions/cache/restore@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: apps/desktop/public/pyodide/v${{ steps.pyodide.outputs.version }}/full/
          key: pyodide-${{ runner.os }}-${{ steps.pyodide.outputs.version }}-${{ hashFiles('apps/desktop/scripts/ensure-pyodide-assets.mjs') }}

      - name: Ensure Pyodide assets are present
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1'
        run: node apps/desktop/scripts/ensure-pyodide-assets.mjs

      - name: Save Pyodide asset cache
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1' && steps.pyodide-cache.outputs.cache-hit != 'true'
        uses: actions/cache/save@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: apps/desktop/public/pyodide/v${{ steps.pyodide.outputs.version }}/full/
          key: pyodide-${{ runner.os }}-${{ steps.pyodide.outputs.version }}-${{ hashFiles('apps/desktop/scripts/ensure-pyodide-assets.mjs') }}
      - name: Build desktop (Vite)
        run: pnpm build:desktop

      - name: Desktop dist asset report
        run: node scripts/desktop_dist_asset_report.mjs --json-out desktop-dist-assets-report.json
        env:
          # Optional: define these as GitHub Actions "Variables" to enable gating without
          # changing the workflow. Leaving them unset (or empty) keeps the report informational.
          FORMULA_DESKTOP_DIST_TOTAL_BUDGET_MB: ${{ vars.FORMULA_DESKTOP_DIST_TOTAL_BUDGET_MB }}
          FORMULA_DESKTOP_DIST_SINGLE_FILE_BUDGET_MB: ${{ vars.FORMULA_DESKTOP_DIST_SINGLE_FILE_BUDGET_MB }}

      - name: Upload desktop dist asset report (JSON)
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: desktop-dist-assets-report
          path: desktop-dist-assets-report.json
          if-no-files-found: ignore

      - name: Report frontend asset download size (desktop)
        env:
          FORMULA_ENFORCE_FRONTEND_ASSET_SIZE: ${{ vars.FORMULA_ENFORCE_FRONTEND_ASSET_SIZE }}
          FORMULA_FRONTEND_ASSET_SIZE_LIMIT_MB: ${{ vars.FORMULA_FRONTEND_ASSET_SIZE_LIMIT_MB }}
          FORMULA_FRONTEND_ASSET_SIZE_COMPRESSION: ${{ vars.FORMULA_FRONTEND_ASSET_SIZE_COMPRESSION }}
        run: node scripts/frontend_asset_size_report.mjs --dist apps/desktop/dist --json-out desktop-frontend-asset-size-report.json

      - name: Upload frontend asset size report (desktop, JSON)
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: desktop-frontend-asset-size-report
          path: desktop-frontend-asset-size-report.json
          if-no-files-found: ignore

      - name: Check desktop JS bundle size budgets
        run: pnpm -C apps/desktop check:bundle-size
        env:
          # Budgets are interpreted as KiB (1024 bytes). Adjust intentionally when
          # landing changes that affect the initial load footprint.
          FORMULA_DESKTOP_JS_TOTAL_BUDGET_KB: ${{ vars.FORMULA_DESKTOP_JS_TOTAL_BUDGET_KB || '5700' }}
          FORMULA_DESKTOP_JS_ENTRY_BUDGET_KB: ${{ vars.FORMULA_DESKTOP_JS_ENTRY_BUDGET_KB || '2100' }}
          # Optional: budget just the Vite-emitted JS bundles (dist/assets/**/*.js).
          FORMULA_DESKTOP_JS_ASSETS_BUDGET_KB: ${{ vars.FORMULA_DESKTOP_JS_ASSETS_BUDGET_KB }}
          FORMULA_DESKTOP_BUNDLE_SIZE_WARN_ONLY: ${{ vars.FORMULA_DESKTOP_BUNDLE_SIZE_WARN_ONLY }}
          FORMULA_DESKTOP_BUNDLE_SIZE_SKIP_GZIP: ${{ vars.FORMULA_DESKTOP_BUNDLE_SIZE_SKIP_GZIP }}

      - name: Smoke-check WASM assets
        run: pnpm smoke:wasm

      - name: Install Linux dependencies (Tauri/WebView)
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libgtk-3-dev \
            libwebkit2gtk-4.1-dev \
            libayatana-appindicator3-dev \
            librsvg2-dev \
            libssl-dev \
            patchelf

      - name: Build desktop binary (Rust, release)
        id: build_desktop_binary
        run: |
          # The desktop shell package has historically been named both `desktop` and
          # `formula-desktop-tauri`. Build whichever exists so CI keeps reporting size
          # without depending on an exact package rename history.
          if cargo metadata --no-deps --format-version=1 | grep -q '"name":"formula-desktop-tauri"'; then
            cargo build -p formula-desktop-tauri --bin formula-desktop --features desktop --release --locked
          else
            cargo build -p desktop --bin formula-desktop --features desktop --release --locked
          fi

      - name: Desktop size report (binary + dist)
        env:
          # Optional: define these as GitHub Actions "Variables" to enable gating without
          # changing the workflow. Leaving them unset (or empty) keeps the report informational.
          FORMULA_DESKTOP_BINARY_SIZE_LIMIT_MB: ${{ vars.FORMULA_DESKTOP_BINARY_SIZE_LIMIT_MB }}
          FORMULA_DESKTOP_DIST_SIZE_LIMIT_MB: ${{ vars.FORMULA_DESKTOP_DIST_SIZE_LIMIT_MB }}
        run: python3 scripts/desktop_size_report.py --dist apps/desktop/dist --json-out desktop-size-report.json

      - name: Upload desktop size report (JSON)
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: desktop-size-report
          path: desktop-size-report.json
          if-no-files-found: ignore

      - name: Cache cargo-bloat binary
        if: always() && steps.build_desktop_binary.outcome == 'success'
        id: cargo-bloat-cache
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: ~/.cargo/bin/cargo-bloat
          # Include the pinned Rust toolchain hash so Rust upgrades force a fresh install
          # (ensuring CI validates the new toolchain can still build required cargo-installed tools).
          key: cargo-bloat-${{ runner.os }}-${{ runner.arch }}-rust-${{ hashFiles('rust-toolchain.toml') }}
          restore-keys: |
            cargo-bloat-${{ runner.os }}-${{ runner.arch }}-rust-${{ hashFiles('rust-toolchain.toml') }}-
            cargo-bloat-${{ runner.os }}-${{ runner.arch }}-

      - name: Install cargo-bloat
        if: always() && steps.build_desktop_binary.outcome == 'success' && steps.cargo-bloat-cache.outputs.cache-hit != 'true'
        continue-on-error: true
        run: cargo install cargo-bloat --locked

      - name: Desktop Rust binary size breakdown (cargo-bloat)
        if: always() && steps.build_desktop_binary.outcome == 'success'
        # Informational by default. Set `FORMULA_ENFORCE_DESKTOP_BINARY_SIZE=1` (and a
        # `FORMULA_DESKTOP_BINARY_SIZE_LIMIT_MB` budget) to turn this into a regression gate.
        continue-on-error: ${{ !contains(fromJson('["1","true","True","TRUE","yes","Yes","YES","y","Y","on","On","ON"]'), vars.FORMULA_ENFORCE_DESKTOP_BINARY_SIZE) }}
        env:
          FORMULA_ENFORCE_DESKTOP_BINARY_SIZE: ${{ vars.FORMULA_ENFORCE_DESKTOP_BINARY_SIZE }}
          FORMULA_DESKTOP_BINARY_SIZE_LIMIT_MB: ${{ vars.FORMULA_DESKTOP_BINARY_SIZE_LIMIT_MB }}
        run: python3 scripts/desktop_binary_size_report.py --no-build --json-out desktop-binary-size-report.json

      - name: Upload desktop binary size report (JSON)
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: desktop-binary-size-report
          path: desktop-binary-size-report.json
          if-no-files-found: ignore
  desktop-tauri-check:
    name: Desktop (Tauri) Rust compile check
    needs: conflict-marker-guard
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4
      - uses: dtolnay/rust-toolchain@e97e2d8cc328f1b50210efc529dca0028893a2d9 # v1
        with:
          toolchain: 1.92.0
      - name: Setup Node (for Tauri permission validation script)
        uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4
        with:
          node-version: ${{ env.NODE_VERSION }}
      - name: Check pinned Tauri CLI version matches Tauri crates
        run: node scripts/ci/check-tauri-cli-version.mjs
      # Our dev scripts default to a repo-local CARGO_HOME to avoid cross-agent
      # contention on shared ~/.cargo. In GitHub Actions we prefer the default
      # CARGO_HOME so cargo installs/builds share the same cache.
      - name: Use shared Cargo home for CI caching
        run: echo "CARGO_HOME=$HOME/.cargo" >> "$GITHUB_ENV"
      - name: Install Linux dependencies (Tauri/WebView)
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libgtk-3-dev \
            libwebkit2gtk-4.1-dev \
            libayatana-appindicator3-dev \
            librsvg2-dev \
            libssl-dev \
            patchelf
      - name: Cache Tauri permission list (cargo tauri permission ls)
        id: tauri-permission-list-cache
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: target/ci/tauri-permission-ls.txt
          key: tauri-permission-ls-${{ runner.os }}-${{ runner.arch }}-v${{ env.TAURI_CLI_VERSION }}-${{ hashFiles('Cargo.lock', 'apps/desktop/src-tauri/Cargo.toml', 'apps/desktop/src-tauri/tauri.conf.json') }}
      - name: Cache cargo-tauri binary
        # If the permission list is already cached, `scripts/check-tauri-permissions.mjs` can run
        # without installing the Tauri CLI binary.
        if: steps.tauri-permission-list-cache.outputs.cache-hit != 'true'
        id: cargo-tauri-cache
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: ~/.cargo/bin/cargo-tauri*
          # Include the Rust toolchain pin so Rust upgrades force rebuilding cargo-tauri.
          key: cargo-tauri-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-v${{ env.TAURI_CLI_VERSION }}
          restore-keys: |
            cargo-tauri-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-
      - name: Install pinned tauri-cli (cargo tauri)
        if: steps.tauri-permission-list-cache.outputs.cache-hit != 'true' && steps.cargo-tauri-cache.outputs.cache-hit != 'true'
        run: bash scripts/cargo_agent.sh install tauri-cli --version "${TAURI_CLI_VERSION}" --locked --force
      - name: Verify cargo-tauri version
        if: steps.tauri-permission-list-cache.outputs.cache-hit != 'true'
        shell: bash
        run: |
          set -euo pipefail
          expected="${TAURI_CLI_VERSION}"
          actual="$(cargo tauri --version | tr -d '\r' | awk '{print $2}')"
          echo "cargo-tauri version: ${actual}"
          if [[ "${actual}" != "${expected}" ]]; then
            echo "Expected cargo-tauri ${expected}, but found ${actual}." >&2
            exit 1
          fi
      - name: Cache Tauri tooling downloads
        if: steps.tauri-permission-list-cache.outputs.cache-hit != 'true'
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: ~/.cache/tauri
          key: tauri-tooling-${{ runner.os }}-${{ runner.arch }}-v${{ env.TAURI_CLI_VERSION }}
          restore-keys: |
            tauri-tooling-${{ runner.os }}-${{ runner.arch }}-
            # Backwards-compat: allow restoring caches created before we aligned the key format
            # with release/dry-run workflows (which did not include the extra toolchain hash segment).
            tauri-tooling-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-
      - name: Validate Tauri capability permission identifiers
        env:
          # Allows `scripts/check-tauri-permissions.mjs` to reuse the `cargo tauri permission ls`
          # output across CI runs when the Tauri toolchain + Cargo.lock inputs haven't changed.
          FORMULA_TAURI_PERMISSION_LS_CACHE_PATH: target/ci/tauri-permission-ls.txt
        run: node scripts/check-tauri-permissions.mjs
      - name: Check desktop shell builds with full desktop feature set
        run: |
          # The desktop shell crate was historically named `desktop`. It is now
          # `formula-desktop-tauri` (with the Rust library crate kept as `desktop`
          # so internal `use desktop::...` imports still work).
          if cargo metadata --no-deps --format-version=1 | grep -q '"name":"formula-desktop-tauri"'; then
            cargo check -p formula-desktop-tauri --features desktop --locked
          else
            cargo check -p desktop --features desktop --locked
          fi

  desktop-tauri-check-windows:
    name: Desktop (Tauri) Rust compile check (Windows)
    needs: conflict-marker-guard
    # Pin runner image versions for reproducibility and to keep CI aligned with
    # the Desktop Release workflow (avoid `windows-latest` alias drift).
    runs-on: windows-2022
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4
      - uses: dtolnay/rust-toolchain@e97e2d8cc328f1b50210efc529dca0028893a2d9 # v1
        with:
          toolchain: 1.92.0
      # Our dev scripts default to a repo-local CARGO_HOME to avoid cross-agent
      # contention on shared ~/.cargo. In GitHub Actions we prefer the default
      # CARGO_HOME so cargo installs/builds share the same cache.
      - name: Use shared Cargo home for CI caching
        # PowerShell file redirection can emit UTF-16; explicitly write UTF-8 so
        # GitHub Actions can parse the environment file.
        run: echo "CARGO_HOME=$HOME/.cargo" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
      - name: Check desktop builds with full desktop feature set
        run: |
          if (cargo metadata --no-deps --format-version=1 | Select-String -Pattern '"name":"formula-desktop-tauri"' -Quiet) {
            cargo check -p formula-desktop-tauri --features desktop --locked
          } else {
            cargo check -p desktop --features desktop --locked
          }

  desktop-tauri-check-macos:
    name: Desktop (Tauri) Rust compile check (macOS)
    needs: conflict-marker-guard
    # Pin runner image versions for reproducibility and to keep CI aligned with
    # the Desktop Release workflow (avoid `macos-latest` alias drift).
    runs-on: macos-14
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4
      - name: Setup Node (for static preflight scripts)
        uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4
        with:
          node-version: ${{ env.NODE_VERSION }}
      - name: Validate macOS entitlements (hardened runtime)
        run: node scripts/check-macos-entitlements.mjs
      - uses: dtolnay/rust-toolchain@e97e2d8cc328f1b50210efc529dca0028893a2d9 # v1
        with:
          toolchain: 1.92.0
      # Our dev scripts default to a repo-local CARGO_HOME to avoid cross-agent
      # contention on shared ~/.cargo. In GitHub Actions we prefer the default
      # CARGO_HOME so cargo installs/builds share the same cache.
      - name: Use shared Cargo home for CI caching
        run: echo "CARGO_HOME=$HOME/.cargo" >> "$GITHUB_ENV"
      - name: Check desktop builds with full desktop feature set
        run: |
          if cargo metadata --no-deps --format-version=1 | grep -q '"name":"formula-desktop-tauri"'; then
            cargo check -p formula-desktop-tauri --features desktop --locked
          else
            cargo check -p desktop --features desktop --locked
          fi

  node-tests:
    name: Node tests
    needs: conflict-marker-guard
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Setup pnpm
        uses: pnpm/action-setup@41ff72655975bd51cab0327fa583b6e92b6d3061 # v4
        with:
          version: 9.0.0

      - name: Setup Node
        uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: pnpm
          cache-dependency-path: pnpm-lock.yaml

      - name: "Guard: desktop bundles ship LICENSE/NOTICE (config)"
        run: node scripts/ci/check-desktop-compliance-artifacts.mjs

      - name: "Guard: locale function TSVs match generator output"
        env:
          # The function TSV generator derives its header date from SOURCE_DATE_EPOCH.
          # Keep this pinned so CI never rewrites the committed TSV headers.
          SOURCE_DATE_EPOCH: "0"
        run: node scripts/generate-locale-function-tsv.js --check

      - name: "Guard: locale error TSVs match generator output"
        run: node scripts/generate-locale-error-tsvs.mjs --check

      - uses: dtolnay/rust-toolchain@e97e2d8cc328f1b50210efc529dca0028893a2d9 # v1
        with:
          toolchain: 1.92.0
          components: rustfmt

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Run node:test suite
        run: pnpm test:node

  tab-completion-latency-guard:
    name: TabCompletionEngine latency guard
    needs: conflict-marker-guard
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Setup Node
        uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Run TabCompletionEngine micro-benchmark
        run: node packages/ai-completion/bench/tabCompletionEngine.bench.mjs --ci

  desktop-tauri-guardrails:
    name: Desktop (Tauri) frontend guardrail tests
    needs: conflict-marker-guard
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Setup pnpm
        uses: pnpm/action-setup@41ff72655975bd51cab0327fa583b6e92b6d3061 # v4
        with:
          version: 9.0.0

      - name: Setup Node
        uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: pnpm
          cache-dependency-path: pnpm-lock.yaml

      - name: "Guard: Windows Authenticode timestamp URL uses HTTPS"
        run: node scripts/ci/check-windows-timestamp-url.mjs

      - name: "Guard: Windows WebView2 installer configuration (webviewInstallMode)"
        run: node scripts/ci/check-webview2-install-mode.mjs

      - name: "Guard: Windows downgrade / rollback support (allowDowngrades)"
        run: node scripts/ci/check-windows-allow-downgrades.mjs

      - name: "Guard: WiX upgradeCode is pinned (stable MSI upgrades/downgrades)"
        run: node scripts/ci/check-windows-wix-upgrade-code.mjs

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Run desktop Tauri guardrail Vitest suite (capabilities/event allowlists + IPC readiness + bundle integration)
        env:
          # These tests only parse JSON/config and source files; skip the repo-wide
          # wasm-pack build performed by scripts/vitest.global-setup.mjs.
          FORMULA_SKIP_WASM_BUILD: "1"
        # NOTE: Do not include an extra `--` after the script name. Vitest treats it as
        # an argument separator and will fall back to running the full test suite.
        run: >-
          pnpm test:vitest
          apps/desktop/src/tauri/__tests__/eventPermissions.vitest.ts
          apps/desktop/src/tauri/__tests__/capabilitiesPermissions.vitest.ts
          apps/desktop/src/tauri/__tests__/tauriSecurityConfig.vitest.ts
          apps/desktop/src/tauri/__tests__/openFileIpc.vitest.ts
          apps/desktop/src/tauri/__tests__/openFileIpcWiring.vitest.ts
          apps/desktop/src/tauri/__tests__/bundleAssociationsConfig.vitest.ts
          apps/desktop/src/tauri/__tests__/infoPlistAssociations.vitest.ts

  sync-server-docker:
    name: Sync server Docker build
    needs: conflict-marker-guard
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - name: Setup Node (for JSON parsing in smoke tests)
        uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Build sync-server image
        run: docker build --build-arg npm_config_build_from_source=true -f services/sync-server/Dockerfile . -t formula-sync-server:ci

      - name: Smoke test container
        run: |
          set -euo pipefail
          docker volume create sync-server-ci-data-leveldb > /dev/null
          docker run -d \
            -p 12345:1234 \
            -e SYNC_SERVER_AUTH_TOKEN=ci-token \
            -e SYNC_SERVER_DATA_DIR=/data \
            -v sync-server-ci-data-leveldb:/data \
            --name sync-server \
            formula-sync-server:ci

          cleanup() {
            docker logs sync-server --tail 200 || true
            docker rm -f sync-server || true
            docker volume rm -f sync-server-ci-data-leveldb || true
          }
          trap cleanup EXIT

          for i in {1..30}; do
            if curl -fsS http://127.0.0.1:12345/healthz > /dev/null; then
              break
            fi
            sleep 1
          done

          curl -fsS http://127.0.0.1:12345/healthz | node -e "const fs=require('fs');const j=JSON.parse(fs.readFileSync(0,'utf8'));console.log(JSON.stringify(j));if(j.backend!=='leveldb'){throw new Error('expected backend=leveldb');}if(j.encryptionEnabled!==false){throw new Error('expected encryptionEnabled=false');}"

      - name: Smoke test container (file + encryption)
        run: |
          set -euo pipefail

          # KeyRing JSON with a deterministic all-zero 32-byte key (sufficient for CI smoke testing).
          KEYRING_JSON='{"currentVersion":1,"keys":{"1":"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA="}}'

          docker volume create sync-server-ci-data-file > /dev/null
          docker run -d \
            -p 12346:1234 \
            -e SYNC_SERVER_AUTH_TOKEN=ci-token \
            -e SYNC_SERVER_PERSISTENCE_BACKEND=file \
            -e SYNC_SERVER_PERSISTENCE_ENCRYPTION=keyring \
            -e SYNC_SERVER_ENCRYPTION_KEYRING_JSON="$KEYRING_JSON" \
            -e SYNC_SERVER_DATA_DIR=/data \
            -v sync-server-ci-data-file:/data \
            --name sync-server \
            formula-sync-server:ci

          cleanup() {
            docker logs sync-server --tail 200 || true
            docker rm -f sync-server || true
            docker volume rm -f sync-server-ci-data-file || true
          }
          trap cleanup EXIT

          for i in {1..30}; do
            if curl -fsS http://127.0.0.1:12346/healthz > /dev/null; then
              break
            fi
            sleep 1
          done

          curl -fsS http://127.0.0.1:12346/healthz | node -e "const fs=require('fs');const j=JSON.parse(fs.readFileSync(0,'utf8'));console.log(JSON.stringify(j));if(j.backend!=='file'){throw new Error('expected backend=file');}if(j.encryptionEnabled!==true){throw new Error('expected encryptionEnabled=true');}"
