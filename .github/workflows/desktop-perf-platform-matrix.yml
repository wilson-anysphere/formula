name: Desktop performance (platform matrix)

on:
  workflow_dispatch:
    inputs:
      os:
        description: "Which OS to run on (default: all)"
        required: false
        default: all
        type: choice
        options:
          - all
          - ubuntu-24.04
          - windows-2022
          - macos-14
      startupRuns:
        description: "Number of cold/warm startup iterations (default: 5)"
        required: false
        default: "5"
        type: string
      startupTimeoutMs:
        description: "Per-startup-run timeout in milliseconds (default: 20000)"
        required: false
        default: "20000"
        type: string
      memoryRuns:
        description: "Number of idle-memory iterations (default: 3)"
        required: false
        default: "3"
        type: string
      memoryTimeoutMs:
        description: "Per-memory-run timeout in milliseconds (default: 30000)"
        required: false
        default: "30000"
        type: string
      memorySettleMs:
        description: "Idle-memory settle delay after TTI in milliseconds (default: 5000)"
        required: false
        default: "5000"
        type: string
  schedule:
    # Daily (UTC). Adjust as needed; goal is continuous cross-platform visibility.
    - cron: "0 7 * * *"

permissions:
  contents: read

concurrency:
  # Avoid overlapping scheduled runs (they can be expensive across 3 OSes).
  # Keep per-ref isolation so manual runs on other branches don't get stuck behind main.
  group: desktop-perf-platform-matrix-${{ github.ref }}
  cancel-in-progress: false

env:
  # Keep these in sync with ci.yml/release.yml to reduce cross-workflow drift.
  NODE_VERSION: 22
  WASM_PACK_VERSION: 0.13.1
  # Opt-in: bundle Pyodide assets into `apps/desktop/dist` (otherwise Pyodide is downloaded
  # on-demand at runtime and cached in the app data directory).
  FORMULA_BUNDLE_PYODIDE_ASSETS: ${{ vars.FORMULA_BUNDLE_PYODIDE_ASSETS }}
  # This workflow is for tracking/visibility, not gating. Force bench enforcement off even if
  # repo/organization variables set these for other workflows.
  FORMULA_ENFORCE_DESKTOP_STARTUP_BENCH: "0"
  FORMULA_ENFORCE_DESKTOP_MEMORY_BENCH: "0"
  # Defaults for `workflow_dispatch` inputs. (Scheduled runs will always use these.)
  DESKTOP_STARTUP_RUNS: 5
  DESKTOP_STARTUP_TIMEOUT_MS: 20000
  DESKTOP_MEMORY_RUNS: 3
  DESKTOP_MEMORY_TIMEOUT_MS: 30000
  DESKTOP_MEMORY_SETTLE_MS: 5000

jobs:
  desktop-perf:
    name: Desktop perf (${{ matrix.os }})
    # Avoid spending compute on scheduled runs in forks.
    if: github.event_name != 'schedule' || github.repository == 'wilson-anysphere/formula'
    runs-on: ${{ matrix.os }}
    timeout-minutes: 90
    strategy:
      fail-fast: false
      matrix:
        # Pin runner images for reproducibility. GitHub's `*-latest` labels move over time,
        # which can both break workflows unexpectedly and introduce noise into perf trends.
        # Update these pins deliberately after validating on newer runner images:
        # https://github.com/actions/runner-images
        os: ${{ fromJSON(github.event_name == 'workflow_dispatch' && github.event.inputs.os != 'all' && format('[{0}]', toJSON(github.event.inputs.os)) || '["ubuntu-24.04","windows-2022","macos-14"]') }}

    steps:
      - name: Checkout
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v4

      - name: "Guard: Rust toolchain pins match rust-toolchain.toml"
        shell: bash
        run: bash scripts/ci/check-rust-toolchain-pins.sh

      - name: Setup pnpm
        uses: pnpm/action-setup@41ff72655975bd51cab0327fa583b6e92b6d3061 # v4
        with:
          version: 9.0.0

      - name: Setup Node
        uses: actions/setup-node@6044e13b5dc448c55e2357c09f80417699197238 # v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: pnpm
          cache-dependency-path: pnpm-lock.yaml

      - name: "Guard: Windows Authenticode timestamp URL uses HTTPS"
        run: node scripts/ci/check-windows-timestamp-url.mjs

      - name: Setup Rust toolchain (pinned + wasm32)
        uses: dtolnay/rust-toolchain@e97e2d8cc328f1b50210efc529dca0028893a2d9 # v1
        with:
          toolchain: 1.92.0
          targets: wasm32-unknown-unknown

      # Our dev scripts default to a repo-local CARGO_HOME to avoid cross-agent
      # contention on shared ~/.cargo. In GitHub Actions we prefer the default
      # CARGO_HOME so cargo installs/builds share the same cache.
      - name: Use shared Cargo home for CI caching (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $cargoHome = Join-Path $env:USERPROFILE ".cargo"
          "CARGO_HOME=$cargoHome" | Out-File -FilePath $env:GITHUB_ENV -Append -Encoding utf8

      - name: Use shared Cargo home for CI caching (Unix)
        if: runner.os != 'Windows'
        run: echo "CARGO_HOME=$HOME/.cargo" >> "$GITHUB_ENV"

      - name: Rust cache
        uses: Swatinem/rust-cache@779680da715d629ac1d338a641029a2f4372abb5 # v2

      - name: Install Linux dependencies (Tauri/WebView + headless display)
        if: matrix.os == 'ubuntu-24.04'
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            xvfb \
            libgtk-3-dev \
            libwebkit2gtk-4.1-dev \
            libayatana-appindicator3-dev \
            librsvg2-dev \
            libssl-dev \
            patchelf

      - name: Install JS dependencies
        env:
          # This workflow does not run Playwright tests, so skip the ~GB browser downloads
          # performed by `@playwright/test`'s postinstall script.
          PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD: "1"
        # Prefer cached pnpm store entries to reduce network flakiness on reruns.
        run: pnpm install --frozen-lockfile --prefer-offline

      - name: Apply workflow_dispatch perf overrides
        if: github.event_name == 'workflow_dispatch'
        shell: bash
        env:
          INPUT_STARTUP_RUNS: ${{ github.event.inputs.startupRuns }}
          INPUT_STARTUP_TIMEOUT_MS: ${{ github.event.inputs.startupTimeoutMs }}
          INPUT_MEMORY_RUNS: ${{ github.event.inputs.memoryRuns }}
          INPUT_MEMORY_TIMEOUT_MS: ${{ github.event.inputs.memoryTimeoutMs }}
          INPUT_MEMORY_SETTLE_MS: ${{ github.event.inputs.memorySettleMs }}
        run: |
          set -euo pipefail

          trim() {
            local s="$1"
            # ltrim
            s="${s#"${s%%[![:space:]]*}"}"
            # rtrim
            s="${s%"${s##*[![:space:]]}"}"
            printf '%s' "$s"
          }

          write_int_override() {
            local env_key="$1"
            local input_name="$2"
            local raw="$3"
            local min="$4"
            local value
            value="$(trim "${raw}")"
            if [[ -z "$value" ]]; then
              return 0
            fi
            if ! [[ "$value" =~ ^[0-9]+$ ]]; then
              echo "::error::workflow_dispatch input '${input_name}' must be an integer (got: '${value}')" >&2
              exit 1
            fi
            if (( value < min )); then
              echo "::error::workflow_dispatch input '${input_name}' must be >= ${min} (got: '${value}')" >&2
              exit 1
            fi
            echo "${env_key}=${value}" >> "$GITHUB_ENV"
          }

          write_int_override "DESKTOP_STARTUP_RUNS" "startupRuns" "$INPUT_STARTUP_RUNS" 1
          write_int_override "DESKTOP_STARTUP_TIMEOUT_MS" "startupTimeoutMs" "$INPUT_STARTUP_TIMEOUT_MS" 1
          write_int_override "DESKTOP_MEMORY_RUNS" "memoryRuns" "$INPUT_MEMORY_RUNS" 1
          write_int_override "DESKTOP_MEMORY_TIMEOUT_MS" "memoryTimeoutMs" "$INPUT_MEMORY_TIMEOUT_MS" 1
          write_int_override "DESKTOP_MEMORY_SETTLE_MS" "memorySettleMs" "$INPUT_MEMORY_SETTLE_MS" 0

      - name: Cache wasm-pack binary
        id: wasm-pack-cache
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v4
        with:
          path: ~/.cargo/bin/wasm-pack*
          # Include the Rust toolchain pin so Rust upgrades force rebuilding the cached binary.
          key: wasm-pack-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-

      - name: Cache wasm-pack tool downloads (Linux)
        if: runner.os == 'Linux'
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v4
        with:
          # wasm-pack downloads wasm-bindgen + binaryen (wasm-opt) into this cache dir.
          path: ~/.cache/.wasm-pack
          key: wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-

      - name: Cache wasm-pack tool downloads (macOS)
        if: runner.os == 'macOS'
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v4
        with:
          path: ~/Library/Caches/.wasm-pack
          key: wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-

      - name: Cache wasm-pack tool downloads (Windows)
        if: runner.os == 'Windows'
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v4
        with:
          path: ${{ env.LOCALAPPDATA }}/.wasm-pack
          key: wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-

      - name: Install wasm-pack (required for @formula/engine WASM build)
        if: steps.wasm-pack-cache.outputs.cache-hit != 'true'
        # Use --force so cache restore-keys (or other CI caches) can't strand a stale/untracked
        # wasm-pack binary that would otherwise block `cargo install` from overwriting it.
        run: cargo install wasm-pack --version ${{ env.WASM_PACK_VERSION }} --locked --force

      - name: Verify wasm-pack version
        shell: bash
        run: |
          set -euo pipefail
          expected="${WASM_PACK_VERSION}"
          actual="$(wasm-pack --version | tr -d '\r' | awk '{print $2}')"
          if [[ "${actual}" != "${expected}" ]]; then
            echo "Expected wasm-pack ${expected}, but found ${actual}." >&2
            exit 1
          fi

      - name: Detect Pyodide version (for caching)
        id: pyodide
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1'
        shell: bash
        run: |
          set -euo pipefail
          version="$(node -e "const fs=require('node:fs'); const src=fs.readFileSync('apps/desktop/scripts/ensure-pyodide-assets.mjs','utf8'); const m=src.match(/const\\s+PYODIDE_VERSION\\s*=\\s*['\\\"]([^'\\\"]+)['\\\"]/); if(!m) throw new Error('PYODIDE_VERSION not found'); process.stdout.write(m[1]);")"
          echo "version=${version}" >> "$GITHUB_OUTPUT"

      - name: Restore Pyodide asset cache
        id: pyodide-cache
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1'
        uses: actions/cache/restore@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v4
        with:
          path: apps/desktop/public/pyodide/v${{ steps.pyodide.outputs.version }}/full/
          key: pyodide-${{ runner.os }}-${{ steps.pyodide.outputs.version }}-${{ hashFiles('apps/desktop/scripts/ensure-pyodide-assets.mjs') }}

      - name: Ensure Pyodide assets are present
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1'
        run: node apps/desktop/scripts/ensure-pyodide-assets.mjs

      - name: Save Pyodide asset cache
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1' && steps.pyodide-cache.outputs.cache-hit != 'true'
        uses: actions/cache/save@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v4
        with:
          path: apps/desktop/public/pyodide/v${{ steps.pyodide.outputs.version }}/full/
          key: pyodide-${{ runner.os }}-${{ steps.pyodide.outputs.version }}-${{ hashFiles('apps/desktop/scripts/ensure-pyodide-assets.mjs') }}

      - name: Build desktop frontend (Vite + WASM)
        run: pnpm build:desktop

      - name: Desktop dist asset report
        # Size regressions are useful context, but this workflow is primarily about
        # startup + memory. Keep size checks non-blocking so we still get perf data.
        continue-on-error: true
        run: node scripts/desktop_dist_asset_report.mjs --json-out perf-artifacts/desktop-dist-assets-report.json
        env:
          # Optional: set as GitHub Actions variables to enable gating.
          FORMULA_DESKTOP_DIST_TOTAL_BUDGET_MB: ${{ vars.FORMULA_DESKTOP_DIST_TOTAL_BUDGET_MB }}
          FORMULA_DESKTOP_DIST_SINGLE_FILE_BUDGET_MB: ${{ vars.FORMULA_DESKTOP_DIST_SINGLE_FILE_BUDGET_MB }}

      - name: Build desktop binary (release)
        shell: bash
        run: |
          set -euo pipefail
          if cargo metadata --no-deps --format-version=1 | grep -q '"name":"formula-desktop-tauri"'; then
            cargo build -p formula-desktop-tauri --bin formula-desktop --features desktop --release --locked
          else
            cargo build -p desktop --bin formula-desktop --features desktop --release --locked
          fi

      - name: Run desktop startup benchmark (cold)
        id: startup-cold
        continue-on-error: true
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p perf-artifacts
          node scripts/run-node-ts.mjs apps/desktop/tests/performance/desktop-startup-runner.ts \
            --mode cold \
            --full \
            --runs "${DESKTOP_STARTUP_RUNS}" \
            --timeout-ms "${DESKTOP_STARTUP_TIMEOUT_MS}" \
            --json perf-artifacts/desktop-startup-metrics-cold.json \
            --allow-ci 2>&1 | tee perf-artifacts/desktop-startup-cold.log

      - name: Run desktop startup benchmark (warm)
        id: startup-warm
        continue-on-error: true
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p perf-artifacts
          node scripts/run-node-ts.mjs apps/desktop/tests/performance/desktop-startup-runner.ts \
            --mode warm \
            --full \
            --runs "${DESKTOP_STARTUP_RUNS}" \
            --timeout-ms "${DESKTOP_STARTUP_TIMEOUT_MS}" \
            --json perf-artifacts/desktop-startup-metrics-warm.json \
            --allow-ci 2>&1 | tee perf-artifacts/desktop-startup-warm.log

      - name: Run idle memory benchmark
        id: memory
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p perf-artifacts
          node scripts/run-node-ts.mjs apps/desktop/tests/performance/desktop-memory-runner.ts \
            --runs "${DESKTOP_MEMORY_RUNS}" \
            --timeout-ms "${DESKTOP_MEMORY_TIMEOUT_MS}" \
            --settle-ms "${DESKTOP_MEMORY_SETTLE_MS}" \
            --json perf-artifacts/desktop-memory-metrics.json \
            --allow-ci 2>&1 | tee perf-artifacts/desktop-memory.log

      - name: Summarize + merge perf artifacts
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p perf-artifacts
          node - <<'NODE'
           const fs = require("node:fs");
           const path = require("node:path");
           const { execSync } = require("node:child_process");
           
           function readJsonMaybe(p) {
            try {
              return JSON.parse(fs.readFileSync(p, "utf8"));
            } catch {
              return null;
             }
           }

           function tryExec(command) {
             try {
               return execSync(command, { encoding: "utf8" }).trim();
             } catch {
               return null;
             }
           }

           function compareDottedVersions(a, b) {
             // Descending sort helper for strings like "123.0.4567.89".
             const pa = String(a).split(".").map((x) => Number(x));
             const pb = String(b).split(".").map((x) => Number(x));
             const len = Math.max(pa.length, pb.length);
             for (let i = 0; i < len; i += 1) {
               const av = Number.isFinite(pa[i]) ? pa[i] : 0;
               const bv = Number.isFinite(pb[i]) ? pb[i] : 0;
               if (av !== bv) return bv - av;
             }
             return 0;
           }

           function detectWebview() {
             try {
               if (process.platform === "linux") {
                 const version =
                   tryExec("pkg-config --modversion webkit2gtk-4.1 2>/dev/null") ??
                   tryExec("pkg-config --modversion webkit2gtk-4.0 2>/dev/null");
                 return { engine: "webkitgtk", version };
               }
               if (process.platform === "darwin") {
                 const plist =
                   "/System/Library/Frameworks/WebKit.framework/Versions/A/Resources/Info.plist";
                 const version =
                   tryExec(`plutil -extract CFBundleShortVersionString raw -o - ${plist} 2>/dev/null`) ??
                   tryExec(`defaults read ${plist} CFBundleShortVersionString 2>/dev/null`);
                 return { engine: "wkwebview", version };
               }
               if (process.platform === "win32") {
                 const roots = [
                   process.env["ProgramFiles(x86)"]
                     ? path.join(process.env["ProgramFiles(x86)"], "Microsoft", "EdgeWebView", "Application")
                     : null,
                   process.env.ProgramFiles
                     ? path.join(process.env.ProgramFiles, "Microsoft", "EdgeWebView", "Application")
                     : null,
                   process.env.LOCALAPPDATA
                     ? path.join(process.env.LOCALAPPDATA, "Microsoft", "EdgeWebView", "Application")
                     : null,
                 ].filter(Boolean);
                 for (const root of roots) {
                   try {
                     const entries = fs.readdirSync(root, { withFileTypes: true });
                     const versions = entries
                       .filter((e) => e.isDirectory() && /^\d+\.\d+\.\d+\.\d+$/.test(e.name))
                       .map((e) => e.name)
                       .sort(compareDottedVersions);
                     if (versions.length > 0) {
                       return { engine: "webview2", version: versions[0], rootDir: root };
                     }
                   } catch {
                     // ignore
                   }
                 }
                 return { engine: "webview2", version: null };
               }
             } catch {
               // ignore
             }
             return null;
           }
           
           const startupColdPath = path.resolve("perf-artifacts/desktop-startup-metrics-cold.json");
           const startupWarmPath = path.resolve("perf-artifacts/desktop-startup-metrics-warm.json");
           const memoryPath = path.resolve("perf-artifacts/desktop-memory-metrics.json");
           const startupCold = readJsonMaybe(startupColdPath);
           const startupWarm = readJsonMaybe(startupWarmPath);
           const idleMemory = readJsonMaybe(memoryPath);
           const webview = detectWebview();
           
           const merged = {
             generatedAt: new Date().toISOString(),
             ci: {
               workflow: process.env.GITHUB_WORKFLOW || null,
              runId: process.env.GITHUB_RUN_ID || null,
              runNumber: process.env.GITHUB_RUN_NUMBER || null,
              attempt: process.env.GITHUB_RUN_ATTEMPT || null,
              job: process.env.GITHUB_JOB || null,
            },
            git: { sha: process.env.GITHUB_SHA || null, ref: process.env.GITHUB_REF || null },
            runner: {
              os: process.env.RUNNER_OS || null,
              arch: process.env.RUNNER_ARCH || null,
              name: process.env.RUNNER_NAME || null,
            },
            image: {
              os: process.env.ImageOS || null,
              version: process.env.ImageVersion || null,
              name: process.env.ImageName || null,
            },
             toolchain: {
               node: process.version,
               pnpm: tryExec("pnpm --version"),
               rustc: tryExec("rustc --version"),
               cargo: tryExec("cargo --version"),
               wasmPack: tryExec("wasm-pack --version"),
             },
             webview,
             startupCold,
             startupWarm,
             idleMemory,
           };
           
          fs.writeFileSync(
            path.resolve("perf-artifacts/desktop-perf-metrics.json"),
            JSON.stringify(merged, null, 2),
            "utf8",
          );
          
          const summaryPath = process.env.GITHUB_STEP_SUMMARY;
          if (!summaryPath) process.exit(0);
          
          function fmt(n, digits = 1) {
            if (typeof n !== "number" || !Number.isFinite(n)) return "n/a";
            return n.toFixed(digits);
          }
          
           const lines = [];
           lines.push(`## Desktop perf summary (${process.env.RUNNER_OS ?? "unknown"})`);
           if (process.env.ImageOS || process.env.ImageVersion) {
             lines.push(`Runner image: \`${process.env.ImageOS ?? "n/a"}\` \`${process.env.ImageVersion ?? ""}\``);
           }
           if (webview?.engine) {
             lines.push(
               `WebView: \`${webview.engine}\`${webview.version ? ` \`${webview.version}\`` : ""}`,
             );
           }
           lines.push("");
           lines.push("| Metric | p50 | p95 | Notes |");
           lines.push("|---|---:|---:|---|");
          
          if (startupCold?.summary) {
            const s = startupCold.summary;
            lines.push(
              `| startup.cold.windowVisible (ms) | ${fmt(s.windowVisible?.p50)} | ${fmt(s.windowVisible?.p95)} | target=${s.windowVisible?.targetMs ?? "n/a"} enforced=${s.enforce ? 1 : 0} |`,
            );
            lines.push(
              `| startup.cold.firstRender (ms) | ${fmt(s.firstRender?.p50)} | ${fmt(s.firstRender?.p95)} | |`,
            );
            lines.push(
              `| startup.cold.webviewLoaded (ms) | ${fmt(s.webviewLoaded?.p50)} | ${fmt(s.webviewLoaded?.p95)} | target=${s.webviewLoaded?.targetMs ?? "n/a"} |`,
            );
            lines.push(
              `| startup.cold.tti (ms) | ${fmt(s.tti?.p50)} | ${fmt(s.tti?.p95)} | target=${s.tti?.targetMs ?? "n/a"} enforced=${s.enforce ? 1 : 0} |`,
            );
          } else {
            lines.push("| startup.cold | n/a | n/a | missing desktop-startup-metrics-cold.json |");
          }

          if (startupWarm?.summary) {
            const s = startupWarm.summary;
            lines.push(
              `| startup.warm.windowVisible (ms) | ${fmt(s.windowVisible?.p50)} | ${fmt(s.windowVisible?.p95)} | target=${s.windowVisible?.targetMs ?? "n/a"} enforced=${s.enforce ? 1 : 0} |`,
            );
            lines.push(
              `| startup.warm.firstRender (ms) | ${fmt(s.firstRender?.p50)} | ${fmt(s.firstRender?.p95)} | |`,
            );
            lines.push(
              `| startup.warm.webviewLoaded (ms) | ${fmt(s.webviewLoaded?.p50)} | ${fmt(s.webviewLoaded?.p95)} | target=${s.webviewLoaded?.targetMs ?? "n/a"} |`,
            );
            lines.push(
              `| startup.warm.tti (ms) | ${fmt(s.tti?.p50)} | ${fmt(s.tti?.p95)} | target=${s.tti?.targetMs ?? "n/a"} enforced=${s.enforce ? 1 : 0} |`,
            );
          } else {
            lines.push("| startup.warm | n/a | n/a | missing desktop-startup-metrics-warm.json |");
          }
          
          if (idleMemory?.summary) {
            const m = idleMemory.summary;
            lines.push(
              `| idleMemory.rss (mb) | ${fmt(m.rssMb?.p50, 1)} | ${fmt(m.rssMb?.p95, 1)} | settleMs=${idleMemory.settleMs ?? "n/a"} kind=${idleMemory.measurement ?? "rss"} |`,
            );
          } else {
            lines.push("| idleMemory | n/a | n/a | missing desktop-memory-metrics.json |");
          }
          
          lines.push("");
          fs.appendFileSync(summaryPath, lines.join("\n") + "\n", "utf8");
          NODE

      - name: Upload desktop perf artifacts
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v4
        with:
          name: desktop-perf-${{ matrix.os }}
          if-no-files-found: warn
          path: |
            perf-artifacts/*.json
            perf-artifacts/*.log

      - name: Fail job if perf runners failed
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          failed=0
          if [ "${{ steps.startup-cold.outcome }}" != "success" ]; then
            echo "::error::desktop startup cold runner failed (outcome=${{ steps.startup-cold.outcome }})"
            failed=1
          fi
          if [ "${{ steps.startup-warm.outcome }}" != "success" ]; then
            echo "::error::desktop startup warm runner failed (outcome=${{ steps.startup-warm.outcome }})"
            failed=1
          fi
          if [ "${{ steps.memory.outcome }}" != "success" ]; then
            echo "::error::desktop memory runner failed (outcome=${{ steps.memory.outcome }})"
            failed=1
          fi
          exit "$failed"

  merge:
    name: Desktop perf summary (all OS)
    needs: desktop-perf
    # Avoid spending compute on scheduled runs in forks.
    if: (github.event_name != 'schedule' || github.repository == 'wilson-anysphere/formula') && always()
    runs-on: ubuntu-24.04
    permissions:
      contents: read
      actions: read
    steps:
      - name: Setup Node
        uses: actions/setup-node@6044e13b5dc448c55e2357c09f80417699197238 # v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Download per-OS perf artifacts
        continue-on-error: true
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v4
        with:
          pattern: desktop-perf-*
          path: artifacts/desktop-perf

      - name: Merge metrics + write summary
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p merged
          node - <<'NODE'
          const fs = require("node:fs");
          const path = require("node:path");
          
          function readJsonMaybe(p) {
            try {
              return JSON.parse(fs.readFileSync(p, "utf8"));
            } catch {
              return null;
            }
          }
          
          function fmt(n, digits = 1) {
            if (typeof n !== "number" || !Number.isFinite(n)) return "n/a";
            return n.toFixed(digits);
          }
          
          const artifactsRoot = path.resolve("artifacts/desktop-perf");
          const entries = fs.existsSync(artifactsRoot)
            ? fs.readdirSync(artifactsRoot, { withFileTypes: true }).filter((e) => e.isDirectory()).map((e) => e.name)
            : [];
          
          /** @type {Record<string, any>} */
          const byArtifact = {};
          for (const name of entries) {
            const p = path.join(artifactsRoot, name, "perf-artifacts", "desktop-perf-metrics.json");
            byArtifact[name] = readJsonMaybe(p);
          }
          
           const merged = {
             generatedAt: new Date().toISOString(),
             ci: {
               workflow: process.env.GITHUB_WORKFLOW ?? null,
               runId: process.env.GITHUB_RUN_ID ?? null,
              runNumber: process.env.GITHUB_RUN_NUMBER ?? null,
              attempt: process.env.GITHUB_RUN_ATTEMPT ?? null,
            },
            git: { sha: process.env.GITHUB_SHA ?? null, ref: process.env.GITHUB_REF ?? null },
             artifacts: byArtifact,
           };
           
           fs.writeFileSync(path.resolve("merged/desktop-perf-platform-matrix.json"), JSON.stringify(merged, null, 2), "utf8");

          const rows = [
            { label: "Linux", artifact: "desktop-perf-ubuntu-24.04" },
            { label: "Windows", artifact: "desktop-perf-windows-2022" },
            { label: "macOS", artifact: "desktop-perf-macos-14" },
          ].map((r) => ({ ...r, data: byArtifact[r.artifact] ?? null }));

          // Convert key p95 metrics into benchmark-action format for long-term trending (gh-pages).
          // Keep metric names stable once published.
          const bench = [];
          function pushMetric(name, unit, value) {
            if (typeof value !== "number" || !Number.isFinite(value)) return;
            bench.push({ name, unit, value });
          }
          for (const row of rows) {
            const os = String(row.label).trim().toLowerCase();
            const cold = row.data?.startupCold?.summary ?? null;
            const warm = row.data?.startupWarm?.summary ?? null;
            const mem = row.data?.idleMemory?.summary ?? null;
            pushMetric(`desktop.platform.${os}.startup.cold.window_visible_ms.p95`, "ms", cold?.windowVisible?.p95);
            pushMetric(`desktop.platform.${os}.startup.cold.tti_ms.p95`, "ms", cold?.tti?.p95);
            pushMetric(`desktop.platform.${os}.startup.warm.window_visible_ms.p95`, "ms", warm?.windowVisible?.p95);
            pushMetric(`desktop.platform.${os}.startup.warm.tti_ms.p95`, "ms", warm?.tti?.p95);
            if (os === "windows") {
              pushMetric(`desktop.platform.${os}.memory.idle_working_set_mb.p95`, "mb", mem?.rssMb?.p95);
            } else {
              pushMetric(`desktop.platform.${os}.memory.idle_rss_mb.p95`, "mb", mem?.rssMb?.p95);
            }
          }
          fs.writeFileSync(
            path.resolve("merged/benchmark-results.desktop-perf-platform-matrix.json"),
            JSON.stringify(bench, null, 2),
            "utf8",
          );
           
           const summaryPath = process.env.GITHUB_STEP_SUMMARY;
           if (!summaryPath) process.exit(0);
          
          const lines = [];
          lines.push("## Desktop perf summary (all OS)");
          lines.push("");
          lines.push(`- Commit: \`${process.env.GITHUB_SHA ?? "n/a"}\``);
          lines.push(`- Run: https://github.com/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID}`);
          lines.push("");
          
          lines.push("### WebView runtime");
          lines.push("");
          lines.push("| OS | engine | version |");
          lines.push("|---|---|---|");
          for (const row of rows) {
            const w = row.data?.webview ?? null;
            lines.push(`| ${row.label} | \`${w?.engine ?? "n/a"}\` | \`${w?.version ?? "n/a"}\` |`);
          }
          lines.push("");
          
          lines.push("### Startup (p95, ms)");
          lines.push("");
          lines.push("| OS | cold windowVisible | cold tti | warm windowVisible | warm tti |");
          lines.push("|---|---:|---:|---:|---:|");
          for (const row of rows) {
            const cold = row.data?.startupCold?.summary ?? null;
            const warm = row.data?.startupWarm?.summary ?? null;
            lines.push(
              `| ${row.label} | ${fmt(cold?.windowVisible?.p95, 0)} | ${fmt(cold?.tti?.p95, 0)} | ${fmt(warm?.windowVisible?.p95, 0)} | ${fmt(warm?.tti?.p95, 0)} |`,
            );
          }
          lines.push("");
          
          lines.push("### Idle memory (p95, MB)");
          lines.push("");
          lines.push("| OS | kind | idle memory |");
          lines.push("|---|---|---:|");
          for (const row of rows) {
            const mem = row.data?.idleMemory ?? null;
            const kind = mem?.measurement ?? "rss";
            const p95 = mem?.summary?.rssMb?.p95;
            lines.push(`| ${row.label} | \`${kind}\` | ${fmt(p95, 1)} |`);
          }
          lines.push("");
          
          fs.appendFileSync(summaryPath, lines.join("\n") + "\n", "utf8");
          NODE

      - name: Upload merged desktop perf metrics
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v4
        with:
          name: desktop-perf-platform-matrix
          if-no-files-found: warn
          path: |
            merged/desktop-perf-platform-matrix.json
            merged/benchmark-results.desktop-perf-platform-matrix.json

  publish:
    name: Publish desktop perf platform matrix history (gh-pages)
    # Only the merged artifact is required. Keeping this job independent of the full matrix result
    # lets scheduled runs publish partial data (e.g. if a single OS runner flakes).
    needs: merge
    runs-on: ubuntu-24.04
    timeout-minutes: 10
    concurrency:
      # Avoid concurrent gh-pages pushes from multiple benchmark workflows.
      group: benchmark-gh-pages-publish
      cancel-in-progress: false
    permissions:
      actions: read
      contents: write
    # Only scheduled runs on main should update gh-pages history.
    if: github.repository == 'wilson-anysphere/formula' && github.ref == 'refs/heads/main' && github.event_name == 'schedule' && needs.merge.result == 'success'
    steps:
      - name: Checkout
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v4

      - name: Download merged perf summary artifact
        continue-on-error: true
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v4
        with:
          name: desktop-perf-platform-matrix
          path: artifacts/desktop-perf-platform-matrix

      - name: Check benchmark results (skip publish when empty)
        id: bench
        shell: bash
        run: |
          set -euo pipefail
          path="artifacts/desktop-perf-platform-matrix/merged/benchmark-results.desktop-perf-platform-matrix.json"
          if [ ! -f "$path" ]; then
            echo "::notice::Missing ${path}; skipping gh-pages publish."
            echo "publish=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          if ! count="$(node -e 'const fs=require(\"fs\");const p=process.argv[1];const v=JSON.parse(fs.readFileSync(p,\"utf8\"));console.log(Array.isArray(v)?v.length:0);' "$path")"; then
            echo "::notice::Failed to parse ${path}; skipping gh-pages publish."
            echo "publish=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          if ! [[ "$count" =~ ^[0-9]+$ ]] || [ "$count" -lt 1 ]; then
            echo "::notice::Benchmark results file is empty; skipping gh-pages publish."
            echo "publish=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          echo "publish=true" >> "$GITHUB_OUTPUT"

      - name: Publish benchmark results (non-gating)
        if: steps.bench.outputs.publish == 'true'
        continue-on-error: true
        uses: benchmark-action/github-action-benchmark@4bdcce38c94cec68da58d012ac24b7b1155efe8b # v1
        with:
          tool: customSmallerIsBetter
          output-file-path: artifacts/desktop-perf-platform-matrix/merged/benchmark-results.desktop-perf-platform-matrix.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          alert-threshold: '120%'
          comment-on-alert: false
          fail-on-alert: false
