name: Desktop Release

# NOTE: Third-party GitHub Actions are pinned to an immutable commit SHA for
# supply-chain hardening. To update, pick the desired upstream tag (same major
# version), resolve it to a commit with `git ls-remote <repo> <tag> <tag>^{}`,
# then replace the SHA below and update the trailing comment.

on:
  push:
    tags:
      - "v*"
  workflow_dispatch:
    inputs:
      tag:
        description: "Git tag to use for the release (optional). Example: v0.2.3"
        required: false
        type: string
      version:
        description: "Version label for artifacts (optional). Example: 0.2.3"
        required: false
        type: string
      upload:
        description: "If true, create/update a draft GitHub Release and attach assets. If false, upload bundles as workflow artifacts."
        required: false
        type: boolean
        default: false
      windows_timestamp_url:
        description: "Override Windows Authenticode timestamp server URL for this run (optional; must be https://). Example: https://timestamp.digicert.com"
        required: false
        type: string

permissions:
  contents: read

# Prevent multiple runs for the same tag/ref from racing while uploading GitHub Release
# assets (including Tauri updater manifests like `latest.json`). Without this,
# manual re-runs or tag updates can overlap and clobber/partially overwrite the
# release asset set.
concurrency:
  # For `workflow_dispatch`, `github.ref` is the branch the workflow is run from, but the release
  # tag may come from inputs. Key concurrency off the *effective* release tag when we're actually
  # uploading to a GitHub Release (`upload=true`) so dispatch release runs for a given tag can't
  # overlap with the corresponding tag push run.
  #
  # NOTE: `github.event.inputs.*` may be empty/undefined for optional inputs, so guard `startsWith`
  # with truthy checks to avoid evaluation errors.
  #
  # In dry-run mode (`upload=false`), fall back to the branch ref so dry runs don't block releases.
  group: desktop-release-${{ github.event_name == 'workflow_dispatch' && github.event.inputs.upload == 'true' && ((github.event.inputs.tag && (startsWith(github.event.inputs.tag, 'refs/tags/') && github.event.inputs.tag || (startsWith(github.event.inputs.tag, 'v') && format('refs/tags/{0}', github.event.inputs.tag) || format('refs/tags/v{0}', github.event.inputs.tag)))) || (github.event.inputs.version && (startsWith(github.event.inputs.version, 'refs/tags/') && github.event.inputs.version || (startsWith(github.event.inputs.version, 'v') && format('refs/tags/{0}', github.event.inputs.version) || format('refs/tags/v{0}', github.event.inputs.version)))) || github.ref) || github.ref }}
  cancel-in-progress: false

env:
  # Keep release builds on the same Node.js major as CI (see ci.yml) to avoid
  # "works in CI, breaks in release" drift.
  NODE_VERSION: 22
  # Pin wasm-pack for reproducible tagged releases (avoid `cargo install wasm-pack`
  # pulling newer incompatible versions). Keep this in sync with ci.yml/perf.yml.
  WASM_PACK_VERSION: 0.13.1
  # Pin the Tauri CLI (`cargo tauri`) version used by release builds so the toolchain
  # can't drift independently from the repo's pinned Tauri crates.
  #
  # Keep this in sync with:
  # - apps/desktop/src-tauri/Cargo.toml (tauri = "2.9")
  # - docs/release.md (local release prep instructions)
  TAURI_CLI_VERSION: "2.9.5"
  # Opt-in: bundle Pyodide assets into `apps/desktop/dist` (otherwise Pyodide is downloaded
  # on-demand at runtime and cached in the app data directory).
  FORMULA_BUNDLE_PYODIDE_ASSETS: ${{ vars.FORMULA_BUNDLE_PYODIDE_ASSETS }}

jobs:
  conflict-marker-guard:
    name: "Guard: no merge conflict markers"
    permissions:
      contents: read
    # Pinned runner images keep release workflows deterministic and avoid breakages
    # when GitHub updates the default `*-latest` hosted runner images. Update
    # these pins deliberately after validating the newer runner images (recommended:
    # run this workflow via workflow_dispatch with upload=false).
    # See https://github.com/actions/runner-images for available images and deprecation notices.
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
      - name: Fail if merge conflict markers are present
        run: bash scripts/ci/check-merge-conflict-markers.sh
      - name: "Guard: release workflow runner images are pinned (no *-latest)"
        run: bash scripts/ci/check-gha-runner-pins.sh
      - name: "Guard: release workflow actions are pinned to commit SHAs"
        run: bash scripts/ci/check-gha-action-sha-pins.sh
      - name: "Guard: Rust toolchain pins match rust-toolchain.toml"
        run: bash scripts/ci/check-rust-toolchain-pins.sh
      - name: "Guard: Node version pins match CI workflow"
        run: bash scripts/ci/check-node-version-pins.sh
      - name: "Guard: pnpm version pins match package.json + CI workflow"
        run: bash scripts/ci/check-pnpm-version-pins.sh
      - name: "Guard: wasm-pack version pins match CI workflow"
        run: bash scripts/ci/check-wasm-pack-version-pins.sh
      - name: "Guard: Tauri CLI version pins match CI workflow"
        run: bash scripts/ci/check-tauri-cli-version-pins.sh

  preflight:
    name: Preflight validations
    needs: conflict-marker-guard
    permissions:
      contents: read
      actions: read
    runs-on: ubuntu-24.04
    outputs:
      upload: ${{ steps.params.outputs.upload }}
      release_tag: ${{ steps.params.outputs.release_tag }}
      artifact_label: ${{ steps.params.outputs.artifact_label }}
      should_validate_version: ${{ steps.params.outputs.should_validate_version }}
      windows_timestamp_url: ${{ steps.params.outputs.windows_timestamp_url }}
    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

      - name: Compute release parameters
        id: params
        shell: bash
        env:
          EVENT_NAME: ${{ github.event_name }}
          REF_NAME: ${{ github.ref_name }}
          INPUT_TAG: ${{ github.event.inputs.tag }}
          INPUT_VERSION: ${{ github.event.inputs.version }}
          INPUT_UPLOAD: ${{ github.event.inputs.upload }}
          INPUT_WINDOWS_TIMESTAMP_URL: ${{ github.event.inputs.windows_timestamp_url }}
        run: |
          set -euo pipefail

          # Defaults:
          upload="false"
          release_tag=""
          windows_timestamp_url=""

          # Derive the release tag / artifact label.
          if [[ "${EVENT_NAME}" == "push" ]]; then
            upload="true"
            release_tag="${REF_NAME}"
            artifact_label="${REF_NAME}"
          else
            # workflow_dispatch
            if [[ "${INPUT_UPLOAD:-}" == "true" ]]; then
              upload="true"
            fi

            tag="${INPUT_TAG:-}"
            version="${INPUT_VERSION:-}"
            windows_timestamp_url="${INPUT_WINDOWS_TIMESTAMP_URL:-}"

            # Some users may paste full ref names. Normalize to a bare tag/version string.
            tag="${tag#refs/tags/}"
            version="${version#refs/tags/}"
            windows_timestamp_url="${windows_timestamp_url#refs/tags/}"
            # Strip common whitespace/newlines from the URL input (copy/paste hygiene).
            windows_timestamp_url="$(echo "${windows_timestamp_url}" | tr -d '\r\n' | xargs || true)"

            if [[ -n "${tag}" ]]; then
              if [[ "${tag}" == v* ]]; then
                release_tag="${tag}"
              else
                release_tag="v${tag}"
              fi
              artifact_label="${release_tag}"
            elif [[ -n "${version}" ]]; then
              # `version` is primarily for labeling dry-run artifacts. When `upload=true`, we
              # still need a GitHub Release tag, so we normalize it to a `v*` tag.
              artifact_label="${version}"
              if [[ "${version}" == v* ]]; then
                release_tag="${version}"
              else
                release_tag="v${version}"
              fi
            else
              short_sha="$(echo "${GITHUB_SHA}" | cut -c1-7)"
              artifact_label="manual-${short_sha}"
            fi

            if [[ "${upload}" == "true" && -z "${release_tag}" ]]; then
              echo "error: upload=true requires either the 'tag' or 'version' workflow input." >&2
              exit 1
            fi
          fi

          should_validate_version="false"
          if [[ "${EVENT_NAME}" == "push" || "${upload}" == "true" ]]; then
            should_validate_version="true"
          fi

          # Artifact names should be safe as directory/file-ish identifiers. GitHub allows many
          # characters, but keep it simple for consumers and avoid surprises.
          artifact_label_sanitized="$(echo "${artifact_label}" | sed -E 's/[^A-Za-z0-9._-]+/-/g; s/^-+//; s/-+$//')"
          if [[ -z "${artifact_label_sanitized}" ]]; then
            artifact_label_sanitized="manual-$(echo "${GITHUB_SHA}" | cut -c1-7)"
          fi

          echo "upload=${upload}" >> "${GITHUB_OUTPUT}"
          echo "release_tag=${release_tag}" >> "${GITHUB_OUTPUT}"
          echo "artifact_label=${artifact_label_sanitized}" >> "${GITHUB_OUTPUT}"
          echo "should_validate_version=${should_validate_version}" >> "${GITHUB_OUTPUT}"
          echo "windows_timestamp_url=${windows_timestamp_url}" >> "${GITHUB_OUTPUT}"

      - name: "Guard: tag must be on main"
        if: steps.params.outputs.upload == 'true'
        shell: bash
        run: |
          set -euo pipefail
          git fetch origin main --depth=1

          if git merge-base --is-ancestor "$GITHUB_SHA" origin/main; then
            exit 0
          fi

          # In a shallow checkout, `origin/main` may not include enough history to
          # prove the tagged commit is reachable. Fetch full main history and retry.
          git fetch --unshallow origin main 2>/dev/null || git fetch origin main --depth=1000000

          if ! git merge-base --is-ancestor "$GITHUB_SHA" origin/main; then
            echo "::error::Releases must be tagged from the main branch. Commit $GITHUB_SHA is not reachable from origin/main."
            exit 1
          fi

      - name: Setup Node
        uses: actions/setup-node@6044e13b5dc448c55e2357c09f80417699197238 # v6.2.0
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Verify tagged commit has successful CI run
        if: steps.params.outputs.upload == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: node scripts/check-tag-ci-status.mjs --sha "${{ github.sha }}" --workflow "CI"

      - name: Check pinned Tauri CLI version matches Tauri crates
        run: node scripts/ci/check-tauri-cli-version.mjs

      - name: Check desktop version matches release tag
        if: steps.params.outputs.should_validate_version == 'true'
        run: node scripts/check-desktop-version.mjs "${{ steps.params.outputs.release_tag }}"

      - name: Validate desktop compliance artifact bundling config (LICENSE/NOTICE)
        run: node scripts/ci/check-desktop-compliance-artifacts.mjs

      - name: Validate Tauri updater config
        run: node scripts/check-updater-config.mjs

      - name: Validate Tauri updater signing secrets
        # Only enforce when we're publishing to a GitHub Release (tag push or workflow_dispatch upload=true),
        # and we have a reason to require updater signing:
        # - always in the upstream repo (wilson-anysphere/formula)
        # - on forks only when the user configured their own updater key secrets
        #
        # If plugins.updater.active=true but updater signing secrets are missing, the release would upload
        # unsigned updater metadata (missing `latest.json.sig`) and auto-update would not work.
        if: steps.params.outputs.upload == 'true' && (github.repository == 'wilson-anysphere/formula' || secrets.TAURI_PRIVATE_KEY != '')
        run: node scripts/ci/check-tauri-updater-secrets.mjs
        env:
          TAURI_PRIVATE_KEY: ${{ secrets.TAURI_PRIVATE_KEY }}
          TAURI_KEY_PASSWORD: ${{ secrets.TAURI_KEY_PASSWORD }}

      - name: Validate desktop URL scheme registration metadata (formula://)
        run: node scripts/check-desktop-url-scheme.mjs

      - name: Validate Windows WebView2 installer configuration
        run: node scripts/ci/check-webview2-install-mode.mjs

      - name: Validate Windows Authenticode timestamp URL (HTTPS)
        run: node scripts/ci/check-windows-timestamp-url.mjs
        env:
          FORMULA_WINDOWS_TIMESTAMP_URL: ${{ steps.params.outputs.windows_timestamp_url }}

      - name: Validate Windows downgrade / rollback support (allowDowngrades)
        run: node scripts/ci/check-windows-allow-downgrades.mjs

      - name: Validate WiX upgradeCode is pinned (stable MSI upgrades/downgrades)
        run: node scripts/ci/check-windows-wix-upgrade-code.mjs

      # Fail fast (before any platform builds start) if maintainers require code signing or if
      # signing secrets are partially configured. This avoids wasting build time and uploading
      # a partial set of GitHub Release assets.
      - name: "Preflight: warn when APPLE_SIGNING_IDENTITY is missing (recommended)"
        if: secrets.APPLE_CERTIFICATE != '' && secrets.APPLE_SIGNING_IDENTITY == ''
        shell: bash
        run: |
          set -euo pipefail
          echo "::warning::APPLE_CERTIFICATE is configured but APPLE_SIGNING_IDENTITY is missing. CI will fall back to the generic \"Developer ID Application\" selector, which can be ambiguous if multiple certificates exist. Set APPLE_SIGNING_IDENTITY (e.g. \"Developer ID Application: Your Company (TEAMID)\") for deterministic signing."

      - name: "Preflight: verify macOS code signing secrets (base64 + PKCS#12)"
        if: secrets.APPLE_CERTIFICATE != '' || vars.FORMULA_REQUIRE_CODESIGN == '1'
        shell: bash
        env:
          FORMULA_REQUIRE_CODESIGN: ${{ vars.FORMULA_REQUIRE_CODESIGN }}
          APPLE_CERTIFICATE: ${{ secrets.APPLE_CERTIFICATE }}
          APPLE_CERTIFICATE_PASSWORD: ${{ secrets.APPLE_CERTIFICATE_PASSWORD }}
        run: bash scripts/ci/verify-codesign-secrets.sh macos

      - name: "Preflight: verify Windows code signing secrets (base64 + PKCS#12)"
        if: secrets.WINDOWS_CERTIFICATE != '' || vars.FORMULA_REQUIRE_CODESIGN == '1'
        shell: bash
        env:
          FORMULA_REQUIRE_CODESIGN: ${{ vars.FORMULA_REQUIRE_CODESIGN }}
          WINDOWS_CERTIFICATE: ${{ secrets.WINDOWS_CERTIFICATE }}
          WINDOWS_CERTIFICATE_PASSWORD: ${{ secrets.WINDOWS_CERTIFICATE_PASSWORD }}
        run: bash scripts/ci/verify-codesign-secrets.sh windows

      - name: "Preflight: require macOS notarization creds when FORMULA_REQUIRE_CODESIGN=1"
        if: vars.FORMULA_REQUIRE_CODESIGN == '1'
        shell: bash
        env:
          APPLE_SIGNING_IDENTITY: ${{ secrets.APPLE_SIGNING_IDENTITY }}
          APPLE_ID: ${{ secrets.APPLE_ID }}
          APPLE_PASSWORD: ${{ secrets.APPLE_PASSWORD }}
          APPLE_TEAM_ID: ${{ secrets.APPLE_TEAM_ID }}
        run: |
          set -euo pipefail

          missing=()
          for name in APPLE_SIGNING_IDENTITY APPLE_ID APPLE_PASSWORD APPLE_TEAM_ID; do
            if [[ -z "${!name:-}" ]]; then
              missing+=("$name")
            fi
          done

          if ((${#missing[@]} > 0)); then
            echo "" >&2
            echo "Code signing is required (FORMULA_REQUIRE_CODESIGN=1) but macOS notarization/signing secrets are missing:" >&2
            for m in "${missing[@]}"; do
              echo "  - ${m}" >&2
            done
            echo "" >&2
            echo "Set these in GitHub: Settings → Secrets and variables → Actions → New repository secret." >&2
            echo "See docs/release.md (\"Code signing\")." >&2
            exit 1
          fi

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@e97e2d8cc328f1b50210efc529dca0028893a2d9 # v1
        with:
          toolchain: 1.92.0

      - name: Cache Rust (cargo registry + git) (preflight)
        # Cache restores can fail due to transient GitHub issues or permission settings.
        # Lockfile validation should still run (just slower), so treat caching as best-effort.
        continue-on-error: true
        uses: Swatinem/rust-cache@779680da715d629ac1d338a641029a2f4372abb5 # v2
        with:
          # Keep caches bounded for preflight runs: only cache the Cargo registry/git index to speed
          # up `cargo metadata` lockfile validation on reruns.
          cache-targets: "false"
          cache-bin: "false"
          cache-on-failure: "true"

      - name: Check Cargo.lock is up-to-date (no implicit lockfile updates)
        shell: bash
        run: bash scripts/ci/check-cargo-lock-reproducible.sh

      - name: Fail if preflight modified tracked files
        shell: bash
        run: git diff --exit-code
  build:
    name: Build (${{ matrix.label }})
    needs: preflight
    permissions:
      contents: write
      id-token: write
      attestations: write
    if: needs.preflight.outputs.upload == 'true'
    strategy: &build_strategy
      fail-fast: false
      # NOTE: `tauri-apps/tauri-action` updates shared GitHub Release assets (notably `latest.json`)
      # for the updater. Matrix jobs remain parallel for fast releases; we publish a single combined
      # updater manifest in a dedicated job after all platform builds complete.
      matrix:
        # Pinned runner images keep release workflows deterministic and avoid breakages
        # when GitHub updates the default `*-latest` hosted runner images. Update
        # these pins deliberately after validating the newer runner images (recommended:
        # run this workflow via workflow_dispatch with upload=false).
        # See https://github.com/actions/runner-images for available images and deprecation notices.
        include:
          - platform: macos-14
            label: macos-14
            # The macOS job builds a universal bundle (x86_64 + arm64).
            cache_target: universal-apple-darwin
            cache_features: desktop
            rust_target: ""
            tauri_args: ""
          - platform: ubuntu-24.04
            label: ubuntu-24.04
            cache_target: x86_64-unknown-linux-gnu
            cache_features: desktop
            rust_target: ""
            tauri_args: "--bundles appimage,deb,rpm"
          - platform: ubuntu-24.04-arm64
            label: ubuntu-24.04 (arm64)
            cache_target: aarch64-unknown-linux-gnu
            cache_features: desktop
            rust_target: ""
            tauri_args: "--bundles appimage,deb,rpm"
          - platform: windows-2022
            label: windows-2022 (x64)
            cache_target: x86_64-pc-windows-msvc
            cache_features: desktop
            rust_target: x86_64-pc-windows-msvc
            tauri_args: "--target x86_64-pc-windows-msvc --bundles msi,nsis"
          - platform: windows-2022
            label: windows-2022 (arm64)
            cache_target: aarch64-pc-windows-msvc
            cache_features: desktop
            rust_target: aarch64-pc-windows-msvc
            tauri_args: "--target aarch64-pc-windows-msvc --bundles msi,nsis"

    runs-on: ${{ matrix.platform }}

    steps: &build_steps
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          fetch-depth: 0

      # Ensure all Cargo builds (including `cargo tauri build`) emit artifacts under the
      # expected path `apps/desktop/src-tauri/target/**`. This keeps release assertions
      # deterministic and matches docs/CI checks that look under src-tauri/target.
      - name: Set CARGO_TARGET_DIR for desktop builds (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $targetDir = Join-Path $env:GITHUB_WORKSPACE 'apps/desktop/src-tauri/target'
          "CARGO_TARGET_DIR=$targetDir" | Out-File -FilePath $env:GITHUB_ENV -Append -Encoding utf8

      - name: Set CARGO_TARGET_DIR for desktop builds (Unix)
        if: runner.os != 'Windows'
        shell: bash
        run: echo "CARGO_TARGET_DIR=$GITHUB_WORKSPACE/apps/desktop/src-tauri/target" >> "$GITHUB_ENV"
      - name: Setup pnpm
        uses: pnpm/action-setup@41ff72655975bd51cab0327fa583b6e92b6d3061 # v4.2.0
        with:
          # Pin the pnpm patch version for deterministic tagged-release builds.
          # Keep this in sync with the root package.json `packageManager` field.
          version: 9.0.0

      - name: Setup Node
        uses: actions/setup-node@6044e13b5dc448c55e2357c09f80417699197238 # v6.2.0
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: pnpm
          cache-dependency-path: pnpm-lock.yaml

      - name: Detect Pyodide version (for caching)
        id: pyodide
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1'
        shell: bash
        run: |
          set -euo pipefail
          version="$(node -e "const fs=require('node:fs'); const src=fs.readFileSync('apps/desktop/scripts/ensure-pyodide-assets.mjs','utf8'); const m=src.match(/const\\s+PYODIDE_VERSION\\s*=\\s*['\\\"]([^'\\\"]+)['\\\"]/); if(!m) throw new Error('PYODIDE_VERSION not found'); process.stdout.write(m[1]);")"
          echo "version=${version}" >> "$GITHUB_OUTPUT"

      - name: Restore Pyodide asset cache
        id: pyodide-cache
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1'
        uses: actions/cache/restore@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v5.0.2
        with:
          path: apps/desktop/public/pyodide/v${{ steps.pyodide.outputs.version }}/full/
          key: pyodide-${{ runner.os }}-${{ steps.pyodide.outputs.version }}-${{ hashFiles('apps/desktop/scripts/ensure-pyodide-assets.mjs') }}

      - name: Ensure Pyodide assets are present
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1'
        run: node apps/desktop/scripts/ensure-pyodide-assets.mjs

      - name: Save Pyodide asset cache
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1' && steps.pyodide-cache.outputs.cache-hit != 'true'
        uses: actions/cache/save@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v5.0.2
        with:
          path: apps/desktop/public/pyodide/v${{ steps.pyodide.outputs.version }}/full/
          key: pyodide-${{ runner.os }}-${{ steps.pyodide.outputs.version }}-${{ hashFiles('apps/desktop/scripts/ensure-pyodide-assets.mjs') }}

      - name: Validate macOS entitlements (hardened runtime)
        if: runner.os == 'macOS'
        run: node scripts/check-macos-entitlements.mjs

      # Code signing is optional and frequently unavailable in forks/dry-runs (no repo secrets).
      # When signing secrets are missing, we patch `tauri.conf.json` for this CI run so bundling
      # still succeeds (unsigned artifacts), and we only export notarization env vars when all
      # required credentials are configured.
      #
      # This helper also exports Tauri updater signing env vars (`TAURI_PRIVATE_KEY` /
      # `TAURI_KEY_PASSWORD`) only when configured, so forks/dry-runs don't pass empty secrets into
      # `cargo tauri` / `tauri-action`.
      #
      # When maintainers set FORMULA_REQUIRE_CODESIGN=1, this step switches to enforcement mode and
      # fails early if platform signing secrets are missing.
      - name: Prepare optional Tauri signing config (macOS/Windows)
        run: node scripts/ci/prepare-tauri-signing-config.mjs
        env:
          # Optional: set as a GitHub Actions "Variable" to enforce platform code signing.
          # - FORMULA_REQUIRE_CODESIGN=1 to fail when required signing secrets are missing
          FORMULA_REQUIRE_CODESIGN: ${{ vars.FORMULA_REQUIRE_CODESIGN }}
          # Optional override: allow re-runs to switch timestamp servers without changing the repo.
          FORMULA_WINDOWS_TIMESTAMP_URL: ${{ needs.preflight.outputs.windows_timestamp_url }}

          APPLE_CERTIFICATE: ${{ secrets.APPLE_CERTIFICATE }}
          APPLE_CERTIFICATE_PASSWORD: ${{ secrets.APPLE_CERTIFICATE_PASSWORD }}
          APPLE_SIGNING_IDENTITY: ${{ secrets.APPLE_SIGNING_IDENTITY }}
          APPLE_ID: ${{ secrets.APPLE_ID }}
          APPLE_PASSWORD: ${{ secrets.APPLE_PASSWORD }}
          APPLE_TEAM_ID: ${{ secrets.APPLE_TEAM_ID }}

          WINDOWS_CERTIFICATE: ${{ secrets.WINDOWS_CERTIFICATE }}
          WINDOWS_CERTIFICATE_PASSWORD: ${{ secrets.WINDOWS_CERTIFICATE_PASSWORD }}

          # Optional: Tauri updater signing secrets. Forks/dry-runs often do not configure these,
          # so the helper only exports them to subsequent steps when non-empty.
          TAURI_PRIVATE_KEY: ${{ secrets.TAURI_PRIVATE_KEY }}
          TAURI_KEY_PASSWORD: ${{ secrets.TAURI_KEY_PASSWORD }}

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@e97e2d8cc328f1b50210efc529dca0028893a2d9 # v1
        with:
          toolchain: 1.92.0

      - name: Install Rust targets (WASM)
        run: rustup target add wasm32-unknown-unknown

      - name: Install macOS Rust targets (universal build)
        if: runner.os == 'macOS'
        run: rustup target add x86_64-apple-darwin aarch64-apple-darwin

      - name: Install Rust target (${{ matrix.rust_target }})
        if: matrix.rust_target != ''
        run: rustup target add ${{ matrix.rust_target }}

      - name: Ensure MSVC ARM64 build tools are installed (Windows ARM64)
        if: runner.os == 'Windows' && matrix.rust_target == 'aarch64-pc-windows-msvc'
        id: windows_arm64_toolchain
        shell: pwsh
        run: |
          $ErrorActionPreference = "Stop"
          $vswhere = "${env:ProgramFiles(x86)}\Microsoft Visual Studio\Installer\vswhere.exe"
          if (!(Test-Path $vswhere)) {
            throw "vswhere not found at $vswhere (expected on GitHub-hosted Windows runners)."
          }
          $installPath = & $vswhere -latest -products * -requires Microsoft.VisualStudio.Component.VC.Tools.x86.x64 -property installationPath
          if (!$installPath) {
            throw "Failed to locate a Visual Studio installation via vswhere."
          }
          Write-Host "Visual Studio install path: $installPath"
          $msvcRoot = Join-Path $installPath "VC\Tools\MSVC"
          $msvcVersionDir = Get-ChildItem -Path $msvcRoot -Directory | Sort-Object Name -Descending | Select-Object -First 1
          if (!$msvcVersionDir) {
            throw "MSVC toolset directory not found under $msvcRoot"
          }
          $arm64LibDir = Join-Path $msvcVersionDir.FullName "lib\arm64"
          $arm64BinDir = Join-Path $msvcVersionDir.FullName "bin\Hostx64\arm64"
          $arm64Cl = Join-Path $arm64BinDir "cl.exe"
          $arm64LinkExe = Join-Path $arm64BinDir "link.exe"
          $hasArm64Toolchain = (Test-Path $arm64LibDir) -and (Test-Path $arm64Cl) -and (Test-Path $arm64LinkExe)

          if (-not $hasArm64Toolchain) {
            Write-Host "MSVC ARM64 toolchain not found; installing Visual Studio component Microsoft.VisualStudio.Component.VC.Tools.ARM64"
            $vsInstaller = "${env:ProgramFiles(x86)}\Microsoft Visual Studio\Installer\vs_installer.exe"
            if (!(Test-Path $vsInstaller)) {
              throw "Visual Studio installer not found at $vsInstaller"
            }
            & $vsInstaller modify --installPath $installPath --add Microsoft.VisualStudio.Component.VC.Tools.ARM64 --includeRecommended --passive --norestart
            $exitCode = $LASTEXITCODE
            # 3010 is a common "success, reboot required" code for Windows installers.
            if ($exitCode -ne 0 -and $exitCode -ne 3010) {
              throw "vs_installer.exe failed with exit code $exitCode while installing MSVC ARM64 components."
            }

            $msvcVersionDir = Get-ChildItem -Path $msvcRoot -Directory | Sort-Object Name -Descending | Select-Object -First 1
            $arm64LibDir = Join-Path $msvcVersionDir.FullName "lib\arm64"
            $arm64BinDir = Join-Path $msvcVersionDir.FullName "bin\Hostx64\arm64"
            $arm64Cl = Join-Path $arm64BinDir "cl.exe"
            $arm64LinkExe = Join-Path $arm64BinDir "link.exe"
          }

          if (!(Test-Path $arm64LibDir) -or !(Test-Path $arm64Cl) -or !(Test-Path $arm64LinkExe)) {
            throw "MSVC ARM64 build tools were not found. Expected:\n  - $arm64LibDir\n  - $arm64Cl\n  - $arm64LinkExe\nWindows ARM64 builds require the MSVC ARM64 toolchain to be present on the runner."
          }

          Write-Host "MSVC ARM64 tools present:"
          Write-Host "  - libs: $arm64LibDir"
          Write-Host "  - cl.exe: $arm64Cl"
          Write-Host "  - link.exe: $arm64LinkExe"

          $sdkLibRoot = Join-Path ${env:ProgramFiles(x86)} "Windows Kits\10\Lib"
          if (!(Test-Path $sdkLibRoot)) {
            throw "Windows SDK lib root not found at $sdkLibRoot. Windows ARM64 builds require the Windows 10/11 SDK with ARM64 libraries."
          }

          function Find-SdkArm64($root) {
            $dirs = @(Get-ChildItem -Path $root -Directory -ErrorAction SilentlyContinue | Sort-Object Name -Descending)
            foreach ($dir in $dirs) {
              $um = Join-Path $dir.FullName "um\arm64"
              $ucrt = Join-Path $dir.FullName "ucrt\arm64"
              if ((Test-Path $um) -and (Test-Path $ucrt)) {
                return [pscustomobject]@{ VersionDir = $dir; Um = $um; Ucrt = $ucrt; AllDirs = $dirs }
              }
            }
            return [pscustomobject]@{ VersionDir = $null; Um = $null; Ucrt = $null; AllDirs = $dirs }
          }

          $sdkInfo = Find-SdkArm64 $sdkLibRoot
          if (-not $sdkInfo.AllDirs -or $sdkInfo.AllDirs.Count -eq 0) {
            throw "No Windows SDK lib versions found under $sdkLibRoot. Windows ARM64 builds require a Windows SDK installation with ARM64 libraries."
          }

          if (-not $sdkInfo.VersionDir) {
            # Some runner images can have the Windows SDK installed without the ARM64 lib subset.
            # Attempt to add the matching Windows 10 SDK component via the Visual Studio installer.
            $candidateName = $sdkInfo.AllDirs[0].Name
            $sdkBuild = $null
            if ($candidateName -match '^10\.0\.(\d+)\.\d+$') {
              $sdkBuild = $Matches[1]
            }
            if (-not $sdkBuild) {
              # Reasonable fallback for windows-2022 images (10.0.20348.0).
              $sdkBuild = "20348"
            }

            $sdkComponents = @(
              "Microsoft.VisualStudio.Component.Windows10SDK.$sdkBuild",
              "Microsoft.VisualStudio.Component.Windows11SDK.$sdkBuild"
            ) | Select-Object -Unique
            Write-Host "Windows SDK ARM64 libs not found; attempting to install one of:"
            $sdkComponents | ForEach-Object { Write-Host "  - $_" }
            $vsInstaller = "${env:ProgramFiles(x86)}\Microsoft Visual Studio\Installer\vs_installer.exe"
            if (!(Test-Path $vsInstaller)) {
              throw "Visual Studio installer not found at $vsInstaller"
            }
            $installErrors = @()
            foreach ($sdkComponent in $sdkComponents) {
              Write-Host "Installing Windows SDK component: $sdkComponent"
              & $vsInstaller modify --installPath $installPath --add $sdkComponent --includeRecommended --passive --norestart
              $exitCode = $LASTEXITCODE
              # 3010 is a common "success, reboot required" code for Windows installers.
              if ($exitCode -ne 0 -and $exitCode -ne 3010) {
                $installErrors += "$sdkComponent (exit code $exitCode)"
                continue
              }
              $sdkInfo = Find-SdkArm64 $sdkLibRoot
              if ($sdkInfo.VersionDir) {
                break
              }
            }

            if (-not $sdkInfo.VersionDir -and $installErrors.Count -gt 0) {
              Write-Host "Windows SDK component install attempts failed:"
              $installErrors | ForEach-Object { Write-Host "  - $_" }
            }
          }

          if (-not $sdkInfo.VersionDir) {
            throw "Windows SDK ARM64 UM/UCRT libraries were not found under $sdkLibRoot. The runner image may be missing the Windows SDK ARM64 components."
          }

          $sdkVersionDir = $sdkInfo.VersionDir
          $sdkUmArm64 = $sdkInfo.Um
          $sdkUcrtArm64 = $sdkInfo.Ucrt

          # Ensure downstream MSVC environment setup uses a Windows SDK version that actually
          # includes ARM64 libraries. Some runner images can have multiple SDK versions installed,
          # and the newest one may be missing the arm64 lib subset. We pin `ilammy/msvc-dev-cmd`
          # to the discovered version so `LIB`/`INCLUDE` resolve correctly during cross-compiles.
          if ($env:GITHUB_OUTPUT) {
            "sdk_version=$($sdkVersionDir.Name)" | Out-File -FilePath $env:GITHUB_OUTPUT -Append -Encoding utf8
          }

          Write-Host "windows-arm64-toolchain: OK"
          Write-Host " - MSVC: $($msvcVersionDir.FullName)"
          Write-Host " - link.exe: $arm64LinkExe"
          Write-Host " - MSVC lib: $arm64LibDir"
          Write-Host " - SDK um/arm64: $sdkUmArm64"
          Write-Host " - SDK ucrt/arm64: $sdkUcrtArm64"

      - name: Setup Python
        uses: actions/setup-python@83679a892e2d95755f2dac6acb0bfd1e9ac5d548 # v6.1.0
        with:
          python-version: "3.11"

      # Our dev scripts default to a repo-local CARGO_HOME to avoid cross-agent
      # contention on shared ~/.cargo. In GitHub Actions we prefer the default
      # CARGO_HOME so cargo installs/builds share the same cache.
      - name: Use shared Cargo home for CI caching (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $cargoHome = Join-Path $env:USERPROFILE ".cargo"
          "CARGO_HOME=$cargoHome" | Out-File -FilePath $env:GITHUB_ENV -Append -Encoding utf8

      - name: Use shared Cargo home for CI caching (Unix)
        if: runner.os != 'Windows'
        run: echo "CARGO_HOME=$HOME/.cargo" >> "$GITHUB_ENV"

      - name: Install WiX Toolset (required for MSI builds)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $ErrorActionPreference = "Stop"

          # Tauri's MSI bundler requires WiX (candle.exe/light.exe) to be on PATH.
          # GitHub runners don't consistently have it available, and Tauri may skip
          # MSI generation without failing. Install WiX deterministically.
          $candle = Get-Command candle.exe -ErrorAction SilentlyContinue
          $light = Get-Command light.exe -ErrorAction SilentlyContinue
          if (-not $candle -or -not $light) {
            choco install wixtoolset --yes --no-progress

            # Ensure the newly-installed tools are visible in the current step.
            # (Chocolatey may update PATH via the registry; refreshenv reloads it.)
            if (Test-Path "$env:ChocolateyInstall\\helpers\\chocolateyProfile.psm1") {
              Import-Module "$env:ChocolateyInstall\\helpers\\chocolateyProfile.psm1"
              refreshenv
            }
          }

          # Add common WiX install locations to PATH for subsequent steps.
          $wixRoots = Get-ChildItem -Path (Join-Path ${env:ProgramFiles(x86)} "WiX Toolset v*") -Directory -ErrorAction SilentlyContinue
          foreach ($root in $wixRoots) {
            $bin = Join-Path $root.FullName "bin"
            if (Test-Path $bin) {
              $env:PATH = "$bin;$env:PATH"
              $bin | Out-File -FilePath $env:GITHUB_PATH -Append -Encoding utf8
            }
          }

          if (-not (Get-Command candle.exe -ErrorAction SilentlyContinue)) {
            throw "WiX Toolset installation failed: candle.exe not found on PATH."
          }
          if (-not (Get-Command light.exe -ErrorAction SilentlyContinue)) {
            throw "WiX Toolset installation failed: light.exe not found on PATH."
          }

      - name: Install NSIS (required for EXE builds)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $ErrorActionPreference = "Stop"

          # Tauri's NSIS bundler requires makensis.exe. If it's missing, Tauri may
          # skip EXE generation without failing the overall build. Install NSIS
          # deterministically so Windows releases always include both `.exe` and `.msi`.
          if (-not (Get-Command makensis.exe -ErrorAction SilentlyContinue)) {
            choco install nsis --yes --no-progress

            # Ensure the newly-installed tools are visible in the current step.
            if (Test-Path "$env:ChocolateyInstall\\helpers\\chocolateyProfile.psm1") {
              Import-Module "$env:ChocolateyInstall\\helpers\\chocolateyProfile.psm1"
              refreshenv
            }
          }

          if (-not (Get-Command makensis.exe -ErrorAction SilentlyContinue)) {
            throw "NSIS installation failed: makensis.exe not found on PATH."
          }

      - name: Install 7-Zip (required for NSIS payload validation)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $ErrorActionPreference = "Stop"
          if (-not (Get-Command 7z.exe -ErrorAction SilentlyContinue)) {
            choco install 7zip --yes --no-progress
            if (Test-Path "$env:ChocolateyInstall\\helpers\\chocolateyProfile.psm1") {
              Import-Module "$env:ChocolateyInstall\\helpers\\chocolateyProfile.psm1"
              refreshenv
            }
          }

          if (-not (Get-Command 7z.exe -ErrorAction SilentlyContinue)) {
            throw "7-Zip installation failed: 7z.exe not found on PATH."
          }

      - name: Cache Rust (cargo registry + git)
        uses: Swatinem/rust-cache@779680da715d629ac1d338a641029a2f4372abb5 # v2
        with:
          # We cache build artifacts separately (see "Cache cargo target") to keep cache sizes
          # bounded for tagged releases. rust-cache still provides fast restores for the Cargo
          # registry/git index and respects our CARGO_HOME override above.
          cache-targets: "false"
          # We cache cargo-installed tools explicitly (wasm-pack/cargo-tauri) with versioned keys
          # below, so skip caching ~/.cargo/bin here to avoid duplicate cache uploads/downloads.
          cache-bin: "false"
          # Save the registry/git cache even when later release steps fail, so reruns
          # don't start from a cold dependency download.
          cache-on-failure: "true"

      - name: Cache cargo target (release build artifacts)
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v5.0.2
        with:
          path: |
            # Avoid recursive `target/**/...` patterns here: Cargo target directories can be large,
            # and GitHub Actions globbing will traverse the tree to find matches. The release output
            # layout is predictable:
            #   - target/release/<dir>
            #   - target/<triple>/release/<dir>
            target/release/deps
            target/*/release/deps
            target/release/build
            target/*/release/build
            target/release/.fingerprint
            target/*/release/.fingerprint
            target/release/incremental
            target/*/release/incremental
            target/release/wbuild
            target/*/release/wbuild
            target/.rustc_info.json
            target/*/.rustc_info.json
            apps/desktop/src-tauri/target/release/deps
            apps/desktop/src-tauri/target/*/release/deps
            apps/desktop/src-tauri/target/release/build
            apps/desktop/src-tauri/target/*/release/build
            apps/desktop/src-tauri/target/release/.fingerprint
            apps/desktop/src-tauri/target/*/release/.fingerprint
            apps/desktop/src-tauri/target/release/incremental
            apps/desktop/src-tauri/target/*/release/incremental
            apps/desktop/src-tauri/target/release/wbuild
            apps/desktop/src-tauri/target/*/release/wbuild
            apps/desktop/src-tauri/target/.rustc_info.json
            apps/desktop/src-tauri/target/*/.rustc_info.json
          # Keep these caches isolated per Rust target triple + runner arch so cross-compile jobs
          # (e.g. Windows aarch64) don't thrash/overwrite caches or restore host build-script
          # binaries from an incompatible runner architecture.
          # Include the Rust toolchain pin so caches don't leak across rustc upgrades.
          # (Similar to Swatinem/rust-cache's default behavior.)
          key: cargo-target-desktop-release-${{ runner.os }}-${{ runner.arch }}-${{ matrix.cache_target }}-${{ matrix.cache_features }}-${{ hashFiles('rust-toolchain.toml') }}-${{ hashFiles('Cargo.lock') }}
          restore-keys: |
            cargo-target-desktop-release-${{ runner.os }}-${{ runner.arch }}-${{ matrix.cache_target }}-${{ matrix.cache_features }}-${{ hashFiles('rust-toolchain.toml') }}-
            # Backwards-compat: allow restoring caches created before we started keying
            # on the Tauri feature set (so the first run after a workflow update isn't cold).
            cargo-target-desktop-release-${{ runner.os }}-${{ runner.arch }}-${{ matrix.cache_target }}-${{ hashFiles('rust-toolchain.toml') }}-

      - name: Install Linux dependencies
        if: runner.os == 'Linux'
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            file \
            binutils \
            cpio \
            xvfb \
            libgtk-3-dev \
            libwebkit2gtk-4.1-dev \
            libayatana-appindicator3-dev \
            librsvg2-dev \
            libssl-dev \
            patchelf \
            squashfs-tools \
            fakeroot \
            rpm \
            rpm2cpio

          # AppImage-based tooling (including `appimagetool`) supports "extract and run" mode.
          # Prefer it in CI to reduce reliance on a working FUSE setup.
          echo "APPIMAGE_EXTRACT_AND_RUN=1" >> "${GITHUB_ENV}"

          # `appimagetool` is distributed as an AppImage and may require the FUSE 2 runtime on some hosts.
          # Ubuntu 24.04 uses `libfuse2t64` as part of the time_t 64-bit transition.
          #
          # Best-effort install: extract-and-run mode means the build can proceed without FUSE.
          sudo apt-get install -y libfuse2 || sudo apt-get install -y libfuse2t64 || true
      - name: Install JS dependencies
        # Prefer cached pnpm store entries to reduce network flakiness on reruns.
        env:
          # Release builds don't run Playwright tests, so skip the ~GB browser downloads
          # performed by `@playwright/test`'s postinstall script. (CI test workflows that
          # run Playwright should not set this.)
          PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD: "1"
        run: pnpm install --frozen-lockfile --prefer-offline

      - name: Cache wasm-pack binary
        id: wasm-pack-cache
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v5.0.2
        with:
          path: ~/.cargo/bin/wasm-pack*
          # Include the Rust toolchain pin so Rust upgrades force rebuilding the cached binary.
          key: wasm-pack-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-

      - name: Cache wasm-pack tool downloads (Linux)
        if: runner.os == 'Linux'
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v5.0.2
        with:
          # wasm-pack downloads wasm-bindgen + binaryen (wasm-opt) into this cache dir.
          path: ~/.cache/.wasm-pack
          # Include Cargo.lock so when the wasm-bindgen version changes we can save the new
          # downloaded toolchain instead of re-downloading it every run (cache keys are immutable).
          key: wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-v${{ env.WASM_PACK_VERSION }}-${{ hashFiles('Cargo.lock') }}
          restore-keys: |
            wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-v${{ env.WASM_PACK_VERSION }}-
            wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-

      - name: Cache wasm-pack tool downloads (macOS)
        if: runner.os == 'macOS'
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v5.0.2
        with:
          path: ~/Library/Caches/.wasm-pack
          key: wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-v${{ env.WASM_PACK_VERSION }}-${{ hashFiles('Cargo.lock') }}
          restore-keys: |
            wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-v${{ env.WASM_PACK_VERSION }}-
            wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-

      - name: Cache wasm-pack tool downloads (Windows)
        if: runner.os == 'Windows'
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v5.0.2
        with:
          path: ${{ env.LOCALAPPDATA }}/.wasm-pack
          key: wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-v${{ env.WASM_PACK_VERSION }}-${{ hashFiles('Cargo.lock') }}
          restore-keys: |
            wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-v${{ env.WASM_PACK_VERSION }}-
            wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-

      - name: Install wasm-pack (required for @formula/engine WASM build)
        # Pinned for release reproducibility. Known-good with this repo's WASM build
        # (`crates/formula-wasm` via `packages/engine/scripts/build-wasm.mjs`).
        if: steps.wasm-pack-cache.outputs.cache-hit != 'true'
        # Use --force so cache restore-keys (or other CI caches) can't strand a stale/untracked
        # wasm-pack binary that would otherwise block `cargo install` from overwriting it.
        run: cargo install wasm-pack --version ${{ env.WASM_PACK_VERSION }} --locked --force

      - name: Verify wasm-pack version
        shell: bash
        run: |
          set -euo pipefail
          expected="${WASM_PACK_VERSION}"
          actual="$(wasm-pack --version | tr -d '\r' | awk '{print $2}')"
          if [[ "${actual}" != "${expected}" ]]; then
            echo "Expected wasm-pack ${expected}, but found ${actual}." >&2
            exit 1
          fi

      - name: Cache pinned Tauri CLI binary (cargo-tauri)
        id: tauri-cli-cache
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v5.0.2
        with:
          path: ~/.cargo/bin/cargo-tauri*
          # Include the Rust toolchain pin so Rust upgrades force rebuilding the cached binary.
          key: cargo-tauri-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-v${{ env.TAURI_CLI_VERSION }}
          restore-keys: |
            cargo-tauri-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-

      - name: Install pinned Tauri CLI (cargo tauri)
        if: steps.tauri-cli-cache.outputs.cache-hit != 'true'
        run: cargo install tauri-cli --version ${{ env.TAURI_CLI_VERSION }} --locked --force

      - name: Verify Tauri CLI version
        shell: bash
        run: |
          set -euo pipefail
          expected="${TAURI_CLI_VERSION}"
          actual="$(cargo tauri --version | tr -d '\r' | awk '{print $2}')"
          echo "cargo-tauri version: ${actual}"
          if [[ "${actual}" != "${expected}" ]]; then
            echo "Expected cargo-tauri ${expected}, but found ${actual}." >&2
            exit 1
          fi

      - name: Cache Tauri tooling downloads (Linux)
        if: runner.os == 'Linux'
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v5.0.2
        with:
          path: ~/.cache/tauri
          key: tauri-tooling-${{ runner.os }}-${{ runner.arch }}-v${{ env.TAURI_CLI_VERSION }}
          restore-keys: |
            tauri-tooling-${{ runner.os }}-${{ runner.arch }}-

      - name: Cache Tauri tooling downloads (macOS)
        if: runner.os == 'macOS'
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v5.0.2
        with:
          path: ~/Library/Caches/tauri
          key: tauri-tooling-${{ runner.os }}-${{ runner.arch }}-v${{ env.TAURI_CLI_VERSION }}
          restore-keys: |
            tauri-tooling-${{ runner.os }}-${{ runner.arch }}-

      - name: Cache Tauri tooling downloads (Windows)
        if: runner.os == 'Windows'
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v5.0.2
        with:
          # Tauri's cache directory lives under %LOCALAPPDATA% on Windows.
          path: ${{ env.LOCALAPPDATA }}/tauri
          key: tauri-tooling-${{ runner.os }}-${{ runner.arch }}-v${{ env.TAURI_CLI_VERSION }}
          restore-keys: |
            tauri-tooling-${{ runner.os }}-${{ runner.arch }}-

      - name: Cache Tauri permission list (cargo tauri permission ls)
        if: runner.os == 'Linux'
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v5.0.2
        with:
          path: target/ci/tauri-permission-ls.txt
          key: tauri-permission-ls-${{ runner.os }}-${{ runner.arch }}-v${{ env.TAURI_CLI_VERSION }}-${{ hashFiles('Cargo.lock', 'apps/desktop/src-tauri/Cargo.toml', 'apps/desktop/src-tauri/tauri.conf.json') }}

      - name: Validate Tauri capability permission identifiers
        # Fail the release early if `apps/desktop/src-tauri/capabilities/*.json` references
        # permissions that do not exist in the pinned toolchain (`cargo tauri permission ls`).
        if: runner.os == 'Linux'
        env:
          FORMULA_TAURI_PERMISSION_LS_CACHE_PATH: target/ci/tauri-permission-ls.txt
        run: node scripts/check-tauri-permissions.mjs

      # Ensure release builds produce separate debug symbol files for crash symbolication
      # without bloating installer assets. We keep this as a workflow-only override (instead
      # of changing the workspace-wide Cargo profile) so Linux builds remain size-focused.
      - name: Configure Cargo release debug symbols (macOS)
        if: runner.os == 'macOS'
        shell: bash
        run: |
          set -euo pipefail
          # Use full debug info in the sidecar dSYM for reliable crash symbolication.
          echo "CARGO_PROFILE_RELEASE_DEBUG=2" >> "$GITHUB_ENV"
          echo "CARGO_PROFILE_RELEASE_SPLIT_DEBUGINFO=packed" >> "$GITHUB_ENV"

      - name: Build and upload release assets (macOS universal)
        id: tauri_release_macos
        if: runner.os == 'macOS' && needs.preflight.outputs.upload == 'true'
        # Pinned for reproducible releases: avoid upstream floating major tags moving and breaking builds.
        # To upgrade, bump to a newer `v0.x.y` tag in a PR after verifying the release workflow.
        uses: tauri-apps/tauri-action@73fb865345c54760d875b94642314f8c0c894afa # v0.6.1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          projectPath: apps/desktop
          # Use the Cargo-installed Tauri CLI (`cargo tauri`) instead of letting the
          # action install a floating `@tauri-apps/cli@v2` toolchain.
          tauriScript: cargo tauri
          args: --target universal-apple-darwin
          tagName: ${{ needs.preflight.outputs.release_tag }}
          releaseName: Formula ${{ needs.preflight.outputs.release_tag }}
          releaseBody: |
            Automated build for ${{ needs.preflight.outputs.release_tag }}.
            See the assets below for the installers/bundles.
          releaseDraft: true
          # Mark GitHub Releases as prereleases when the semver tag contains a
          # prerelease suffix like `-beta.1` or `-rc.0` (e.g. `v1.2.3-beta.1`).
          prerelease: ${{ contains(needs.preflight.outputs.release_tag, '-') }}

      - name: Attest build provenance (macOS release assets)
        if: runner.os == 'macOS' && needs.preflight.outputs.upload == 'true' && steps.tauri_release_macos.outcome == 'success'
        id: provenance_macos
        continue-on-error: true
        uses: actions/attest-build-provenance@00014ed6ed5efc5b1ab7f7f34a39eb55d41aa4f8 # v1
        with:
          subject-path: ${{ join(fromJson(steps.tauri_release_macos.outputs.artifactPaths), '\n') }}

      - name: Upload provenance bundle (workflow artifact, macOS)
        if: steps.provenance_macos.outcome == 'success'
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: provenance-${{ needs.preflight.outputs.artifact_label }}-${{ matrix.cache_target }}
          path: ${{ steps.provenance_macos.outputs.bundle-path }}
          if-no-files-found: warn

      - name: Upload provenance bundle to the draft release (macOS)
        if: steps.provenance_macos.outcome == 'success'
        continue-on-error: true
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PROVENANCE_BUNDLE_PATH: ${{ steps.provenance_macos.outputs.bundle-path }}
        shell: bash
        run: |
          set -euo pipefail
          out="provenance-${{ matrix.cache_target }}.intoto.jsonl"
          PROVENANCE_OUT="$out" python - <<'PY'
          import os
          import shutil
          
          src = os.environ["PROVENANCE_BUNDLE_PATH"]
          dst = os.environ["PROVENANCE_OUT"]
          shutil.copyfile(src, dst)
          print(f"Copied provenance bundle: {src} -> {dst}")
          PY
          gh release upload "${{ needs.preflight.outputs.release_tag }}" "${out}" \
            --repo "${{ github.repository }}" \
            --clobber

      - name: Build desktop bundles (macOS universal, dry run)
        id: tauri_dryrun_macos
        if: runner.os == 'macOS' && needs.preflight.outputs.upload != 'true'
        uses: tauri-apps/tauri-action@73fb865345c54760d875b94642314f8c0c894afa # v0.6.1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          projectPath: apps/desktop
          # Use the Cargo-installed Tauri CLI (`cargo tauri`) instead of letting the
          # action install a floating `@tauri-apps/cli@v2` toolchain.
          tauriScript: cargo tauri
          args: --target universal-apple-darwin

      - name: Validate macOS bundle (DMG, Info.plist, codesign/notarization)
        # Always run on macOS so unsigned fork/dry-run builds still validate bundle structure.
        # Codesign + notarization checks are conditional on env vars (APPLE_* secrets) and are
        # skipped automatically when signing is not configured.
        if: runner.os == 'macOS'
        shell: bash
        run: bash scripts/validate-macos-bundle.sh

      # Debug symbols are not end-user installer assets, but they are needed for post-release crash
      # symbolication. Package them separately so they can be downloaded from the workflow run
      # without bloating installer bundles.
      - name: Package macOS debug symbols (dSYM)
        if: runner.os == 'macOS'
        shell: bash
        env:
          ARTIFACT_LABEL: ${{ needs.preflight.outputs.artifact_label }}
          CACHE_TARGET: ${{ matrix.cache_target }}
        run: |
          set -euo pipefail

          mkdir -p debug-symbols

          roots=()
          if [[ -n "${CARGO_TARGET_DIR:-}" ]]; then
            cargo_target_dir="${CARGO_TARGET_DIR}"
            if [[ "${cargo_target_dir}" != /* ]]; then
              cargo_target_dir="${PWD}/${cargo_target_dir}"
            fi
            if [[ -d "${cargo_target_dir}" ]]; then
              roots+=("${cargo_target_dir}")
            fi
          fi
          for root in "apps/desktop/src-tauri/target" "apps/desktop/target" "target"; do
            if [[ -d "${root}" ]]; then
              roots+=("${root}")
            fi
          done
          if ((${#roots[@]} == 0)); then
            echo "debug-symbols: ERROR no Cargo target directories found (CARGO_TARGET_DIR=${CARGO_TARGET_DIR:-<unset>})" >&2
            exit 1
          fi

          # Canonicalize + de-dupe roots to avoid double-scanning when `CARGO_TARGET_DIR` overlaps
          # the default workspace target directories. Avoid Bash 4 associative arrays (macOS runners
          # still ship Bash 3.2).
          uniq_roots=()
          for root in "${roots[@]}"; do
            abs="$(cd "$root" && pwd -P)"
            seen=0
            for existing in "${uniq_roots[@]}"; do
              if [[ "$existing" == "$abs" ]]; then
                seen=1
                break
              fi
            done
            if [[ "$seen" -eq 0 ]]; then
              uniq_roots+=("$abs")
            fi
          done
          roots=("${uniq_roots[@]}")

          shopt -s nullglob
          dsym_dirs=()
          for root in "${roots[@]}"; do
            # Prefer dSYMs produced for the actual build target triple (macOS job is universal).
            # This avoids uploading multiple copies (e.g. intermediate x86_64/aarch64 builds).
            dsym_dirs+=("${root}/${CACHE_TARGET}/release/bundle/macos/"*.dSYM)
            dsym_dirs+=("${root}/release/bundle/macos/"*.dSYM)
          done

          # If no bundle-local dSYMs were produced, fall back to Cargo release outputs
          # (prefer the configured target triple directory, then the native release dir).
          if ((${#dsym_dirs[@]} == 0)); then
            for root in "${roots[@]}"; do
              dsym_dirs+=("${root}/${CACHE_TARGET}/release/"*.dSYM)
              dsym_dirs+=("${root}/release/"*.dSYM)
            done
          fi

          # Last resort: accept any target triple to avoid failing hard if the output layout changes.
          if ((${#dsym_dirs[@]} == 0)); then
            for root in "${roots[@]}"; do
              dsym_dirs+=("${root}"/*/release/bundle/macos/*.dSYM)
              dsym_dirs+=("${root}"/*/release/*.dSYM)
            done
          fi
          shopt -u nullglob

          if ((${#dsym_dirs[@]} == 0)); then
            echo "debug-symbols: ERROR no .dSYM bundles found in Cargo release outputs." >&2
            echo "debug-symbols: Searched roots:" >&2
            printf '  - %s\n' "${roots[@]}" >&2
            exit 1
          fi
          # Zip (and optionally clean up) dSYM bundles.
          #
          # NOTE: macOS runners ship an older Bash (3.2), so avoid Bash 4+ builtins like `mapfile`
          # and associative arrays. We use a process-substitution `while read` loop instead.
          bundle_local_dsyms=()
          while IFS= read -r dsym; do
            [[ -n "${dsym}" ]] || continue

            base="$(basename "$dsym")"

            # Avoid output filename collisions when the same dSYM name appears in multiple Cargo
            # target roots (`target/` vs `apps/desktop/src-tauri/target/`, etc).
            loc="target"
            case "$dsym" in
              apps/desktop/src-tauri/target/*|*/apps/desktop/src-tauri/target/*) loc="src-tauri-target" ;;
              apps/desktop/target/*|*/apps/desktop/target/*) loc="desktop-target" ;;
              target/*|*/target/*) loc="workspace-target" ;;
            esac

            source="release"
            if [[ "$dsym" == *"/release/bundle/"* ]]; then
              source="bundle"
            fi

            triple="native"
            if [[ "$dsym" == *"/release/bundle/"* ]]; then
              prefix="${dsym%%/release/bundle/*}"
              triple="${prefix##*/}"
            elif [[ "$dsym" == *"/release/"* ]]; then
              prefix="${dsym%%/release/*}"
              triple="${prefix##*/}"
            fi
            if [[ "$triple" == "target" ]]; then
              triple="native"
            fi

            out="debug-symbols/debug-symbols-${ARTIFACT_LABEL}-${CACHE_TARGET}-${triple}-${loc}-${source}-${base}.zip"
            echo "debug-symbols: zipping $dsym -> $out"
            rm -f "$out"
            # Use `ditto` to preserve bundle structure/metadata for dSYM directories.
            ditto -c -k --sequesterRsrc --keepParent "$dsym" "$out"

            if [[ "$dsym" == *"/release/bundle/"* ]]; then
              bundle_local_dsyms+=("$dsym")
            fi
          done < <(printf '%s\n' "${dsym_dirs[@]}" | sort -u)

          # If any dSYM bundles were emitted into `**/release/bundle/**`, remove them so they
          # don't bloat dry-run bundle artifacts or fail strip/bundle verification checks.
          for dsym in "${bundle_local_dsyms[@]}"; do
            echo "debug-symbols: removing bundle-local dSYM: $dsym"
            rm -rf "$dsym"
          done

          ls -lah debug-symbols

          if [[ -n "${GITHUB_STEP_SUMMARY:-}" ]]; then
            {
              echo "### Debug symbols (${CACHE_TARGET})"
              echo
              echo "- Workflow artifact: \`debug-symbols-${ARTIFACT_LABEL}-${CACHE_TARGET}\`"
              echo "- Files:"
              for f in debug-symbols/*.zip; do
                echo "  - \`$(basename "$f")\`"
              done
              echo
            } >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Upload debug symbol archives (macOS)
        if: runner.os == 'macOS'
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: debug-symbols-${{ needs.preflight.outputs.artifact_label }}-${{ matrix.cache_target }}
          path: debug-symbols/*.zip
          if-no-files-found: error

      - name: Upload debug symbol archives to draft release (macOS)
        if: runner.os == 'macOS' && needs.preflight.outputs.upload == 'true' && (vars.FORMULA_UPLOAD_DEBUG_SYMBOLS_TO_RELEASE == '1' || vars.FORMULA_UPLOAD_DEBUG_SYMBOLS_TO_RELEASE == 'true')
        shell: bash
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          shopt -s nullglob
          files=(debug-symbols/*.zip)
          if ((${#files[@]} == 0)); then
            echo "No debug symbol archives found under debug-symbols/*.zip" >&2
            exit 1
          fi
          gh release upload "${{ needs.preflight.outputs.release_tag }}" "${files[@]}" \
            --repo "${{ github.repository }}" \
            --clobber

      - name: Desktop dist asset report
        if: runner.os == 'macOS'
        run: node scripts/desktop_dist_asset_report.mjs --json-out desktop-dist-assets-report.json
        env:
          # Optional: set as GitHub Actions variables to enable gating.
          FORMULA_DESKTOP_DIST_TOTAL_BUDGET_MB: ${{ vars.FORMULA_DESKTOP_DIST_TOTAL_BUDGET_MB }}
          FORMULA_DESKTOP_DIST_SINGLE_FILE_BUDGET_MB: ${{ vars.FORMULA_DESKTOP_DIST_SINGLE_FILE_BUDGET_MB }}

      - name: Verify macOS signed app entitlements (hardened runtime)
        # Only run when code signing is enabled (forks/dry-runs may not have signing secrets).
        if: runner.os == 'macOS' && secrets.APPLE_CERTIFICATE != '' && secrets.APPLE_CERTIFICATE_PASSWORD != ''
        run: |
          set -euo pipefail
          # Cargo workspaces typically emit bundle outputs under `<repo>/target/**`, but standalone
          # Tauri projects use `<src-tauri>/target/**`. Support both so signed-release validation
          # doesn't fail when the build output layout changes.
          search_roots=(
            apps/desktop/src-tauri/target/universal-apple-darwin
            apps/desktop/target/universal-apple-darwin
            target/universal-apple-darwin
            apps/desktop/src-tauri/target
            apps/desktop/target
            target
          )

          app=""
          for root in "${search_roots[@]}"; do
            [[ -d "$root" ]] || continue

            # Fast path: avoid traversing the entire Cargo target directory (which can be large)
            # by checking the canonical bundle locations directly:
            # - <target>/release/bundle/macos/*.app
            # - <target>/<triple>/release/bundle/macos/*.app
            nullglob_was_set=0
            if shopt -q nullglob; then nullglob_was_set=1; fi
            shopt -s nullglob
            candidates=(
              "$root"/release/bundle/macos/*.app
              "$root"/*/release/bundle/macos/*.app
            )
            if [[ "${nullglob_was_set}" -eq 0 ]]; then shopt -u nullglob; fi

            if ((${#candidates[@]} > 0)); then
              app="${candidates[0]}"
              break
            fi
          done

          # Fallback (slower): scan with `find` if the bundle layout is unexpected.
          if [[ -z "${app:-}" ]]; then
            for root in "${search_roots[@]}"; do
              [[ -d "$root" ]] || continue
              candidate="$(find "$root" -maxdepth 12 -type d -path '*/release/bundle/macos/*.app' -print 2>/dev/null | head -n 1 || true)"
              if [[ -n "$candidate" ]]; then
                app="$candidate"
                break
              fi
            done
          fi

          if [[ -z "${app:-}" ]]; then
            echo "::error::No .app bundle found under expected release bundle roots." >&2
            echo "Searched: ${search_roots[*]}" >&2
            for root in "${search_roots[@]}"; do
              if [[ -d "$root" ]]; then
                echo "Available .app directories under $root (first 20):" >&2
                find "$root" -maxdepth 12 -type d -name '*.app' -print 2>/dev/null | head -n 20 || true
              fi
            done
            exit 1
          fi
          echo "Verifying entitlements embedded in: $app"
          codesign --verify --deep --strict --verbose=2 "$app"
          tmp_entitlements="$(mktemp -t formula-entitlements.XXXXXX)"
          tmp_raw="$(mktemp -t formula-entitlements-raw.XXXXXX)"
          trap 'rm -f "$tmp_entitlements" "$tmp_raw"' EXIT

          # `codesign -d` may print non-XML metadata (e.g. "Executable=...") alongside the entitlements.
          # Extract just the plist so we can lint + validate it using the same guardrail script.
          codesign -d --entitlements :- "$app" 2>&1 | tee "$tmp_raw" \
            | awk 'BEGIN{p=0} /^[[:space:]]*<\\?xml/{p=1} /^[[:space:]]*<plist/{if(p==0)p=1} p{print} p && /<\\/plist>/{exit}' \
            > "$tmp_entitlements"

          if [[ ! -s "$tmp_entitlements" ]]; then
            echo "::error::Failed to extract entitlements plist from codesign output." >&2
            echo "Raw codesign output:" >&2
            cat "$tmp_raw" >&2 || true
            exit 1
          fi

          node scripts/check-macos-entitlements.mjs --path "$tmp_entitlements"

      - name: Setup MSVC cross-compilation environment (amd64 → arm64)
        # Only needed for the Windows ARM64 bundle job; set it immediately before the Tauri build so
        # earlier host-target `cargo install` steps (wasm-pack, tauri-cli) and the COI smoke check run
        # in the default x64 environment.
        if: runner.os == 'Windows' && matrix.rust_target == 'aarch64-pc-windows-msvc'
        uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0
        with:
          arch: amd64_arm64
          sdk: ${{ steps.windows_arm64_toolchain.outputs.sdk_version }}

      - name: Configure Cargo release debug symbols (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $ErrorActionPreference = "Stop"
          # Use full debug info in the PDB for reliable crash symbolication.
          "CARGO_PROFILE_RELEASE_DEBUG=2" | Out-File -FilePath $env:GITHUB_ENV -Append -Encoding utf8

      - name: Build and upload release assets
        id: tauri_release_non_macos
        if: runner.os != 'macOS' && needs.preflight.outputs.upload == 'true'
        # Pinned for reproducible releases: avoid upstream floating major tags moving and breaking builds.
        # To upgrade, bump to a newer `v0.x.y` tag in a PR after verifying the release workflow.
        uses: tauri-apps/tauri-action@73fb865345c54760d875b94642314f8c0c894afa # v0.6.1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          projectPath: apps/desktop
          # Use the Cargo-installed Tauri CLI (`cargo tauri`) instead of letting the
          # action install a floating `@tauri-apps/cli@v2` toolchain.
          tauriScript: cargo tauri
          args: ${{ matrix.tauri_args }}
          tagName: ${{ needs.preflight.outputs.release_tag }}
          releaseName: Formula ${{ needs.preflight.outputs.release_tag }}
          releaseBody: |
            Automated build for ${{ needs.preflight.outputs.release_tag }}.
            See the assets below for the installers/bundles.
          releaseDraft: true
          # Mark GitHub Releases as prereleases when the semver tag contains a
          # prerelease suffix like `-beta.1` or `-rc.0` (e.g. `v1.2.3-beta.1`).
          prerelease: ${{ contains(needs.preflight.outputs.release_tag, '-') }}

      - name: Smoke check packaged cross-origin isolation (COOP/COEP)
        # Run the COI smoke check against the already-built Tauri artifacts produced
        # by the `tauri-apps/tauri-action` step above.
        #
        # Skip Windows ARM64 cross-compile builds (the produced binary isn't runnable on x64 runners).
        if: >-
          needs.preflight.outputs.upload == 'true'
          && (runner.os != 'Windows' || matrix.rust_target != 'aarch64-pc-windows-msvc')
          && (
            (runner.os == 'macOS' && steps.tauri_release_macos.outcome == 'success')
            || (runner.os != 'macOS' && steps.tauri_release_non_macos.outcome == 'success')
          )
        run: pnpm -C apps/desktop check:coi -- --no-build

      - name: Attest build provenance (release assets)
        if: runner.os != 'macOS' && needs.preflight.outputs.upload == 'true' && steps.tauri_release_non_macos.outcome == 'success'
        id: provenance_non_macos
        continue-on-error: true
        uses: actions/attest-build-provenance@00014ed6ed5efc5b1ab7f7f34a39eb55d41aa4f8 # v1
        with:
          subject-path: ${{ join(fromJson(steps.tauri_release_non_macos.outputs.artifactPaths), '\n') }}

      - name: Upload provenance bundle (workflow artifact)
        if: steps.provenance_non_macos.outcome == 'success'
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: provenance-${{ needs.preflight.outputs.artifact_label }}-${{ matrix.cache_target }}
          path: ${{ steps.provenance_non_macos.outputs.bundle-path }}
          if-no-files-found: warn

      - name: Upload provenance bundle to the draft release
        if: steps.provenance_non_macos.outcome == 'success'
        continue-on-error: true
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PROVENANCE_BUNDLE_PATH: ${{ steps.provenance_non_macos.outputs.bundle-path }}
        shell: bash
        run: |
          set -euo pipefail
          out="provenance-${{ matrix.cache_target }}.intoto.jsonl"
          PROVENANCE_OUT="$out" python - <<'PY'
          import os
          import shutil
          
          src = os.environ["PROVENANCE_BUNDLE_PATH"]
          dst = os.environ["PROVENANCE_OUT"]
          shutil.copyfile(src, dst)
          print(f"Copied provenance bundle: {src} -> {dst}")
          PY
          gh release upload "${{ needs.preflight.outputs.release_tag }}" "${out}" \
            --repo "${{ github.repository }}" \
            --clobber

      - name: Build desktop bundles (dry run)
        id: tauri_dryrun_non_macos
        if: runner.os != 'macOS' && needs.preflight.outputs.upload != 'true'
        uses: tauri-apps/tauri-action@73fb865345c54760d875b94642314f8c0c894afa # v0.6.1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          projectPath: apps/desktop
          # Use the Cargo-installed Tauri CLI (`cargo tauri`) instead of letting the
          # action install a floating `@tauri-apps/cli@v2` toolchain.
          tauriScript: cargo tauri
          args: ${{ matrix.tauri_args }}

      - name: Package Windows debug symbols (PDB)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $ErrorActionPreference = "Stop"

          $label = "${{ needs.preflight.outputs.artifact_label }}"
          $cacheTarget = "${{ matrix.cache_target }}"
          $target = "${{ matrix.rust_target }}"
          if ([string]::IsNullOrWhiteSpace($target)) {
            throw "debug-symbols: ERROR matrix.rust_target is empty; expected an explicit Windows target triple."
          }

          $candidatePdbs = @()
          if ($env:CARGO_TARGET_DIR) {
            $cargoTargetDir = $env:CARGO_TARGET_DIR
            if (-not [System.IO.Path]::IsPathRooted($cargoTargetDir)) {
              $cargoTargetDir = Join-Path $env:GITHUB_WORKSPACE $cargoTargetDir
            }
            $candidatePdbs += (Join-Path $cargoTargetDir "$target/release/formula-desktop.pdb")
            $candidatePdbs += (Join-Path $cargoTargetDir "release/formula-desktop.pdb")
          }
          $candidatePdbs += @(
            (Join-Path $env:GITHUB_WORKSPACE "apps/desktop/src-tauri/target/$target/release/formula-desktop.pdb"),
            (Join-Path $env:GITHUB_WORKSPACE "apps/desktop/target/$target/release/formula-desktop.pdb"),
            (Join-Path $env:GITHUB_WORKSPACE "target/$target/release/formula-desktop.pdb"),
            (Join-Path $env:GITHUB_WORKSPACE "apps/desktop/src-tauri/target/release/formula-desktop.pdb"),
            (Join-Path $env:GITHUB_WORKSPACE "apps/desktop/target/release/formula-desktop.pdb"),
            (Join-Path $env:GITHUB_WORKSPACE "target/release/formula-desktop.pdb")
          )

          $pdbPath = $candidatePdbs | Where-Object { Test-Path $_ } | Select-Object -First 1
          if (-not $pdbPath) {
            $joined = $candidatePdbs -join "`n"
            throw "debug-symbols: ERROR formula-desktop.pdb not found. Looked in:`n$joined"
          }

          New-Item -ItemType Directory -Force -Path "debug-symbols" | Out-Null
          Copy-Item -Force $pdbPath "debug-symbols/formula-desktop.pdb"

          $zipPath = "debug-symbols/debug-symbols-$label-$cacheTarget-formula-desktop.pdb.zip"
          if (Test-Path $zipPath) { Remove-Item $zipPath -Force }
          Compress-Archive -Path "debug-symbols/formula-desktop.pdb" -DestinationPath $zipPath

          # If any PDB files were emitted into `**/release/bundle/**`, remove them so they don't
          # bloat dry-run bundle artifacts or trip strip/symbol checks.
          $bundleCandidates = @()
          if ($env:CARGO_TARGET_DIR) {
            $cargoTargetDir = $env:CARGO_TARGET_DIR
            if (-not [System.IO.Path]::IsPathRooted($cargoTargetDir)) {
              $cargoTargetDir = Join-Path $env:GITHUB_WORKSPACE $cargoTargetDir
            }
            $bundleCandidates += (Join-Path $cargoTargetDir "$target/release/bundle")
            $bundleCandidates += (Join-Path $cargoTargetDir "release/bundle")
          }
          $bundleCandidates += @(
            (Join-Path $env:GITHUB_WORKSPACE "apps/desktop/src-tauri/target/$target/release/bundle"),
            (Join-Path $env:GITHUB_WORKSPACE "apps/desktop/target/$target/release/bundle"),
            (Join-Path $env:GITHUB_WORKSPACE "target/$target/release/bundle"),
            (Join-Path $env:GITHUB_WORKSPACE "apps/desktop/src-tauri/target/release/bundle"),
            (Join-Path $env:GITHUB_WORKSPACE "apps/desktop/target/release/bundle"),
            (Join-Path $env:GITHUB_WORKSPACE "target/release/bundle")
          )
          foreach ($bundleDir in $bundleCandidates) {
            if (-not (Test-Path $bundleDir)) { continue }
            $bundlePdbs = Get-ChildItem -Path $bundleDir -Recurse -File -Filter "*.pdb" -ErrorAction SilentlyContinue
            if ($bundlePdbs -and $bundlePdbs.Count -gt 0) {
              Write-Host "debug-symbols: removing bundle-local PDB(s) under $bundleDir:"
              $bundlePdbs | ForEach-Object {
                Write-Host "- $($_.FullName)"
                Remove-Item -Force $_.FullName
              }
            }
          }

          Get-ChildItem -Path "debug-symbols" | Format-Table Name,Length

          if ($env:GITHUB_STEP_SUMMARY) {
            Add-Content -Path $env:GITHUB_STEP_SUMMARY -Value "### Debug symbols ($cacheTarget)"
            Add-Content -Path $env:GITHUB_STEP_SUMMARY -Value ""
            Add-Content -Path $env:GITHUB_STEP_SUMMARY -Value ('- Workflow artifact: `debug-symbols-' + $label + '-' + $cacheTarget + '`')
            Add-Content -Path $env:GITHUB_STEP_SUMMARY -Value "- Files:"
            Get-ChildItem -Path "debug-symbols" -Filter "*.zip" -File | ForEach-Object {
              Add-Content -Path $env:GITHUB_STEP_SUMMARY -Value ('  - `' + $_.Name + '`')
            }
            Add-Content -Path $env:GITHUB_STEP_SUMMARY -Value ""
          }

      - name: Upload debug symbol archives (Windows)
        if: runner.os == 'Windows'
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: debug-symbols-${{ needs.preflight.outputs.artifact_label }}-${{ matrix.cache_target }}
          path: debug-symbols/*.zip
          if-no-files-found: error

      - name: Upload debug symbol archives to draft release (Windows)
        if: runner.os == 'Windows' && needs.preflight.outputs.upload == 'true' && (vars.FORMULA_UPLOAD_DEBUG_SYMBOLS_TO_RELEASE == '1' || vars.FORMULA_UPLOAD_DEBUG_SYMBOLS_TO_RELEASE == 'true')
        shell: pwsh
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          $ErrorActionPreference = "Stop"

          $tag = "${{ needs.preflight.outputs.release_tag }}"
          $files = Get-ChildItem -Path "debug-symbols" -Filter "*.zip" -File | ForEach-Object { $_.FullName }
          if (-not $files -or $files.Count -eq 0) {
            throw "No debug symbol archives found under debug-symbols/*.zip"
          }

          gh release upload $tag $files --repo "${{ github.repository }}" --clobber

      - name: Smoke check packaged cross-origin isolation (COOP/COEP)
        # Run against the already-built Tauri artifacts produced by the earlier
        # `tauri-apps/tauri-action` build step(s) in this job.
        #
        # Skip Windows ARM64 cross-compile builds (the produced binary isn't runnable on x64 runners).
        if: >-
          needs.preflight.outputs.upload != 'true'
          && (runner.os != 'Windows' || matrix.rust_target != 'aarch64-pc-windows-msvc')
        run: pnpm -C apps/desktop check:coi -- --no-build

      - name: Desktop dist asset report
        if: runner.os != 'macOS'
        run: node scripts/desktop_dist_asset_report.mjs --json-out desktop-dist-assets-report.json
        env:
          # Optional: set as GitHub Actions variables to enable gating.
          FORMULA_DESKTOP_DIST_TOTAL_BUDGET_MB: ${{ vars.FORMULA_DESKTOP_DIST_TOTAL_BUDGET_MB }}
          FORMULA_DESKTOP_DIST_SINGLE_FILE_BUDGET_MB: ${{ vars.FORMULA_DESKTOP_DIST_SINGLE_FILE_BUDGET_MB }}

      - name: Upload desktop dist asset report (JSON)
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: desktop-dist-assets-report-${{ needs.preflight.outputs.artifact_label }}-${{ matrix.cache_target }}
          path: desktop-dist-assets-report.json
          if-no-files-found: ignore

      - name: Validate Windows installer bundles (presence + Authenticode + file associations/protocol)
        if: runner.os == 'Windows'
        shell: pwsh
        env:
          WINDOWS_CERTIFICATE: ${{ secrets.WINDOWS_CERTIFICATE }}
        run: |
          $ErrorActionPreference = "Stop"
          $target = "${{ matrix.rust_target }}"
          if ([string]::IsNullOrWhiteSpace($target)) {
            throw "windows-bundle: ERROR matrix.rust_target is empty; expected an explicit Windows target triple."
          }

          $bundleCandidates = @(
            (Join-Path $env:GITHUB_WORKSPACE "apps/desktop/src-tauri/target/$target/release/bundle"),
            (Join-Path $env:GITHUB_WORKSPACE "apps/desktop/target/$target/release/bundle"),
            (Join-Path $env:GITHUB_WORKSPACE "target/$target/release/bundle")
          )
          $bundleDir = $bundleCandidates | Where-Object { Test-Path $_ } | Select-Object -First 1
          if (-not $bundleDir) {
            $candidatesJoined = $bundleCandidates -join "`n"
            throw "windows-bundle: ERROR expected Tauri bundle dir not found. Looked in:`n$candidatesJoined"
          }

          # Require both installer formats (MSI + NSIS EXE) so we don't publish a
          # partial Windows release.
          pwsh -NoProfile -ExecutionPolicy Bypass -File ./scripts/validate-windows-bundles.ps1 -BundleDir $bundleDir -RequireExe -RequireMsi
      - name: Verify Windows ARM64 binary architecture (AA64)
        if: runner.os == 'Windows' && matrix.rust_target == 'aarch64-pc-windows-msvc'
        shell: pwsh
        run: |
          $ErrorActionPreference = "Stop"
          $target = "${{ matrix.rust_target }}"
          $releaseCandidates = @(
            (Join-Path $env:GITHUB_WORKSPACE "apps/desktop/src-tauri/target/$target/release"),
            (Join-Path $env:GITHUB_WORKSPACE "apps/desktop/target/$target/release"),
            (Join-Path $env:GITHUB_WORKSPACE "target/$target/release")
          )
          $releaseDir = $releaseCandidates | Where-Object { Test-Path $_ } | Select-Object -First 1
          if (-not $releaseDir) {
            $candidatesJoined = $releaseCandidates -join "`n"
            throw "windows-arm64: Expected Rust release directory not found. Looked in:`n$candidatesJoined"
          }
          # Avoid scanning the entire Cargo target release directory (can be large in CI). The binary
          # is expected at <releaseDir>/formula-desktop.exe; fall back to a recursive search only if
          # the direct path is missing (defensive against unusual build layouts).
          $exePath = Join-Path $releaseDir "formula-desktop.exe"
          if (Test-Path $exePath) {
            $exe = Get-Item -LiteralPath $exePath
          } else {
            $exe = Get-ChildItem -Path $releaseDir -Recurse -File -Filter "formula-desktop.exe" -ErrorAction SilentlyContinue | Select-Object -First 1
          }
          if (-not $exe) {
            throw "windows-arm64: Expected compiled binary formula-desktop.exe not found under: $releaseDir"
          }
          $dumpbin = Get-Command dumpbin.exe -ErrorAction SilentlyContinue
          if (-not $dumpbin) {
            throw "windows-arm64: dumpbin.exe not found on PATH (expected after MSVC dev-cmd setup)."
          }
          $headers = & dumpbin.exe /headers $exe.FullName
          $joined = ($headers -join "`n")
          $machineLine = ($headers | Select-String -Pattern "machine" -CaseSensitive:$false | Select-Object -First 1).ToString()
          Write-Host "windows-arm64: dumpbin machine line: $machineLine"
          if ($joined -notmatch '\bAA64\b') {
            throw "windows-arm64: Expected ARM64 machine type 'AA64' in dumpbin output for $($exe.FullName), but it was not found. If this is x64, the ARM64 target toolchain/environment is misconfigured."
          }
          if ($joined -match '\b8664\b') {
            throw "windows-arm64: Binary appears to be x64 (machine type '8664'), expected ARM64 (AA64)."
          }

      - name: Smoke test produced AppImage (extract + ldd + arch)
        if: runner.os == 'Linux'
        run: bash scripts/ci/check-appimage.sh

      - name: Validate produced AppImage desktop integration (.desktop + file associations + deep links)
        if: runner.os == 'Linux'
        run: bash scripts/validate-linux-appimage.sh

      - name: Validate produced RPM package (rpm metadata + payload)
        if: runner.os == 'Linux'
        run: bash scripts/validate-linux-rpm.sh --no-container

      - name: Verify Linux .deb package (deps + ldd + desktop integration)
        if: runner.os == 'Linux'
        shell: bash
        run: |
          set -euo pipefail

          for cmd in dpkg dpkg-deb ldd awk sort grep file timeout Xvfb; do
            if ! command -v "${cmd}" >/dev/null 2>&1; then
              echo "::error::Missing required command '${cmd}' on PATH (expected on ubuntu runner)" >&2
              exit 1
            fi
          done

          preferred_dir="apps/desktop/src-tauri/target/release/bundle/deb"
          echo "Preferred .deb output dir: ${preferred_dir}"
          ls -lah "${preferred_dir}" 2>/dev/null || true
          # Preferred location (matches docs/release.md), but fall back to scanning common Cargo target dirs.
          #
          # Use globs instead of `find` to avoid traversing the entire Cargo target directory (which can be large).
          shopt -s nullglob
          debs=("${preferred_dir}"/*.deb)

          if ((${#debs[@]} == 0)); then
            roots=()
            if [[ -n "${CARGO_TARGET_DIR:-}" ]]; then
              roots+=("${CARGO_TARGET_DIR}")
            fi
            roots+=("apps/desktop/src-tauri/target" "apps/desktop/target" "target")

            debs=()
            for root in "${roots[@]}"; do
              [[ -d "${root}" ]] || continue
              debs+=("${root}"/release/bundle/deb/*.deb)
              debs+=("${root}"/*/release/bundle/deb/*.deb)
            done
          fi

          # De-dupe for deterministic logs (and to avoid double-validating when roots overlap).
          if ((${#debs[@]} > 0)); then mapfile -t debs < <(printf '%s\n' "${debs[@]}" | sort -u); fi
          shopt -u nullglob

          echo "Discovered ${#debs[@]} .deb artifact(s)."
          if ((${#debs[@]} > 0)); then
            printf '  - %s\n' "${debs[@]}"
          fi

          if ((${#debs[@]} == 0)); then
            echo "::error::could not find any .deb artifacts under apps/desktop/src-tauri/target/release/bundle/deb or target/release/bundle/deb (or target/*/release/bundle/deb)" >&2
            echo "Debug: searched roots:" >&2
            echo "  - apps/desktop/src-tauri/target/release/bundle/deb/*.deb" >&2
            echo "  - CARGO_TARGET_DIR=${CARGO_TARGET_DIR:-<unset>}" >&2
            echo "  - apps/desktop/src-tauri/target" >&2
            echo "  - apps/desktop/target" >&2
            echo "  - target" >&2
            exit 1
          fi

          if ((${#debs[@]} > 1)); then
            echo "Found multiple .deb artifacts; validating all:"
            printf '  - %s\n' "${debs[@]}"
          fi

          for deb in "${debs[@]}"; do
            echo "Using deb: ${deb}"

            echo "::group::dpkg -I ${deb}"
            dpkg -I "${deb}" | tee dpkg-info.txt
            echo "::endgroup::"

            # Ensure key runtime deps are declared (at least: WebKitGTK + GTK + AppIndicator).
            depends="$(awk '
              BEGIN { in_dep=0; out="" }
              /^[[:space:]]*Depends:/ {
                in_dep=1
                sub(/^[[:space:]]*Depends:[[:space:]]*/, "", $0)
                out=$0
                next
              }
              in_dep==1 {
                # Stop when the next control field begins. Debian control field names begin with a letter
                # (e.g. "Description:"), so avoid treating dependency version epochs like "1:1.2.3" as fields.
                #
                # Require a space after the colon so we don't confuse dependency arch qualifiers like
                # "libc6:amd64" (colon not followed by whitespace) with a new control field.
                if ($0 ~ /^[[:space:]]+[A-Za-z][A-Za-z0-9-]*:[[:space:]]/) { exit }
                sub(/^[[:space:]]+/, "", $0)
                if (out == "") out=$0; else out=out " " $0
              }
              END { print out }
            ' dpkg-info.txt)"
            if [[ -z "${depends// }" ]]; then
              echo "::error::Could not parse Depends from dpkg -I output for ${deb}" >&2
              exit 1
            fi
            echo "dpkg Depends: ${depends}"
            # Keep these checks intentionally fuzzy (substring matches) to tolerate distro/package naming
            # differences (e.g. Ubuntu 24.04's *t64 transition) while still ensuring the core runtime
            # stack is declared.
            for needle in "webkit2gtk" "libgtk-3" "appindicator" "librsvg" "libssl"; do
              if ! grep -qi "$needle" <<<"${depends}"; then
                echo "::error::Expected runtime dependency '$needle' missing from dpkg Depends for ${deb}" >&2
                exit 1
              fi
            done

            tmpdir="$(mktemp -d)"
            trap 'rm -rf "${tmpdir}"' EXIT
            dpkg-deb -x "${deb}" "${tmpdir}"

            bin="${tmpdir}/usr/bin/formula-desktop"
            if [[ ! -f "${bin}" ]]; then
              echo "::error::Expected installed binary not found at ${bin} after extracting ${deb}"
              echo "Extracted file tree (first 200 entries):"
              find "${tmpdir}" -maxdepth 5 -type f -print | head -n 200
              exit 1
            fi
            if [[ ! -x "${bin}" ]]; then
              echo "::error::Expected installed binary is not executable: ${bin}"
              ls -lah "${bin}" || true
              exit 1
            fi

            echo "::group::file ${bin}"
            file "${bin}" || true
            echo "::endgroup::"

            echo "::group::ldd ${bin}"
            set +e
            ldd_out="$(ldd "${bin}" 2>&1)"
            ldd_status=$?
            set -e
            echo "${ldd_out}"
            echo "::endgroup::"
            if grep -q "not found" <<<"${ldd_out}"; then
              echo "::error::Missing shared library dependencies detected by ldd for ${bin}"
              echo "${ldd_out}" | grep "not found" || true
              exit 1
            fi
            if [[ "${ldd_status}" -ne 0 ]] && ! grep -qF "not a dynamic executable" <<<"${ldd_out}"; then
              echo "::error::ldd exited with status ${ldd_status} for ${bin}"
              exit 1
            fi

            # Optional lightweight runtime smoke test: the desktop binary supports a special
            # `--cross-origin-isolation-check` mode that starts the webview under a virtual display
            # and exits quickly with a status code.
            echo "::group::Run packaged binary smoke check (--cross-origin-isolation-check)"
            (
              export HOME="${tmpdir}/home"
              export XDG_CONFIG_HOME="${HOME}/.config"
              export XDG_DATA_HOME="${HOME}/.local/share"
              mkdir -p "${XDG_CONFIG_HOME}" "${XDG_DATA_HOME}"
              if [[ -z "${XDG_RUNTIME_DIR:-}" ]]; then
                export XDG_RUNTIME_DIR="${HOME}/.run"
                mkdir -p "${XDG_RUNTIME_DIR}"
                chmod 700 "${XDG_RUNTIME_DIR}"
              fi
              # Run `timeout` *inside* the xvfb helper so the helper's EXIT trap can reliably
              # clean up the background Xvfb process even when the command times out.
              bash scripts/xvfb-run-safe.sh timeout 45s "${bin}" --cross-origin-isolation-check
            )
            echo "::endgroup::"

            python3 scripts/ci/verify_linux_desktop_integration.py --package-root "${tmpdir}"

            rm -rf "${tmpdir}"
            trap - EXIT
          done

      - name: Upload desktop bundles (dry run)
        if: needs.preflight.outputs.upload != 'true'
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: desktop-bundles-${{ needs.preflight.outputs.artifact_label }}-${{ matrix.platform }}${{ matrix.rust_target != '' && format('-{0}', matrix.rust_target) || '' }}
          if-no-files-found: error
          path: |
            apps/desktop/src-tauri/target/release/bundle/**
            apps/desktop/src-tauri/target/*/release/bundle/**
            apps/desktop/target/release/bundle/**
            apps/desktop/target/*/release/bundle/**
            target/release/bundle/**
            target/*/release/bundle/**

      - name: Export updater manifest for merge (latest.json)
        if: needs.preflight.outputs.upload == 'true' && (github.repository == 'wilson-anysphere/formula' || secrets.TAURI_PRIVATE_KEY != '')
        run: node scripts/ci/export-updater-manifest.mjs "updater-manifest/latest-${{ matrix.cache_target }}.json"

      - name: Upload updater manifest artifact (per-platform)
        if: needs.preflight.outputs.upload == 'true' && (github.repository == 'wilson-anysphere/formula' || secrets.TAURI_PRIVATE_KEY != '')
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: updater-manifest-${{ matrix.cache_target }}
          path: updater-manifest/latest-${{ matrix.cache_target }}.json
          if-no-files-found: error

      - name: Verify Windows ARM64 MSI targets ARM64 (template summary)
        if: runner.os == 'Windows' && matrix.rust_target == 'aarch64-pc-windows-msvc'
        shell: pwsh
        run: |
          $ErrorActionPreference = "Stop"
          $target = "${{ matrix.rust_target }}"
          $bundleCandidates = @(
            (Join-Path $env:GITHUB_WORKSPACE "apps/desktop/src-tauri/target/$target/release/bundle"),
            (Join-Path $env:GITHUB_WORKSPACE "apps/desktop/target/$target/release/bundle"),
            (Join-Path $env:GITHUB_WORKSPACE "target/$target/release/bundle")
          )
          $bundleDir = $bundleCandidates | Where-Object { Test-Path $_ } | Select-Object -First 1
          if (-not $bundleDir) {
            $candidatesJoined = $bundleCandidates -join "`n"
            throw "windows-arm64-msi: ERROR expected Tauri bundle dir not found. Looked in:`n$candidatesJoined"
          }
          $msis = @(
            Get-ChildItem -Path (Join-Path $bundleDir "msi") -Recurse -File -Filter "*.msi" -ErrorAction SilentlyContinue
          )
          if ($msis.Count -eq 0) {
            throw "windows-arm64-msi: ERROR no .msi installers found under: $bundleDir"
          }

          $installer = New-Object -ComObject WindowsInstaller.Installer
          foreach ($msi in $msis) {
            $db = $installer.OpenDatabase($msi.FullName, 0)
            $summary = $db.SummaryInformation(0)
            $template = $summary.Property(7)
            Write-Host "windows-arm64-msi: $($msi.Name) template=$template"
            if ($template -notmatch '(?i)arm64') {
              throw "windows-arm64-msi: ERROR Expected MSI Template Summary to include ARM64 for $($msi.FullName), got: $template"
            }
          }

      - name: Verify Windows installers bundle/reference WebView2 (bootstrapper/runtime)
        if: runner.os == 'Windows'
        run: python scripts/ci/check-windows-webview2-installer.py

      - name: Verify Linux release artifacts (AppImage + deb + rpm + signatures)
        if: runner.os == 'Linux'
        shell: bash
        env:
          FORMULA_HAS_TAURI_UPDATER_KEY: ${{ secrets.TAURI_PRIVATE_KEY != '' }}
          # Updater signature files (`*.sig`) are only generated when the updater private key is
          # configured. Forks/dry-runs often have no secrets, so we skip `.sig` validation there.
          #
          # In the upstream repo we *require* updater signatures to avoid accidentally publishing
          # a release without auto-update metadata/signatures.
          FORMULA_REQUIRE_TAURI_UPDATER_SIGNATURES: ${{ github.repository == 'wilson-anysphere/formula' || secrets.TAURI_PRIVATE_KEY != '' }}
        run: |
          set -euo pipefail

          # Tauri bundles normally live under `src-tauri/target/release/bundle`, but can also
          # end up under `src-tauri/target/<triple>/release/bundle` if `--target` is used.
          bundle_roots=()
          # Prefer `CARGO_TARGET_DIR` if it's set (some Tauri builds export it), but also scan the
          # common workspace/default target roots.
          if [[ -n "${CARGO_TARGET_DIR:-}" ]]; then
            cargo_target_dir="${CARGO_TARGET_DIR}"
            if [[ "${cargo_target_dir}" != /* ]]; then
              cargo_target_dir="${PWD}/${cargo_target_dir}"
            fi
            if [[ -d "${cargo_target_dir}" ]]; then
              bundle_roots+=("${cargo_target_dir}")
            fi
          fi
          for root in "apps/desktop/src-tauri/target" "apps/desktop/target" "target"; do
            if [[ -d "$root" ]]; then
              bundle_roots+=("$root")
            fi
          done
          if ((${#bundle_roots[@]} == 0)); then
            echo "Expected Tauri target directory not found. Looked in: CARGO_TARGET_DIR=${CARGO_TARGET_DIR:-} apps/desktop/src-tauri/target apps/desktop/target target" >&2
            exit 1
          fi

          # Canonicalize + de-dupe bundle roots (avoid duplicate scanning when CARGO_TARGET_DIR overlaps defaults).
          declare -A seen_bundle_roots=()
          uniq_bundle_roots=()
          for root in "${bundle_roots[@]}"; do
            abs="$(cd "$root" && pwd -P)"
            if [[ -n "${seen_bundle_roots[${abs}]:-}" ]]; then
              continue
            fi
            seen_bundle_roots["${abs}"]=1
            uniq_bundle_roots+=("${abs}")
          done
          bundle_roots=("${uniq_bundle_roots[@]}")

          # Use predictable bundle globs (fast) rather than `find` (which traverses the entire Cargo target dir).
          shopt -s nullglob
          appimages=()
          debs=()
          rpms=()
          for root in "${bundle_roots[@]}"; do
            appimages+=("$root"/release/bundle/appimage/*.AppImage)
            appimages+=("$root"/*/release/bundle/appimage/*.AppImage)
            debs+=("$root"/release/bundle/deb/*.deb)
            debs+=("$root"/*/release/bundle/deb/*.deb)
            rpms+=("$root"/release/bundle/rpm/*.rpm)
            rpms+=("$root"/*/release/bundle/rpm/*.rpm)
          done
          shopt -u nullglob

          if ((${#appimages[@]} > 0)); then mapfile -t appimages < <(printf '%s\n' "${appimages[@]}" | sort -u); fi
          if ((${#debs[@]} > 0)); then mapfile -t debs < <(printf '%s\n' "${debs[@]}" | sort -u); fi
          if ((${#rpms[@]} > 0)); then mapfile -t rpms < <(printf '%s\n' "${rpms[@]}" | sort -u); fi

          echo "Bundle outputs:"
          printf '  AppImage: %s\n' "${#appimages[@]}"
          printf '  deb:      %s\n' "${#debs[@]}"
          printf '  rpm:      %s\n' "${#rpms[@]}"

          if ((${#appimages[@]} == 0)); then
            echo "Missing required Linux artifact: .AppImage" >&2
            exit 1
          fi
          if ((${#debs[@]} == 0)); then
            echo "Missing required Linux artifact: .deb" >&2
            exit 1
          fi
          if ((${#rpms[@]} == 0)); then
            echo "Missing required Linux artifact: .rpm" >&2
            exit 1
          fi

          if [[ "${FORMULA_REQUIRE_TAURI_UPDATER_SIGNATURES}" == "true" && "${FORMULA_HAS_TAURI_UPDATER_KEY}" != "true" ]]; then
            echo "TAURI_PRIVATE_KEY is required to validate updater signatures but is not configured." >&2
            exit 1
          fi

          if [[ "${FORMULA_REQUIRE_TAURI_UPDATER_SIGNATURES}" == "true" ]]; then
            # Ensure updater signature files exist for each bundle type.
            for artifact in "${appimages[@]}" "${debs[@]}" "${rpms[@]}"; do
              if [[ ! -f "${artifact}.sig" ]]; then
                echo "Missing signature file for ${artifact} (expected ${artifact}.sig)" >&2
                exit 1
              fi
            done
          else
            echo "TAURI_PRIVATE_KEY not configured; skipping updater signature (*.sig) verification."
          fi

      - name: Verify Linux package dependency metadata (deb + rpm)
        if: runner.os == 'Linux'
        run: bash scripts/ci/verify-linux-package-deps.sh

      - name: Verify macOS universal binary (lipo)
        if: runner.os == 'macOS'
        shell: bash
        run: |
          set -euo pipefail

          # Locate the packaged `.app` under the Tauri bundle output directory and verify the
          # main executable is a universal binary (x86_64 + arm64).
          #
           # Prefer the universal target output (`**/universal-apple-darwin/**`) to avoid
           # accidentally validating an intermediate single-arch bundle.
           app_path=""

           # Some Tauri builds export `CARGO_TARGET_DIR`. Normalize it for consistent path checks.
           cargo_target_dir="${CARGO_TARGET_DIR:-}"
           if [[ -n "$cargo_target_dir" && "$cargo_target_dir" != /* ]]; then
             cargo_target_dir="${PWD}/${cargo_target_dir}"
           fi

           # Fast path: avoid traversing large Cargo target directories by checking the canonical
           # bundle locations directly:
           # - <target>/release/bundle/*/*.app
           # - <target>/<triple>/release/bundle/*/*.app
           nullglob_was_set=0
           if shopt -q nullglob; then nullglob_was_set=1; fi
           shopt -s nullglob
           candidates=()

           # Prefer universal target output first.
           candidates+=(
             apps/desktop/src-tauri/target/universal-apple-darwin/release/bundle/*/*.app
           )

           if [[ -n "$cargo_target_dir" && -d "$cargo_target_dir" ]]; then
             candidates+=(
               "$cargo_target_dir"/universal-apple-darwin/release/bundle/*/*.app
               "$cargo_target_dir"/release/bundle/*/*.app
               "$cargo_target_dir"/*/release/bundle/*/*.app
             )
           fi

           candidates+=(
             target/universal-apple-darwin/release/bundle/*/*.app
             apps/desktop/target/universal-apple-darwin/release/bundle/*/*.app
             apps/desktop/src-tauri/target/release/bundle/*/*.app
             apps/desktop/src-tauri/target/*/release/bundle/*/*.app
             apps/desktop/target/release/bundle/*/*.app
             apps/desktop/target/*/release/bundle/*/*.app
             target/release/bundle/*/*.app
             target/*/release/bundle/*/*.app
           )

           if ((${#candidates[@]} > 0)); then
             app_path="${candidates[0]}"
           fi
           if [[ "${nullglob_was_set}" -eq 0 ]]; then shopt -u nullglob; fi

           # Fallback (slower): previous `find`-based discovery for unexpected layouts.
           if [[ -z "$app_path" ]]; then
             app_path="$(
               find apps/desktop/src-tauri/target/universal-apple-darwin -type d -path '*/release/bundle/*/*.app' -prune -print 2>/dev/null | head -n 1 || true
             )"
             if [[ -z "$app_path" ]]; then
               if [[ -n "$cargo_target_dir" && -d "$cargo_target_dir" ]]; then
                 app_path="$(
                   find "$cargo_target_dir/universal-apple-darwin" -type d -path '*/release/bundle/*/*.app' -prune -print 2>/dev/null | head -n 1 || true
                 )"
                 if [[ -z "$app_path" ]]; then
                   app_path="$(
                     find "$cargo_target_dir" -type d -path '*/release/bundle/*/*.app' -prune -print 2>/dev/null | head -n 1 || true
                   )"
                 fi
               fi
             fi
             if [[ -z "$app_path" ]]; then
               app_path="$(
                 find target/universal-apple-darwin -type d -path '*/release/bundle/*/*.app' -prune -print 2>/dev/null | head -n 1 || true
               )"
             fi
             if [[ -z "$app_path" ]]; then
               app_path="$(
                 find apps/desktop/target/universal-apple-darwin -type d -path '*/release/bundle/*/*.app' -prune -print 2>/dev/null | head -n 1 || true
               )"
             fi
             if [[ -z "$app_path" ]]; then
               app_path="$(
                 find apps/desktop/src-tauri/target -type d -path '*/release/bundle/*/*.app' -prune -print 2>/dev/null | head -n 1 || true
               )"
             fi
             if [[ -z "$app_path" ]]; then
               app_path="$(
                 find apps/desktop/target -type d -path '*/release/bundle/*/*.app' -prune -print 2>/dev/null | head -n 1 || true
               )"
             fi
             if [[ -z "$app_path" ]]; then
               app_path="$(
                 find target -type d -path '*/release/bundle/*/*.app' -prune -print 2>/dev/null | head -n 1 || true
               )"
             fi
           fi

           if [[ -z "$app_path" ]]; then
             echo "::error::No .app bundle found under the expected Cargo target directories (CARGO_TARGET_DIR=${CARGO_TARGET_DIR:-})." >&2
             if [[ -n "${CARGO_TARGET_DIR:-}" ]]; then
              echo
              echo "CARGO_TARGET_DIR *.app bundles:"
              find "${cargo_target_dir}" -type d -name '*.app' -print 2>/dev/null || true
            fi
            echo "apps/desktop/src-tauri/target *.app bundles:"
            find apps/desktop/src-tauri/target -type d -name '*.app' -print 2>/dev/null || true
            echo
            echo "apps/desktop/target *.app bundles:"
            find apps/desktop/target -type d -name '*.app' -print 2>/dev/null || true
            echo
            echo "target *.app bundles:"
            find target -type d -name '*.app' -print 2>/dev/null || true
            exit 1
          fi

          echo "Found app bundle: $app_path"
          macos_dir="$app_path/Contents/MacOS"
          if [[ ! -d "$macos_dir" ]]; then
            echo "::error::Expected Contents/MacOS directory not found: $macos_dir" >&2
            find "$app_path/Contents" -maxdepth 2 -print 2>/dev/null || true
            exit 1
          fi

          # Prefer the bundle-declared executable (CFBundleExecutable) so this check stays correct
          # even if the binary name changes.
          exe_name=""
          info_plist="$app_path/Contents/Info.plist"
          if [[ -f "$info_plist" ]]; then
            exe_name="$(/usr/libexec/PlistBuddy -c 'Print :CFBundleExecutable' "$info_plist" 2>/dev/null || true)"
          fi
          if [[ -z "$exe_name" ]]; then
            exe_name="formula-desktop"
          fi

          bin_path="$macos_dir/$exe_name"
          if [[ ! -f "$bin_path" ]]; then
            # Fall back to the first executable file under Contents/MacOS (avoid picking non-binaries).
            bin_path="$(find "$macos_dir" -maxdepth 1 -type f -perm -0100 -print | head -n 1 || true)"
          fi
          if [[ -z "$bin_path" || ! -f "$bin_path" ]]; then
            echo "::error::Could not find app executable under $macos_dir" >&2
            ls -la "$macos_dir" || true
            exit 1
          fi

          echo "Checking architectures for: $bin_path"
          info="$(lipo -info "$bin_path" | tee /dev/stderr)"
          echo "$info" | grep -qw "x86_64" || { echo "::error::macOS binary is missing x86_64 slice"; exit 1; }
          echo "$info" | grep -qw "arm64" || { echo "::error::macOS binary is missing arm64 slice"; exit 1; }

      - name: Verify Windows ARM64 binary (formula-desktop.exe is AA64)
        if: matrix.rust_target == 'aarch64-pc-windows-msvc'
        shell: pwsh
        run: |
          $ErrorActionPreference = 'Stop'

          $exeCandidates = @(
            (Join-Path $env:GITHUB_WORKSPACE 'apps/desktop/src-tauri/target/aarch64-pc-windows-msvc/release/formula-desktop.exe'),
            (Join-Path $env:GITHUB_WORKSPACE 'target/aarch64-pc-windows-msvc/release/formula-desktop.exe')
          )
          $exe = $exeCandidates | Where-Object { Test-Path $_ } | Select-Object -First 1
          if (!$exe) {
            Write-Error "Expected ARM64 executable not found. Looked in:`n$($exeCandidates -join [Environment]::NewLine)`nDid the build run with --target aarch64-pc-windows-msvc?"
            exit 1
          }

          # Locate dumpbin from the installed Visual Studio toolchain.
          $vswhere = Join-Path ${env:ProgramFiles(x86)} 'Microsoft Visual Studio/Installer/vswhere.exe'
          if (!(Test-Path $vswhere)) {
            Write-Error "vswhere.exe not found at: $vswhere"
            exit 1
          }

          $vsInstall = & $vswhere -latest -products * -requires Microsoft.Component.MSBuild -property installationPath
          if (!$vsInstall) {
            Write-Error 'Unable to locate a Visual Studio installation via vswhere.'
            exit 1
          }

          $msvcRoot = Join-Path $vsInstall 'VC/Tools/MSVC'
          if (!(Test-Path $msvcRoot)) {
            Write-Error "MSVC tools dir not found at: $msvcRoot"
            exit 1
          }

          # Prefer predictable MSVC layout (avoid recursively scanning the entire tools directory).
          # Typical path:
          #   <msvcRoot>/<version>/bin/Hostx64/x64/dumpbin.exe
          $dumpbin = $null
          $versionDirs = @()
          try {
            $versionDirs = @(
              Get-ChildItem -Path $msvcRoot -Directory -ErrorAction SilentlyContinue |
                Sort-Object -Property Name -Descending
            )
          } catch {
            $versionDirs = @()
          }
          foreach ($v in $versionDirs) {
            $candidate = Join-Path $v.FullName (Join-Path 'bin' (Join-Path 'Hostx64' (Join-Path 'x64' 'dumpbin.exe')))
            if (Test-Path $candidate) {
              $dumpbin = Get-Item -LiteralPath $candidate
              break
            }
          }
          if (!$dumpbin) {
            # Fallback: recursive search (slower) in case MSVC layout differs.
            $dumpbin = Get-ChildItem -Path $msvcRoot -Filter dumpbin.exe -Recurse -ErrorAction SilentlyContinue |
              Where-Object { $_.FullName -match '\\bin\\Hostx64\\x64\\dumpbin\.exe$' } |
              Sort-Object -Property FullName -Descending |
              Select-Object -First 1
          }

          if (!$dumpbin) {
            Write-Error "dumpbin.exe not found under: $msvcRoot"
            exit 1
          }

          $headers = & $dumpbin.FullName /headers $exe
          $headersText = ($headers | Out-String)
          Write-Host $headersText

          if ($headersText -notmatch 'AA64') {
            Write-Error "Expected ARM64 machine type 'AA64' in dumpbin output, but it was not found."
            exit 1
          }

          if ($headersText -match '8664') {
            Write-Error "Binary appears to be x64 (machine type '8664'), expected ARM64 (AA64)."
            exit 1
          }

      - name: Verify Windows ARM64 updater signatures exist
        if: matrix.rust_target == 'aarch64-pc-windows-msvc' && secrets.TAURI_PRIVATE_KEY != ''
        shell: pwsh
        run: |
          $ErrorActionPreference = 'Stop'

          $bundleCandidates = @(
            (Join-Path $env:GITHUB_WORKSPACE 'apps/desktop/src-tauri/target/aarch64-pc-windows-msvc/release/bundle'),
            (Join-Path $env:GITHUB_WORKSPACE 'target/aarch64-pc-windows-msvc/release/bundle')
          )
          $bundleDir = $bundleCandidates | Where-Object { Test-Path $_ } | Select-Object -First 1
          if (!$bundleDir) {
            Write-Error "Bundle output dir not found. Looked in:`n$($bundleCandidates -join [Environment]::NewLine)"
            exit 1
          }

          $sigs = Get-ChildItem -Path $bundleDir -Recurse -File -Filter '*.sig'
          if ($sigs.Count -lt 1) {
            Write-Error "No updater signature files (*.sig) found under: $bundleDir"
            exit 1
          }

          Write-Host "Found updater signatures:"
          $sigs | ForEach-Object { Write-Host "- $($_.FullName)" }

      - name: Validate desktop release artifacts
        env:
          FORMULA_HAS_TAURI_UPDATER_KEY: ${{ secrets.TAURI_PRIVATE_KEY != '' }}
          # `latest.json` is only generated/uploaded when we publish to a GitHub Release.
          # In dry-run (workflow_dispatch upload=false) we still validate installer artifacts exist,
          # but we skip enforcing updater signatures/manifest files.
          FORMULA_REQUIRE_TAURI_UPDATER_SIGNATURES: ${{ needs.preflight.outputs.upload == 'true' && (github.repository == 'wilson-anysphere/formula' || secrets.TAURI_PRIVATE_KEY != '') }}
        run: node scripts/ci/check-desktop-release-artifacts.mjs

      - name: Verify macOS bundle file associations + deep link schemes
        if: runner.os == 'macOS'
        shell: bash
        run: |
          set -euo pipefail

          # Cargo workspaces typically emit bundle outputs under `<repo>/target/**`, but standalone
          # Tauri projects may use `<src-tauri>/target/**`, and some CI/caching setups override
          # CARGO_TARGET_DIR. Search all common roots so this check doesn't fail due to layout
          # differences.
          search_roots=()
          if [[ -n "${CARGO_TARGET_DIR:-}" ]]; then
            cargo_target_dir="${CARGO_TARGET_DIR}"
            if [[ "${cargo_target_dir}" != /* ]]; then
              cargo_target_dir="${PWD}/${cargo_target_dir}"
            fi
            if [[ -d "${cargo_target_dir}" ]]; then
              search_roots+=("${cargo_target_dir}")
            fi
          fi
          for root in "apps/desktop/src-tauri/target" "apps/desktop/target" "target"; do
            if [[ -d "${root}" ]]; then
              search_roots+=("${root}")
            fi
          done

          app_path=""
          for root in "${search_roots[@]}"; do
            # Fast path: avoid traversing the entire Cargo target directory (which can be large)
            # by checking the canonical bundle locations directly:
            # - <target>/release/bundle/macos/*.app
            # - <target>/<triple>/release/bundle/macos/*.app
            nullglob_was_set=0
            if shopt -q nullglob; then nullglob_was_set=1; fi
            shopt -s nullglob
            candidates=(
              "$root"/release/bundle/macos/*.app
              "$root"/*/release/bundle/macos/*.app
            )
            if [[ "${nullglob_was_set}" -eq 0 ]]; then shopt -u nullglob; fi

            if ((${#candidates[@]} > 0)); then
              app_path="${candidates[0]}"
              break
            fi
          done

          # Fallback (slower): scan with `find` if the bundle layout is unexpected.
          if [[ -z "${app_path}" ]]; then
            for root in "${search_roots[@]}"; do
              candidate="$(find "$root" -type d -path '*/release/bundle/macos/*.app' -prune -print 2>/dev/null | head -n 1 || true)"
              if [[ -n "$candidate" ]]; then
                app_path="$candidate"
                break
              fi
            done
          fi

          if [[ -z "${app_path}" ]]; then
            echo "::error::Could not find a built .app bundle under expected target roots." >&2
            echo "Searched roots: ${search_roots[*]}" >&2
            for root in "${search_roots[@]}"; do
              echo "Available .app directories under $root (first 20):" >&2
              find "$root" -maxdepth 12 -type d -name '*.app' -print 2>/dev/null | head -n 20 || true
            done
            exit 1
          fi

          info_plist="${app_path}/Contents/Info.plist"
          if [[ ! -f "${info_plist}" ]]; then
            echo "::error::Missing Info.plist at: ${info_plist}" >&2
            exit 1
          fi

          echo "App bundle: ${app_path}"
          echo "Info.plist: ${info_plist}"
          echo "::group::plutil -p ${info_plist} (first 200 lines)"
          plutil -p "${info_plist}" | head -n 200
          echo "::endgroup::"

          python3 scripts/ci/verify_macos_bundle_associations.py --info-plist "${info_plist}"

      - name: Verify Linux desktop integration in packages (.deb + .rpm)
        if: runner.os == 'Linux'
        shell: bash
        run: |
          set -euo pipefail

          # Prefer predictable globs over `find` to avoid traversing large Cargo target directories.
          # Also support alternative Cargo output roots (apps/desktop/target and CARGO_TARGET_DIR).
          shopt -s nullglob
          roots=()
          if [[ -n "${CARGO_TARGET_DIR:-}" ]]; then
            roots+=("${CARGO_TARGET_DIR}")
          fi
          roots+=("apps/desktop/src-tauri/target" "apps/desktop/target" "target")

          debs=()
          for root in "${roots[@]}"; do
            [[ -d "${root}" ]] || continue
            debs+=("${root}"/release/bundle/deb/*.deb)
            debs+=("${root}"/*/release/bundle/deb/*.deb)
          done
          if ((${#debs[@]} > 0)); then mapfile -t debs < <(printf '%s\n' "${debs[@]}" | sort -u); fi
          shopt -u nullglob

          deb="${debs[0]:-}"
          if [[ -z "${deb}" ]]; then
            echo "::error::Could not find a .deb under any target root (expected <target>/release/bundle/deb/*.deb or <target>/<triple>/release/bundle/deb/*.deb)" >&2
            echo "Searched roots:" >&2
            printf '  - %s\n' "${roots[@]}" >&2
            exit 1
          fi

          echo "Validating .deb desktop integration: ${deb}"
          tmpdir_deb="$(mktemp -d)"
          dpkg-deb -x "${deb}" "${tmpdir_deb}"
          python3 scripts/ci/verify_linux_desktop_integration.py --package-root "${tmpdir_deb}"

          shopt -s nullglob
          rpms=()
          for root in "${roots[@]}"; do
            [[ -d "${root}" ]] || continue
            rpms+=("${root}"/release/bundle/rpm/*.rpm)
            rpms+=("${root}"/*/release/bundle/rpm/*.rpm)
          done
          if ((${#rpms[@]} > 0)); then mapfile -t rpms < <(printf '%s\n' "${rpms[@]}" | sort -u); fi
          shopt -u nullglob

          rpm_path="${rpms[0]:-}"
          if [[ -z "${rpm_path}" ]]; then
            echo "::error::Could not find a .rpm under any target root (expected <target>/release/bundle/rpm/*.rpm or <target>/<triple>/release/bundle/rpm/*.rpm)" >&2
            echo "Searched roots:" >&2
            printf '  - %s\n' "${roots[@]}" >&2
            exit 1
          fi

          if ! command -v rpm2cpio >/dev/null 2>&1; then
            echo "::error::rpm2cpio is required to extract .rpm artifacts for validation (missing on PATH)" >&2
            exit 1
          fi
          if ! command -v cpio >/dev/null 2>&1; then
            echo "::error::cpio is required to extract .rpm artifacts for validation (missing on PATH)" >&2
            exit 1
          fi

          echo "Validating .rpm desktop integration: ${rpm_path}"
          tmpdir_rpm="$(mktemp -d)"
          # `find` may return a relative path; run `rpm2cpio` from the repo root and only `cd`
          # for the `cpio` extraction destination.
          rpm2cpio "${rpm_path}" | (cd "${tmpdir_rpm}" && cpio -idm --quiet --no-absolute-filenames)
          python3 scripts/ci/verify_linux_desktop_integration.py --package-root "${tmpdir_rpm}"

      - name: Smoke test Linux .deb install in clean Ubuntu container
        if: runner.os == 'Linux'
        run: bash scripts/ci/linux-package-install-smoke.sh deb

      - name: Smoke test Linux .rpm install in clean Fedora container
        if: runner.os == 'Linux'
        run: bash scripts/ci/linux-package-install-smoke.sh rpm

      - name: Smoke test Linux .rpm install in clean openSUSE container (optional)
        if: runner.os == 'Linux' && vars.FORMULA_OPENSUSE_SMOKE == '1'
        env:
          FORMULA_RPM_SMOKE_IMAGE: opensuse/tumbleweed:latest
        run: bash scripts/ci/linux-package-install-smoke.sh rpm
      - name: Dump macOS effective entitlements (codesign) (signed builds only)
        if: runner.os == 'macOS'
        shell: bash
        run: |
          # Only run when signing secrets are configured. On forks/dry-runs we build unsigned
          # artifacts (see `scripts/ci/prepare-tauri-signing-config.mjs`).
          if [[ -z "${APPLE_CERTIFICATE:-}" || -z "${APPLE_CERTIFICATE_PASSWORD:-}" ]]; then
            echo "Skipping entitlements dump: macOS signing secrets not configured (unsigned build)."
            exit 0
          fi

          search_roots=(target apps/desktop/src-tauri/target apps/desktop/target)
          app_path=""

          # Fast path: avoid traversing large Cargo target dirs by checking expected bundle locations directly.
          for root in "${search_roots[@]}"; do
            [[ -d "$root" ]] || continue

            nullglob_was_set=0
            if shopt -q nullglob; then nullglob_was_set=1; fi
            shopt -s nullglob
            candidates=(
              "$root"/release/bundle/macos/Formula.app
              "$root"/*/release/bundle/macos/Formula.app
            )
            if [[ "${nullglob_was_set}" -eq 0 ]]; then shopt -u nullglob; fi

            if ((${#candidates[@]} > 0)); then
              app_path="${candidates[0]}"
              break
            fi
          done

          if [[ -z "$app_path" ]]; then
            for root in "${search_roots[@]}"; do
              [[ -d "$root" ]] || continue

              nullglob_was_set=0
              if shopt -q nullglob; then nullglob_was_set=1; fi
              shopt -s nullglob
              candidates=(
                "$root"/release/bundle/macos/*.app
                "$root"/*/release/bundle/macos/*.app
              )
              if [[ "${nullglob_was_set}" -eq 0 ]]; then shopt -u nullglob; fi

              if ((${#candidates[@]} > 0)); then
                app_path="${candidates[0]}"
                break
              fi
            done
          fi

          # Fallback (slower): scan with `find` if the bundle layout is unexpected.
          if [[ -z "$app_path" ]]; then
            for root in "${search_roots[@]}"; do
              if [[ -d "$root" ]]; then
                candidate="$(find "$root" -type d -path "*/release/bundle/macos/Formula.app" | head -n 1 || true)"
                if [[ -n "$candidate" ]]; then
                  app_path="$candidate"
                  break
                fi
              fi
            done
          fi

          if [[ -z "$app_path" ]]; then
            for root in "${search_roots[@]}"; do
              if [[ -d "$root" ]]; then
                candidate="$(find "$root" -type d -path "*/release/bundle/macos/*.app" | head -n 1 || true)"
                if [[ -n "$candidate" ]]; then
                  app_path="$candidate"
                  break
                fi
              fi
            done
          fi

          if [[ -z "$app_path" ]]; then
            echo "No .app bundle found under expected Tauri bundle roots; skipping."
            exit 0
          fi

          echo "Found app bundle: $app_path"

          echo "::group::codesign --verify $app_path"
          if ! /usr/bin/codesign --verify --deep --strict --verbose=2 "$app_path"; then
            echo "::error::codesign verification failed for app bundle: $app_path" >&2
            exit 1
          fi
          echo "::endgroup::"

          exe_path="$app_path/Contents/MacOS/formula-desktop"
          if [[ ! -f "$exe_path" ]]; then
            exe_path="$(find "$app_path/Contents/MacOS" -maxdepth 1 -type f | head -n 1 || true)"
          fi

          if [[ -z "$exe_path" || ! -f "$exe_path" ]]; then
            echo "Could not locate main executable inside: $app_path"
            exit 0
          fi

          echo "Dumping effective entitlements from: $exe_path"
          /usr/bin/codesign -d --entitlements :- "$exe_path" || true
      - name: Verify desktop binary is stripped (no symbols)
        run: python scripts/verify_desktop_binary_stripped.py

      - name: Report desktop installer artifact sizes
        env:
          # Enforce the installer artifact size budget on tagged releases by default.
          # Override via GitHub Actions "Variables":
          # - FORMULA_ENFORCE_BUNDLE_SIZE=0 (or "false") to disable enforcement
          # - FORMULA_BUNDLE_SIZE_LIMIT_MB=50 to adjust the default 50 MB budget
          FORMULA_ENFORCE_BUNDLE_SIZE: ${{ vars.FORMULA_ENFORCE_BUNDLE_SIZE || '1' }}
          FORMULA_BUNDLE_SIZE_LIMIT_MB: ${{ vars.FORMULA_BUNDLE_SIZE_LIMIT_MB }}
        run: python scripts/desktop_bundle_size_report.py --json desktop-bundle-size-report.json

      - name: Restore CI-only Tauri config patches
        shell: bash
        run: |
          set -euo pipefail
          # `scripts/ci/prepare-tauri-signing-config.mjs` may patch `tauri.conf.json` in-place for
          # fork-friendly unsigned builds / per-run timestamp URL overrides. Reset it so subsequent
          # reproducibility guards only fail on unexpected tracked file changes.
          git restore --source=HEAD -- apps/desktop/src-tauri/tauri.conf.json

      - name: Fail if the build modified tracked files
        shell: bash
        run: git diff --exit-code

      - name: Upload desktop installer artifact size report (JSON)
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          # Note: historical name; the report contains per-installer artifact sizes (DMG/MSI/AppImage/etc).
          name: desktop-bundle-size-report-${{ needs.preflight.outputs.artifact_label }}-${{ matrix.platform }}${{ matrix.rust_target != '' && format('-{0}', matrix.rust_target) || '' }}
          path: desktop-bundle-size-report.json
          if-no-files-found: warn

  build-dry-run:
    name: Build (dry run) (${{ matrix.label }})
    needs: preflight
    if: needs.preflight.outputs.upload != 'true'
    permissions:
      contents: read
    strategy: *build_strategy
    runs-on: ${{ matrix.platform }}
    steps: *build_steps

  publish-updater-manifest:
    name: Publish combined updater manifest (latest.json)
    needs: [build, preflight]
    # Publishing `latest.json` requires updater signatures (`latest.json.sig`) which are only
    # produced when TAURI_PRIVATE_KEY is configured. We only publish in the upstream repo or when
    # forks have configured their own updater key secrets.
    if: needs.preflight.outputs.upload == 'true' && (github.repository == 'wilson-anysphere/formula' || secrets.TAURI_PRIVATE_KEY != '')
    runs-on: ubuntu-24.04
    permissions:
      contents: write
      actions: read
    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

      - name: Setup Node
        uses: actions/setup-node@6044e13b5dc448c55e2357c09f80417699197238 # v6.2.0
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Download per-platform updater manifests
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          pattern: updater-manifest-*
          path: updater-manifest
          merge-multiple: true

      - name: Publish combined updater manifest (latest.json + latest.json.sig)
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          TAURI_PRIVATE_KEY: ${{ secrets.TAURI_PRIVATE_KEY }}
          TAURI_KEY_PASSWORD: ${{ secrets.TAURI_KEY_PASSWORD }}
        run: node scripts/ci/publish-updater-manifest.mjs "${{ needs.preflight.outputs.release_tag }}" updater-manifest

  verify-updater-manifest:
    name: Verify updater manifest (latest.json)
    needs: [publish-updater-manifest, preflight]
    # Validating the updater manifest requires updater signatures (`latest.json.sig`), which are
    # only produced when the TAURI_PRIVATE_KEY secret is configured. We always validate in the
    # upstream repo (to avoid accidentally shipping an unsigned updater manifest) and validate in
    # forks only when the user has configured their own updater key secrets.
    if: needs.preflight.outputs.upload == 'true' && (github.repository == 'wilson-anysphere/formula' || secrets.TAURI_PRIVATE_KEY != '')
    runs-on: ubuntu-24.04
    permissions:
      contents: read
    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

      - name: Setup Node
        uses: actions/setup-node@6044e13b5dc448c55e2357c09f80417699197238 # v6.2.0
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Validate updater manifest assets + targets
        env:
          # The validator uses the GitHub API to read/download assets from the draft release.
          # Set both token env vars so it works whether it looks for GH_TOKEN or GITHUB_TOKEN.
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: node scripts/verify-tauri-latest-json.mjs "${{ needs.preflight.outputs.release_tag }}"

      - name: Verify updater manifest signature matches embedded pubkey
        run: node scripts/ci/verify-updater-manifest-signature.mjs latest.json latest.json.sig

      - name: Verify updater asset set (installers + signatures)
        env:
          # This validator also uses the GitHub API to read/download assets from the draft release.
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: node scripts/verify-tauri-updater-assets.mjs "${{ needs.preflight.outputs.release_tag }}"
  verify-release-assets:
    name: Verify GitHub Release assets (multi-arch safe)
    # Wait for the combined updater manifest publish step so we don't race while `latest.json`
    # is being deleted/re-uploaded.
    needs: [publish-updater-manifest, preflight, upload-sbom]
    if: needs.preflight.outputs.upload == 'true' && (github.repository == 'wilson-anysphere/formula' || secrets.TAURI_PRIVATE_KEY != '')
    runs-on: ubuntu-24.04
    permissions:
      contents: read
    steps:
      - name: Validate release assets are present and uniquely named per target
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          TAG_NAME: ${{ needs.preflight.outputs.release_tag }}
          # Optional strict mode: set this as a GitHub Actions Variable to make missing
          # SBOM/provenance assets fail the workflow (off by default).
          FORMULA_ENFORCE_SUPPLY_CHAIN_ASSETS: ${{ vars.FORMULA_ENFORCE_SUPPLY_CHAIN_ASSETS }}
        shell: bash
        run: |
          set -euo pipefail

          repo="${GITHUB_REPOSITORY}"
          tag="${TAG_NAME}"

          api_base="${GITHUB_API_URL:-https://api.github.com}"
          api_base="${api_base%/}"
          api_url="${api_base}/repos/${repo}/releases/tags/${tag}"
          retry_delays=(2 4 8 12 20)
          # Tauri output naming varies slightly between bundlers (e.g. "x64", "x86_64", "x86-64", "amd64", "win64").
          # Treat these as equivalent x64 markers for collision detection.
          win_x64_re='(x64|x86[_-]64|amd64|win64)'
          win_arm64_re='(arm64|aarch64)'
          linux_x64_re='(x64|x86[_-]64|amd64)'
          linux_arm64_re='(arm64|aarch64)'

          fetch_release() {
            curl -sSfL \
              -H "Authorization: Bearer ${GH_TOKEN}" \
              -H 'Accept: application/vnd.github+json' \
              -H 'X-GitHub-Api-Version: 2022-11-28' \
              "${api_url}"
          }

          fetch_assets() {
            local release_id="$1"
            local per_page=100
            local page=1
            local all='[]'

            while :; do
              page_json="$(curl -sSfL \
                -H "Authorization: Bearer ${GH_TOKEN}" \
                -H 'Accept: application/vnd.github+json' \
                -H 'X-GitHub-Api-Version: 2022-11-28' \
                "${api_base}/repos/${repo}/releases/${release_id}/assets?per_page=${per_page}&page=${page}")"

              all="$(jq -s '.[0] + .[1]' <(echo "$all") <(echo "$page_json"))"

              page_len="$(echo "$page_json" | jq -r 'length')"
              if [[ "$page_len" -lt "$per_page" ]]; then
                break
              fi
              page=$((page + 1))
            done

            echo "$all"
          }

          # Returns 0 if all required assets are present; 1 otherwise.
          assets_ready() {
            local json="$1"

            local missing=0

            count_matches() {
              local re="$1"
              echo "$json" | jq -r --arg re "$re" '[.[].name | select(test($re; "i"))] | length'
            }

            require_min() {
              local label="$1"
              local re="$2"
              local min="$3"
              local count
              count="$(count_matches "$re")"
              if [[ "$count" -lt "$min" ]]; then
                echo "missing: ${label} (pattern: ${re}, found: ${count}, expected >= ${min})" >&2
                missing=1
              fi
            }

            require_min "latest.json" '^latest\.json$' 1
            require_min "latest.json.sig" '^latest\.json\.sig$' 1
            require_min "macOS DMG" '\.dmg$' 1

            # Tauri's macOS updater artifact is a tarball archive (distinct from the `.dmg`).
            # The conventional filename ends with `*.app.tar.gz`, but some toolchains may produce
            # `*.tar.gz` / `*.tgz`. Keep this permissive while excluding obvious non-mac tarballs
            # like Linux AppImage archives.
            mac_archive_count="$(echo "$json" | jq -r '[.[].name
              | select(test("\\.(tar\\.gz|tgz)$"; "i"))
              | select(test("\\.AppImage\\.(tar\\.gz|tgz)$"; "i") | not)
            ] | length')"
            if [[ "$mac_archive_count" -lt 1 ]]; then
              echo "missing: macOS updater archive (expected >= 1 tarball: *.app.tar.gz preferred; allow *.tar.gz/*.tgz). Found ${mac_archive_count}." >&2
              missing=1
            fi

            # Windows multi-arch: ensure distinct installers per architecture were uploaded.
            count_windows_arch() {
              local ext_re="$1"
              local arch_re="$2"
              local other_arch_re="$3"
              echo "$json" | jq -r --arg ext "$ext_re" --arg arch "$arch_re" --arg other "$other_arch_re" '[.[].name
                | select(test($ext; "i"))
                # Exclude embedded helper installers (notably WebView2 bootstrapper/runtime executables),
                # which are not the Formula installer artifacts we ship on GitHub Releases.
                | select(test("microsoftedgewebview2"; "i") | not)
                | select(test($arch; "i"))
                | select(test($other; "i") | not)
              ] | length'
            }

            win_x64_msi_count="$(count_windows_arch '\\.msi$' "$win_x64_re" "$win_arm64_re")"
            win_x64_exe_count="$(count_windows_arch '\\.exe$' "$win_x64_re" "$win_arm64_re")"
            win_arm64_msi_count="$(count_windows_arch '\\.msi$' "$win_arm64_re" "$win_x64_re")"
            win_arm64_exe_count="$(count_windows_arch '\\.exe$' "$win_arm64_re" "$win_x64_re")"

            if [[ "$win_x64_msi_count" -lt 1 ]]; then
              echo "missing: Windows x64 MSI (expected >= 1, found ${win_x64_msi_count})" >&2
              missing=1
            fi
            if [[ "$win_x64_exe_count" -lt 1 ]]; then
              echo "missing: Windows x64 EXE (expected >= 1, found ${win_x64_exe_count})" >&2
              missing=1
            fi
            if [[ "$win_arm64_msi_count" -lt 1 ]]; then
              echo "missing: Windows arm64 MSI (expected >= 1, found ${win_arm64_msi_count})" >&2
              missing=1
            fi
            if [[ "$win_arm64_exe_count" -lt 1 ]]; then
              echo "missing: Windows arm64 EXE (expected >= 1, found ${win_arm64_exe_count})" >&2
              missing=1
            fi

            # Linux artifacts shipped on tagged releases.
            require_min "Linux AppImage" '\.AppImage$' 1
            require_min "Linux DEB" '\.deb$' 1
            require_min "Linux RPM" '\.rpm$' 1

            # Linux multi-arch: ensure we shipped installers/packages for both x86_64 and arm64 so
            # they can't clobber each other on the GitHub Release.
            count_linux_arch() {
              local ext_re="$1"
              local arch_re="$2"
              local other_arch_re="$3"
              echo "$json" | jq -r --arg ext "$ext_re" --arg arch "$arch_re" --arg other "$other_arch_re" '[.[].name
                | select(test($ext; "i"))
                | select(test($arch; "i"))
                | select(test($other; "i") | not)
              ] | length'
            }

            linux_x64_appimage_count="$(count_linux_arch '\\.AppImage$' "$linux_x64_re" "$linux_arm64_re")"
            linux_arm64_appimage_count="$(count_linux_arch '\\.AppImage$' "$linux_arm64_re" "$linux_x64_re")"
            linux_x64_deb_count="$(count_linux_arch '\\.deb$' "$linux_x64_re" "$linux_arm64_re")"
            linux_arm64_deb_count="$(count_linux_arch '\\.deb$' "$linux_arm64_re" "$linux_x64_re")"
            linux_x64_rpm_count="$(count_linux_arch '\\.rpm$' "$linux_x64_re" "$linux_arm64_re")"
            linux_arm64_rpm_count="$(count_linux_arch '\\.rpm$' "$linux_arm64_re" "$linux_x64_re")"

            if [[ "$linux_x64_appimage_count" -lt 1 ]]; then
              echo "missing: Linux x86_64 AppImage (expected >= 1, found ${linux_x64_appimage_count})" >&2
              missing=1
            fi
            if [[ "$linux_arm64_appimage_count" -lt 1 ]]; then
              echo "missing: Linux ARM64 AppImage (expected >= 1, found ${linux_arm64_appimage_count})" >&2
              missing=1
            fi
            if [[ "$linux_x64_deb_count" -lt 1 ]]; then
              echo "missing: Linux x86_64 DEB (expected >= 1, found ${linux_x64_deb_count})" >&2
              missing=1
            fi
            if [[ "$linux_arm64_deb_count" -lt 1 ]]; then
              echo "missing: Linux ARM64 DEB (expected >= 1, found ${linux_arm64_deb_count})" >&2
              missing=1
            fi
            if [[ "$linux_x64_rpm_count" -lt 1 ]]; then
              echo "missing: Linux x86_64 RPM (expected >= 1, found ${linux_x64_rpm_count})" >&2
              missing=1
            fi
            if [[ "$linux_arm64_rpm_count" -lt 1 ]]; then
              echo "missing: Linux ARM64 RPM (expected >= 1, found ${linux_arm64_rpm_count})" >&2
              missing=1
            fi

            linux_archless_count="$(echo "$json" | jq -r --arg x64 "$linux_x64_re" --arg arm64 "$linux_arm64_re" '[.[].name
              | select(test("\\.(AppImage|deb|rpm)$"; "i"))
              | select((test($x64; "i") or test($arm64; "i")) | not)
            ] | length')"
            if [[ "$linux_archless_count" -ne 0 ]]; then
              echo "missing: found ${linux_archless_count} Linux package/bundle asset(s) without an arch token" >&2
              missing=1
            fi

            linux_ambiguous_count="$(echo "$json" | jq -r --arg x64 "$linux_x64_re" --arg arm64 "$linux_arm64_re" '[.[].name
              | select(test("\\.(AppImage|deb|rpm)$"; "i"))
              | select(test($x64; "i"))
              | select(test($arm64; "i"))
            ] | length')"
            if [[ "$linux_ambiguous_count" -ne 0 ]]; then
              echo "missing: found ${linux_ambiguous_count} Linux package/bundle asset(s) matching BOTH x86_64 and arm64 patterns (ambiguous naming)" >&2
              missing=1
            fi

            windows_archless_count="$(echo "$json" | jq -r --arg x64 "$win_x64_re" --arg arm64 "$win_arm64_re" '[.[].name
              | select(test("\\.(msi|exe)$"; "i"))
              | select(test("microsoftedgewebview2"; "i") | not)
              | select((test($x64; "i") or test($arm64; "i")) | not)
            ] | length')"
            if [[ "$windows_archless_count" -ne 0 ]]; then
              echo "missing: found ${windows_archless_count} Windows installer asset(s) without an arch token" >&2
              missing=1
            fi

            windows_ambiguous_count="$(echo "$json" | jq -r --arg x64 "$win_x64_re" --arg arm64 "$win_arm64_re" '[.[].name
              | select(test("\\.(msi|exe)$"; "i"))
              | select(test("microsoftedgewebview2"; "i") | not)
              | select(test($x64; "i"))
              | select(test($arm64; "i"))
            ] | length')"
            if [[ "$windows_ambiguous_count" -ne 0 ]]; then
              echo "missing: found ${windows_ambiguous_count} Windows installer asset(s) matching BOTH x64 and arm64 patterns (ambiguous naming)" >&2
              missing=1
            fi

            require_sigs_for_ext() {
              local label="$1"
              local ext_re="$2"
              local exclude_re="${3:-}"
              local missing_sig_bases
              if [[ -n "${exclude_re}" ]]; then
                missing_sig_bases="$(echo "$json" | jq -r --arg ext "$ext_re" --arg exclude "$exclude_re" '
                  ([.[].name] | unique) as $names |
                  [ $names[]
                    | select(test($ext; "i"))
                    | select(test($exclude; "i") | not)
                    | select(($names | index(. + ".sig")) == null)
                  ] | .[]')"
              else
                missing_sig_bases="$(echo "$json" | jq -r --arg ext "$ext_re" '
                  ([.[].name] | unique) as $names |
                  [ $names[]
                    | select(test($ext; "i"))
                    | select(($names | index(. + ".sig")) == null)
                  ] | .[]')"
              fi
              if [[ -n "${missing_sig_bases}" ]]; then
                echo "missing: ${label} signature files (<asset>.sig) for:" >&2
                echo "${missing_sig_bases}" | sed 's/^/  - /' >&2
                missing=1
              fi
            }

            require_sigs_for_arch() {
              local label="$1"
              local arch_re="$2"
              local other_arch_re="$3"
              local missing_sig_bases
              missing_sig_bases="$(echo "$json" | jq -r --arg arch "$arch_re" --arg other "$other_arch_re" '
                ([.[].name] | unique) as $names |
                [ $names[]
                  | select(test("\\.(msi|exe)$"; "i"))
                  | select(test("microsoftedgewebview2"; "i") | not)
                  | select(test($arch; "i"))
                  | select(test($other; "i") | not)
                  | select(($names | index(. + ".sig")) == null)
                ] | .[]')"
              if [[ -n "${missing_sig_bases}" ]]; then
                echo "missing: ${label} signature files (<asset>.sig) for:" >&2
                echo "${missing_sig_bases}" | sed 's/^/  - /' >&2
                missing=1
              fi
            }

            # For Tauri auto-update, each Windows installer asset must have a corresponding
            # signature file uploaded alongside it (<asset>.sig). Missing signatures can be a
            # sign of partial uploads or asset clobbering in multi-arch runs.
            require_sigs_for_arch "Windows x64 installer" "$win_x64_re" "$win_arm64_re"
            require_sigs_for_arch "Windows arm64 installer" "$win_arm64_re" "$win_x64_re"

            # Require signatures for each macOS/Linux installer/bundle artifact, not just at least
            # one signature file. This catches partial uploads where the bundle exists but its `.sig`
            # was not attached to the GitHub Release.
            require_sigs_for_ext "macOS DMG" '\\.dmg$'
            require_sigs_for_ext "macOS updater archive" '\\.(tar\\.gz|tgz)$' '\\.AppImage\\.(tar\\.gz|tgz)$'
            require_sigs_for_ext "Linux AppImage" '\\.AppImage$'
            require_sigs_for_ext "Linux DEB" '\\.deb$'
            require_sigs_for_ext "Linux RPM" '\\.rpm$'

            [[ "$missing" -eq 0 ]]
          }

          release_json="$(fetch_release)"
          release_id="$(echo "$release_json" | jq -r '.id')"
          if [[ -z "${release_id}" || "${release_id}" == "null" ]]; then
            echo "::error::Failed to resolve GitHub Release id for tag ${tag}." >&2
            echo "$release_json" | jq -r '.' >&2 || true
            exit 1
          fi
          assets_json="$(fetch_assets "$release_id")"

          if ! assets_ready "$assets_json"; then
            for delay in "${retry_delays[@]}"; do
              echo "Release assets not fully visible yet; retrying in ${delay}s..." >&2
              sleep "$delay"
              release_json="$(fetch_release)"
              release_id="$(echo "$release_json" | jq -r '.id')"
              if [[ -z "${release_id}" || "${release_id}" == "null" ]]; then
                echo "::error::Failed to resolve GitHub Release id for tag ${tag} during retry." >&2
                echo "$release_json" | jq -r '.' >&2 || true
                exit 1
              fi
              assets_json="$(fetch_assets "$release_id")"
              if assets_ready "$assets_json"; then
                break
              fi
            done
          fi

          if ! assets_ready "$assets_json"; then
            echo "::error::Release asset verification failed after retries." >&2
            echo "$assets_json" | jq -r '.[].name' | sort | sed 's/^/::error:: - /' || true
            exit 1
          fi

          release_url="$(echo "$release_json" | jq -r '.html_url')"
          draft="$(echo "$release_json" | jq -r '.draft')"
          asset_count="$(echo "$assets_json" | jq -r 'length')"

          echo "Release: ${tag} (draft=${draft})"
          echo "URL: ${release_url}"
          echo "Assets: ${asset_count}"
          echo

          mapfile -t asset_names < <(echo "$assets_json" | jq -r '.[].name' | sort)
          printf '%s\n' "${asset_names[@]}"

          # Supply-chain metadata (SBOM + provenance) is uploaded by separate jobs/steps. GitHub
          # Release assets can be eventually consistent (upload succeeded but assets aren't visible
          # via API immediately), so retry briefly before warning.
          sbom_present="false"
          provenance_count="0"

          check_supply_chain_assets() {
            if printf '%s\n' "${asset_names[@]}" | grep -qx 'sbom.spdx.json'; then
              sbom_present="true"
            else
              sbom_present="false"
            fi

            provenance_count="$(printf '%s\n' "${asset_names[@]}" | grep -E '^provenance-.*\\.intoto\\.jsonl$' | wc -l | tr -d ' ')"
          }

          check_supply_chain_assets
          if [[ "${sbom_present}" != "true" || "${provenance_count}" -eq 0 ]]; then
            for delay in "${retry_delays[@]}"; do
              echo "Supply-chain assets not fully visible yet; retrying in ${delay}s..." >&2
              sleep "$delay"
              assets_json="$(fetch_assets "$release_id")"
              mapfile -t asset_names < <(echo "$assets_json" | jq -r '.[].name' | sort)
              check_supply_chain_assets
              if [[ "${sbom_present}" == "true" && "${provenance_count}" -gt 0 ]]; then
                break
              fi
            done
          fi

          dup_names="$(printf '%s\n' "${asset_names[@]}" | sort | uniq -d || true)"
          if [[ -n "${dup_names}" ]]; then
            echo "::error::Duplicate asset names found on the release (unexpected):"
            echo "${dup_names}"
            exit 1
          fi

          if [[ "${sbom_present}" != "true" ]]; then
            echo "::warning::SBOM asset sbom.spdx.json not found on the draft release."
          fi

          if [[ "${provenance_count}" -eq 0 ]]; then
            echo "::warning::No provenance-*.intoto.jsonl attestation bundles found on the draft release."
          fi

          expected_provenance_assets=(
            "provenance-universal-apple-darwin.intoto.jsonl"
            "provenance-x86_64-unknown-linux-gnu.intoto.jsonl"
            "provenance-aarch64-unknown-linux-gnu.intoto.jsonl"
            "provenance-x86_64-pc-windows-msvc.intoto.jsonl"
            "provenance-aarch64-pc-windows-msvc.intoto.jsonl"
          )

          missing_provenance_assets=()
          for expected in "${expected_provenance_assets[@]}"; do
            if ! printf '%s\n' "${asset_names[@]}" | grep -qx "${expected}"; then
              missing_provenance_assets+=("${expected}")
            fi
          done

          if ((${#missing_provenance_assets[@]} > 0)); then
            echo "::warning::Missing expected provenance bundle asset(s) (best-effort generation; see workflow logs):"
            for missing in "${missing_provenance_assets[@]}"; do
              echo "::warning:: - ${missing}"
            done
          fi

          enforce_supply_chain="${FORMULA_ENFORCE_SUPPLY_CHAIN_ASSETS:-}"
          if [[ "${enforce_supply_chain}" == "1" || "${enforce_supply_chain,,}" == "true" ]]; then
            if [[ "${sbom_present}" != "true" ]]; then
              echo "::error::SBOM asset sbom.spdx.json missing (FORMULA_ENFORCE_SUPPLY_CHAIN_ASSETS=1)"
              exit 1
            fi
            if [[ "${provenance_count}" -eq 0 ]]; then
              echo "::error::No provenance-*.intoto.jsonl attestation bundles found (FORMULA_ENFORCE_SUPPLY_CHAIN_ASSETS=1)"
              exit 1
            fi
            if ((${#missing_provenance_assets[@]} > 0)); then
              echo "::error::Missing expected provenance bundle asset(s) (FORMULA_ENFORCE_SUPPLY_CHAIN_ASSETS=1):" >&2
              for missing in "${missing_provenance_assets[@]}"; do
                echo "::error:: - ${missing}" >&2
              done
              exit 1
            fi
          fi

          bucket_for() {
            local name="$1"
            local base="$name"
            [[ "$base" == *.sig ]] && base="${base%.sig}"

            shopt -s nocasematch
            if [[ "$base" == "latest.json" ]]; then
              echo "updater-manifest"
            elif [[ "$base" == "sbom.spdx.json" || "$base" == "SHA256SUMS.txt" || "$base" == provenance-*.intoto.jsonl ]]; then
              echo "supply-chain"
            elif [[ "$base" == *.msi || "$base" == *.exe ]]; then
              if [[ "$base" =~ (arm64|aarch64) ]]; then
                echo "windows-arm64"
              elif [[ "$base" =~ (x64|x86[_-]64|amd64|win64) ]]; then
                echo "windows-x64"
              else
                echo "windows-unknown"
              fi
            elif [[ "$base" == *.dmg || ( ( "$base" == *.tar.gz || "$base" == *.tgz ) && "$base" != *.AppImage.tar.gz && "$base" != *.AppImage.tgz ) ]]; then
              if [[ "$base" =~ universal ]]; then
                echo "macos-universal"
              elif [[ "$base" =~ (arm64|aarch64) ]]; then
                echo "macos-arm64"
              elif [[ "$base" =~ (x64|x86_64) ]]; then
                echo "macos-x64"
              else
                echo "macos-unknown"
              fi
            elif [[ "$base" == *.deb || "$base" == *.rpm || "$base" == *.AppImage || "$base" == *.AppImage.tar.gz || "$base" == *.AppImage.tgz ]]; then
              if [[ "$base" =~ (amd64|x86[_-]64|x64) ]]; then
                echo "linux-x64"
              elif [[ "$base" =~ (arm64|aarch64) ]]; then
                echo "linux-arm64"
              else
                echo "linux-unknown"
              fi
            else
              echo "other"
            fi
            shopt -u nocasematch
          }

          declare -A bucket_assets
          for name in "${asset_names[@]}"; do
            bucket="$(bucket_for "$name")"
            bucket_assets["$bucket"]+="${name}"$'\n'
          done

          render_table() {
            echo "| Bucket | Asset |"
            echo "| --- | --- |"
            for bucket in macos-universal windows-x64 windows-arm64 linux-x64 updater-manifest supply-chain other macos-unknown windows-unknown linux-unknown macos-x64 macos-arm64 linux-arm64; do
              [[ -z "${bucket_assets[$bucket]+x}" ]] && continue
              while IFS= read -r name; do
                [[ -z "$name" ]] && continue
                echo "| ${bucket} | \`${name}\` |"
              done <<< "${bucket_assets[$bucket]}"
            done
          }

          {
            echo "## Release assets (${tag})"
            echo
            render_table
            echo
          } >> "$GITHUB_STEP_SUMMARY"

          echo
          echo "Grouped release assets:"
          render_table

          echo
          echo "Release asset verification passed."

  sbom:
    name: Generate SBOM (Rust + JS)
    needs: preflight
    runs-on: ubuntu-24.04
    outputs:
      generated: ${{ steps.generate_sbom.outcome == 'success' && steps.sbom_file.outputs.exists == 'true' }}
    permissions:
      contents: read
    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

      - name: Generate SBOM (SPDX JSON)
        id: generate_sbom
        continue-on-error: true
        uses: anchore/sbom-action@0b82b0b1a22399a1c542d4d656f70cd903571b5c # v0
        with:
          format: spdx-json
          output-file: sbom.spdx.json
          upload-artifact: false
          upload-release-assets: false

      - name: Sanity-check SBOM includes Rust + JS dependencies
        if: steps.generate_sbom.outcome == 'success'
        shell: bash
        run: |
          set -euo pipefail

          cargo_count="$(grep -c 'pkg:cargo' sbom.spdx.json || true)"
          npm_count="$(grep -c 'pkg:npm' sbom.spdx.json || true)"

          echo "SBOM purl counts:"
          echo "  - pkg:cargo: ${cargo_count}"
          echo "  - pkg:npm: ${npm_count}"

          if [[ "${cargo_count}" -eq 0 ]]; then
            echo "::warning::sbom.spdx.json did not contain any pkg:cargo entries; Rust dependency metadata may be missing."
          fi

          if [[ "${npm_count}" -eq 0 ]]; then
            echo "::warning::sbom.spdx.json did not contain any pkg:npm entries; JS dependency metadata may be missing (check pnpm-lock.yaml support)."
          fi

      - name: SBOM summary
        if: always()
        shell: bash
        run: |
          {
            echo "## SBOM"
            echo
            if [[ -f sbom.spdx.json ]]; then
              bytes="$(wc -c < sbom.spdx.json | tr -d ' ')"
              cargo_count="$(grep -c 'pkg:cargo' sbom.spdx.json || true)"
              npm_count="$(grep -c 'pkg:npm' sbom.spdx.json || true)"
              echo "- File: \`sbom.spdx.json\` (${bytes} bytes)"
              echo "- SPDX JSON generated via Syft (anchore/sbom-action)"
              echo "- pkg:cargo purls: ${cargo_count}"
              echo "- pkg:npm purls: ${npm_count}"
              echo
              echo "On tagged releases (\`upload=true\`), this file is also uploaded to the draft GitHub Release."
            else
              echo "- SBOM file was not generated (see workflow logs above)."
            fi
            echo
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Detect SBOM file
        id: sbom_file
        if: always()
        shell: bash
        run: |
          if [[ -f sbom.spdx.json ]]; then
            echo "exists=true" >> "$GITHUB_OUTPUT"
          else
            echo "exists=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Upload SBOM (workflow artifact)
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: sbom-${{ needs.preflight.outputs.artifact_label }}
          path: sbom.spdx.json
          if-no-files-found: warn

  upload-sbom:
    name: Upload SBOM to the draft release
    # Wait for the build matrix so the draft release definitely exists before attempting to upload.
    # (The release is created by the first successful `tauri-apps/tauri-action` run.)
    needs: [sbom, preflight, build]
    if: needs.preflight.outputs.upload == 'true'
    runs-on: ubuntu-24.04
    permissions:
      contents: write
      actions: read
    steps:
      - name: Download SBOM artifact
        if: needs.sbom.outputs.generated == 'true'
        id: download_sbom
        continue-on-error: true
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          name: sbom-${{ needs.preflight.outputs.artifact_label }}
          path: .

      - name: Upload SBOM to the draft release
        if: needs.sbom.outputs.generated == 'true' && hashFiles('sbom.spdx.json') != ''
        continue-on-error: true
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          gh release upload "${{ needs.preflight.outputs.release_tag }}" sbom.spdx.json \
            --repo "${{ github.repository }}" \
            --clobber

      - name: Skip SBOM upload (artifact download failed)
        if: needs.sbom.outputs.generated == 'true' && (steps.download_sbom.outcome != 'success' || hashFiles('sbom.spdx.json') == '')
        run: echo "::warning::SBOM artifact download failed (or sbom.spdx.json missing); skipping SBOM upload to the draft release."

      - name: Skip SBOM upload (SBOM generation failed)
        if: needs.sbom.outputs.generated != 'true'
        run: echo "::warning::SBOM generation failed; skipping sbom.spdx.json upload to the draft release."

  checksums:
    name: Generate SHA256SUMS.txt
    needs:
      - build
      - preflight
      - sbom
      - upload-sbom
      - verify-updater-manifest
      - verify-release-assets
    # Generating `SHA256SUMS.txt` re-validates the full GitHub Release asset set (including `latest.json.sig`)
    # via `scripts/verify-desktop-release-assets.mjs`. That requires updater signatures, which are only
    # produced when the TAURI_PRIVATE_KEY secret is configured.
    #
    # In forks without updater secrets we still build/upload unsigned artifacts, but we skip this strict
    # release-asset verification job so the workflow can complete.
    if: needs.preflight.outputs.upload == 'true' && (github.repository == 'wilson-anysphere/formula' || secrets.TAURI_PRIVATE_KEY != '')
    runs-on: ubuntu-24.04
    permissions:
      contents: write
    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

      - name: Setup Node
        uses: actions/setup-node@6044e13b5dc448c55e2357c09f80417699197238 # v6.2.0
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Verify desktop release assets + latest.json and generate SHA256SUMS.txt
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        shell: bash
        run: |
          set -euo pipefail

          cmd=(node scripts/verify-desktop-release-assets.mjs --tag "${{ needs.preflight.outputs.release_tag }}" --all-assets --include-sigs)

          # Enforce per-arch completeness + unambiguous naming in the upstream repo, where we ship
          # a full multi-arch matrix (macOS universal, Windows x64/arm64, Linux x86_64/arm64).
          #
          # Forks can opt into the same checks by passing `--expectations` manually (or by editing
          # the workflow), but we avoid forcing the upstream target set on all forks by default.
          if [[ "${{ github.repository }}" == "wilson-anysphere/formula" ]]; then
            cmd+=(--expectations scripts/release-asset-expectations.json)
          fi

          "${cmd[@]}"

      - name: Upload SHA256SUMS.txt to the draft release
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          gh release upload "${{ needs.preflight.outputs.release_tag }}" SHA256SUMS.txt \
            --repo "${{ github.repository }}" \
            --clobber
