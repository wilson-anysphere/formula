name: Desktop performance (platform matrix, on-demand PR)

on:
  pull_request:
    types: [labeled]

permissions:
  contents: read

concurrency:
  # Avoid stacking expensive 3xOS runs if the label is re-applied.
  # Note: this workflow triggers on *any* PR label, so include the label name to avoid canceling
  # an in-flight perf run when maintainers apply unrelated labels.
  # For trigger labels, keep a stable "perf" suffix so `desktop-perf-matrix` and `run-desktop-perf`
  # act like aliases and do not run concurrently.
  group: desktop-perf-platform-matrix-pr-${{ github.event.pull_request.number }}-${{ (github.event.label.name == 'desktop-perf-matrix' || github.event.label.name == 'run-desktop-perf') && 'perf' || github.event.label.name }}
  cancel-in-progress: true

env:
  # Keep these in sync with ci.yml/release.yml/desktop-perf-platform-matrix.yml to reduce drift.
  NODE_VERSION: 22
  WASM_PACK_VERSION: 0.13.1
  # Opt-in: bundle Pyodide assets into `apps/desktop/dist` (otherwise Pyodide is downloaded
  # on-demand at runtime and cached in the app data directory).
  FORMULA_BUNDLE_PYODIDE_ASSETS: ${{ vars.FORMULA_BUNDLE_PYODIDE_ASSETS }}
  # Keep these in sync with desktop-perf-platform-matrix.yml so on-demand PR runs use the
  # same default iteration counts/timeouts as the scheduled platform matrix.
  DESKTOP_STARTUP_RUNS: 5
  DESKTOP_STARTUP_TIMEOUT_MS: 20000
  DESKTOP_MEMORY_RUNS: 3
  DESKTOP_MEMORY_TIMEOUT_MS: 30000
  DESKTOP_MEMORY_SETTLE_MS: 5000

  # Optional: enable gating by setting the repository/organization variable
  # `FORMULA_ENFORCE_DESKTOP_PLATFORM_MATRIX=1`.
  FORMULA_ENFORCE_DESKTOP_PLATFORM_MATRIX: ${{ vars.FORMULA_ENFORCE_DESKTOP_PLATFORM_MATRIX }}

jobs:
  guard:
    name: Guard (label + same-repo PR)
    # Avoid creating work for unrelated label events. This still leaves a workflow run entry,
    # but all jobs will be skipped immediately when the label isn't a trigger label.
    if: github.event.label.name == 'desktop-perf-matrix' || github.event.label.name == 'run-desktop-perf'
    runs-on: ubuntu-24.04
    outputs:
      should_run: ${{ steps.guard.outputs.should_run }}
      head_sha: ${{ steps.guard.outputs.head_sha }}
      pr_number: ${{ steps.guard.outputs.pr_number }}
      label: ${{ steps.guard.outputs.label }}
    steps:
      - name: Decide whether to run the desktop perf platform matrix
        id: guard
        shell: bash
        run: |
          set -euo pipefail
          label="${{ github.event.label.name }}"
          pr_repo="${{ github.event.pull_request.head.repo.full_name }}"
          base_repo="${{ github.repository }}"

          echo "Received label event: ${label}"
          echo "PR head repo: ${pr_repo}"
          echo "Base repo: ${base_repo}"

          # Only run when explicitly requested.
          if [[ "${label}" != "desktop-perf-matrix" && "${label}" != "run-desktop-perf" ]]; then
            echo "::notice::Skipping desktop perf platform matrix (label ${label} is not a trigger label)."
            echo "should_run=false" >> "$GITHUB_OUTPUT"
            echo "label=${label}" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          # Safety: do not execute untrusted fork code.
          if [[ "${pr_repo}" != "${base_repo}" ]]; then
            echo "::notice::Skipping desktop perf platform matrix for fork PRs (head repo ${pr_repo} != ${base_repo})."
            echo "should_run=false" >> "$GITHUB_OUTPUT"
            echo "label=${label}" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          echo "should_run=true" >> "$GITHUB_OUTPUT"
          echo "head_sha=${{ github.event.pull_request.head.sha }}" >> "$GITHUB_OUTPUT"
          echo "pr_number=${{ github.event.pull_request.number }}" >> "$GITHUB_OUTPUT"
          echo "label=${label}" >> "$GITHUB_OUTPUT"

          {
            echo "### Desktop perf platform matrix (on-demand)"
            echo ""
            echo "- Trigger label: \`${label}\`"
            echo "- PR: #${{ github.event.pull_request.number }}"
            echo "- Head SHA: \`${{ github.event.pull_request.head.sha }}\`"
            echo ""
            echo "Running the desktop startup (cold+warm) + idle-memory benchmarks on Linux/Windows/macOS."
          } >> "$GITHUB_STEP_SUMMARY"

  desktop-perf:
    name: Desktop perf (${{ matrix.os }})
    needs: guard
    if: needs.guard.outputs.should_run == 'true'
    runs-on: ${{ matrix.os }}
    timeout-minutes: 90
    strategy:
      fail-fast: false
      matrix:
        # Pin runner images for reproducibility. GitHub's `*-latest` labels move over time,
        # which can both break workflows unexpectedly and introduce noise into perf trends.
        # Update these pins deliberately after validating on newer runner images:
        # https://github.com/actions/runner-images
        os: [ubuntu-24.04, windows-2022, macos-14]
    steps:
      - name: Checkout PR head (not merge commit)
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v4
        with:
          ref: ${{ needs.guard.outputs.head_sha }}

      - name: "Guard: Rust toolchain pins match rust-toolchain.toml"
        shell: bash
        run: bash scripts/ci/check-rust-toolchain-pins.sh

      - name: Setup pnpm
        uses: pnpm/action-setup@41ff72655975bd51cab0327fa583b6e92b6d3061 # v4
        with:
          version: 9.0.0

      - name: Setup Node
        uses: actions/setup-node@6044e13b5dc448c55e2357c09f80417699197238 # v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: pnpm
          cache-dependency-path: pnpm-lock.yaml

      - name: Initialize perf artifact directory
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p perf-artifacts
          node - <<'NODE'
          const fs = require("node:fs");
          fs.writeFileSync(
            "perf-artifacts/metadata.json",
            JSON.stringify(
              {
                generatedAt: new Date().toISOString(),
                pr: {
                  number: Number(process.env.PR_NUMBER ?? "") || null,
                  label: process.env.PR_LABEL ?? null,
                },
                git: { sha: process.env.PR_HEAD_SHA ?? null },
                runner: {
                  os: process.env.RUNNER_OS ?? null,
                  arch: process.env.RUNNER_ARCH ?? null,
                  name: process.env.RUNNER_NAME ?? null,
                },
                enforcePlatformMatrix: process.env.FORMULA_ENFORCE_DESKTOP_PLATFORM_MATRIX ?? null,
              },
              null,
              2,
            ),
            "utf8",
          );
          NODE
        env:
          PR_NUMBER: ${{ needs.guard.outputs.pr_number }}
          PR_LABEL: ${{ needs.guard.outputs.label }}
          PR_HEAD_SHA: ${{ needs.guard.outputs.head_sha }}

      - name: Export desktop perf target env vars (from GitHub Actions variables)
        shell: bash
        run: |
          set -euo pipefail
          
          maybe_set() {
            local name="$1"
            local raw="$2"
            if [[ -n "${!name:-}" ]]; then
              echo "Keeping existing $name=${!name}"
              return 0
            fi
            # Strip newlines/CRs to keep $GITHUB_ENV parsing happy.
            local value="${raw//$'\r'/}"
            value="${value//$'\n'/}"
            if [[ -n "$value" ]]; then
              echo "$name=$value" >> "$GITHUB_ENV"
              echo "Set $name=$value"
            fi
          }
          
          # Startup targets (includes legacy unscoped fallbacks so maintainers can reuse existing CI settings).
          maybe_set FORMULA_DESKTOP_WINDOW_VISIBLE_TARGET_MS "${{ vars.FORMULA_DESKTOP_WINDOW_VISIBLE_TARGET_MS }}"
          maybe_set FORMULA_DESKTOP_TTI_TARGET_MS "${{ vars.FORMULA_DESKTOP_TTI_TARGET_MS }}"
          maybe_set FORMULA_DESKTOP_FIRST_RENDER_TARGET_MS "${{ vars.FORMULA_DESKTOP_FIRST_RENDER_TARGET_MS }}"
          maybe_set FORMULA_DESKTOP_COLD_WINDOW_VISIBLE_TARGET_MS "${{ vars.FORMULA_DESKTOP_COLD_WINDOW_VISIBLE_TARGET_MS }}"
          maybe_set FORMULA_DESKTOP_COLD_FIRST_RENDER_TARGET_MS "${{ vars.FORMULA_DESKTOP_COLD_FIRST_RENDER_TARGET_MS }}"
          maybe_set FORMULA_DESKTOP_COLD_TTI_TARGET_MS "${{ vars.FORMULA_DESKTOP_COLD_TTI_TARGET_MS }}"
          maybe_set FORMULA_DESKTOP_WARM_WINDOW_VISIBLE_TARGET_MS "${{ vars.FORMULA_DESKTOP_WARM_WINDOW_VISIBLE_TARGET_MS }}"
          maybe_set FORMULA_DESKTOP_WARM_FIRST_RENDER_TARGET_MS "${{ vars.FORMULA_DESKTOP_WARM_FIRST_RENDER_TARGET_MS }}"
          maybe_set FORMULA_DESKTOP_WARM_TTI_TARGET_MS "${{ vars.FORMULA_DESKTOP_WARM_TTI_TARGET_MS }}"
          maybe_set FORMULA_DESKTOP_WEBVIEW_LOADED_TARGET_MS "${{ vars.FORMULA_DESKTOP_WEBVIEW_LOADED_TARGET_MS }}"
          
          # Idle memory targets.
          maybe_set FORMULA_DESKTOP_IDLE_RSS_TARGET_MB "${{ vars.FORMULA_DESKTOP_IDLE_RSS_TARGET_MB }}"
          maybe_set FORMULA_DESKTOP_MEMORY_TARGET_MB "${{ vars.FORMULA_DESKTOP_MEMORY_TARGET_MB }}"

      - name: Configure desktop perf enforcement
        shell: bash
        run: |
          set -euo pipefail
          raw="${FORMULA_ENFORCE_DESKTOP_PLATFORM_MATRIX:-}"
          norm="$(echo "$raw" | tr '[:upper:]' '[:lower:]' | xargs || true)"
          if [[ "$norm" == "1" || "$norm" == "true" || "$norm" == "yes" || "$norm" == "on" ]]; then
            echo "FORMULA_ENFORCE_DESKTOP_STARTUP_BENCH=1" >> "$GITHUB_ENV"
            echo "FORMULA_ENFORCE_DESKTOP_MEMORY_BENCH=1" >> "$GITHUB_ENV"
            echo "Desktop perf enforcement: enabled (FORMULA_ENFORCE_DESKTOP_PLATFORM_MATRIX=${raw})"
          else
            echo "FORMULA_ENFORCE_DESKTOP_STARTUP_BENCH=0" >> "$GITHUB_ENV"
            echo "FORMULA_ENFORCE_DESKTOP_MEMORY_BENCH=0" >> "$GITHUB_ENV"
            echo "Desktop perf enforcement: disabled (FORMULA_ENFORCE_DESKTOP_PLATFORM_MATRIX=${raw})"
          fi
      - name: "Guard: Windows Authenticode timestamp URL uses HTTPS"
        run: node scripts/ci/check-windows-timestamp-url.mjs

      - name: Setup Rust toolchain (pinned + wasm32)
        uses: dtolnay/rust-toolchain@e97e2d8cc328f1b50210efc529dca0028893a2d9 # v1
        with:
          toolchain: 1.92.0
          targets: wasm32-unknown-unknown

      # Our dev scripts default to a repo-local CARGO_HOME to avoid cross-agent
      # contention on shared ~/.cargo. In GitHub Actions we prefer the default
      # CARGO_HOME so cargo installs/builds share the same cache.
      - name: Use shared Cargo home for CI caching (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $cargoHome = Join-Path $env:USERPROFILE ".cargo"
          "CARGO_HOME=$cargoHome" | Out-File -FilePath $env:GITHUB_ENV -Append -Encoding utf8

      - name: Use shared Cargo home for CI caching (Unix)
        if: runner.os != 'Windows'
        run: echo "CARGO_HOME=$HOME/.cargo" >> "$GITHUB_ENV"

      - name: Rust cache
        uses: Swatinem/rust-cache@779680da715d629ac1d338a641029a2f4372abb5 # v2

      - name: Install Linux dependencies (Tauri/WebView + headless display)
        if: matrix.os == 'ubuntu-24.04'
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            xvfb \
            libgtk-3-dev \
            libwebkit2gtk-4.1-dev \
            libayatana-appindicator3-dev \
            librsvg2-dev \
            libssl-dev \
            patchelf

      - name: Install JS dependencies
        env:
          # This workflow does not run Playwright tests, so skip the ~GB browser downloads
          # performed by `@playwright/test`'s postinstall script.
          PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD: "1"
        # Prefer cached pnpm store entries to reduce network flakiness on reruns.
        run: pnpm install --frozen-lockfile --prefer-offline

      - name: Cache wasm-pack binary
        id: wasm-pack-cache
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v4
        with:
          path: ~/.cargo/bin/wasm-pack*
          # Include the Rust toolchain pin so Rust upgrades force rebuilding the cached binary.
          key: wasm-pack-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-

      - name: Cache wasm-pack tool downloads (Linux)
        if: runner.os == 'Linux'
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v4
        with:
          # wasm-pack downloads wasm-bindgen + binaryen (wasm-opt) into this cache dir.
          path: ~/.cache/.wasm-pack
          key: wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-

      - name: Cache wasm-pack tool downloads (macOS)
        if: runner.os == 'macOS'
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v4
        with:
          path: ~/Library/Caches/.wasm-pack
          key: wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-

      - name: Cache wasm-pack tool downloads (Windows)
        if: runner.os == 'Windows'
        uses: actions/cache@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v4
        with:
          path: ${{ env.LOCALAPPDATA }}/.wasm-pack
          key: wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-

      - name: Install wasm-pack (required for @formula/engine WASM build)
        if: steps.wasm-pack-cache.outputs.cache-hit != 'true'
        # Use --force so cache restore-keys (or other CI caches) can't strand a stale/untracked
        # wasm-pack binary that would otherwise block `cargo install` from overwriting it.
        run: cargo install wasm-pack --version ${{ env.WASM_PACK_VERSION }} --locked --force

      - name: Verify wasm-pack version
        shell: bash
        run: |
          set -euo pipefail
          expected="${WASM_PACK_VERSION}"
          actual="$(wasm-pack --version | tr -d '\r' | awk '{print $2}')"
          if [[ "${actual}" != "${expected}" ]]; then
            echo "Expected wasm-pack ${expected}, but found ${actual}." >&2
            exit 1
          fi

      - name: Detect Pyodide version (for caching)
        id: pyodide
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1'
        shell: bash
        run: |
          set -euo pipefail
          version="$(node -e "const fs=require('node:fs'); const src=fs.readFileSync('apps/desktop/scripts/ensure-pyodide-assets.mjs','utf8'); const m=src.match(/const\\s+PYODIDE_VERSION\\s*=\\s*['\\\"]([^'\\\"]+)['\\\"]/); if(!m) throw new Error('PYODIDE_VERSION not found'); process.stdout.write(m[1]);")"
          echo "version=${version}" >> "$GITHUB_OUTPUT"

      - name: Restore Pyodide asset cache
        id: pyodide-cache
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1'
        uses: actions/cache/restore@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v4
        with:
          path: apps/desktop/public/pyodide/v${{ steps.pyodide.outputs.version }}/full/
          key: pyodide-${{ runner.os }}-${{ steps.pyodide.outputs.version }}-${{ hashFiles('apps/desktop/scripts/ensure-pyodide-assets.mjs') }}

      - name: Ensure Pyodide assets are present
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1'
        run: node apps/desktop/scripts/ensure-pyodide-assets.mjs

      - name: Save Pyodide asset cache
        if: env.FORMULA_BUNDLE_PYODIDE_ASSETS == '1' && steps.pyodide-cache.outputs.cache-hit != 'true'
        uses: actions/cache/save@8b402f58fbc84540c8b491a91e594a4576fec3d7 # v4
        with:
          path: apps/desktop/public/pyodide/v${{ steps.pyodide.outputs.version }}/full/
          key: pyodide-${{ runner.os }}-${{ steps.pyodide.outputs.version }}-${{ hashFiles('apps/desktop/scripts/ensure-pyodide-assets.mjs') }}

      - name: Build desktop frontend (Vite + WASM)
        run: pnpm build:desktop

      - name: Desktop dist asset report
        # Size regressions are useful context, but this workflow is primarily about
        # startup + memory. Keep size checks non-blocking so we still get perf data.
        continue-on-error: true
        run: node scripts/desktop_dist_asset_report.mjs --json-out perf-artifacts/desktop-dist-assets-report.json
        env:
          # Optional: set as GitHub Actions variables to enable gating.
          FORMULA_DESKTOP_DIST_TOTAL_BUDGET_MB: ${{ vars.FORMULA_DESKTOP_DIST_TOTAL_BUDGET_MB }}
          FORMULA_DESKTOP_DIST_SINGLE_FILE_BUDGET_MB: ${{ vars.FORMULA_DESKTOP_DIST_SINGLE_FILE_BUDGET_MB }}

      - name: Build desktop binary (release)
        shell: bash
        run: |
          set -euo pipefail
          if cargo metadata --no-deps --format-version=1 | grep -q '"name":"formula-desktop-tauri"'; then
            cargo build -p formula-desktop-tauri --bin formula-desktop --features desktop --release --locked
          else
            cargo build -p desktop --bin formula-desktop --features desktop --release --locked
          fi

      - name: Run desktop startup benchmark (cold)
        id: startup-cold
        continue-on-error: true
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p perf-artifacts
          node scripts/run-node-ts.mjs apps/desktop/tests/performance/desktop-startup-runner.ts \
            --mode cold \
            --full \
            --runs "${DESKTOP_STARTUP_RUNS}" \
            --timeout-ms "${DESKTOP_STARTUP_TIMEOUT_MS}" \
            --json perf-artifacts/desktop-startup-metrics-cold.json \
            --allow-ci 2>&1 | tee perf-artifacts/desktop-startup-cold.log

      - name: Run desktop startup benchmark (warm)
        id: startup-warm
        continue-on-error: true
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p perf-artifacts
          node scripts/run-node-ts.mjs apps/desktop/tests/performance/desktop-startup-runner.ts \
            --mode warm \
            --full \
            --runs "${DESKTOP_STARTUP_RUNS}" \
            --timeout-ms "${DESKTOP_STARTUP_TIMEOUT_MS}" \
            --json perf-artifacts/desktop-startup-metrics-warm.json \
            --allow-ci 2>&1 | tee perf-artifacts/desktop-startup-warm.log

      - name: Run idle memory benchmark
        id: memory
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p perf-artifacts
          node scripts/run-node-ts.mjs apps/desktop/tests/performance/desktop-memory-runner.ts \
            --runs "${DESKTOP_MEMORY_RUNS}" \
            --timeout-ms "${DESKTOP_MEMORY_TIMEOUT_MS}" \
            --settle-ms "${DESKTOP_MEMORY_SETTLE_MS}" \
            --json perf-artifacts/desktop-memory-metrics.json \
            --allow-ci 2>&1 | tee perf-artifacts/desktop-memory.log

      - name: Summarize + merge perf artifacts
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p perf-artifacts
          node - <<'NODE'
           const fs = require("node:fs");
           const path = require("node:path");
           const { execSync } = require("node:child_process");
           
           function readJsonMaybe(p) {
            try {
              return JSON.parse(fs.readFileSync(p, "utf8"));
             } catch {
               return null;
             }
           }
           
           function tryExec(command) {
             try {
               return execSync(command, { encoding: "utf8" }).trim();
             } catch {
               return null;
             }
           }

           function compareDottedVersions(a, b) {
             // Descending sort helper for strings like "123.0.4567.89".
             const pa = String(a).split(".").map((x) => Number(x));
             const pb = String(b).split(".").map((x) => Number(x));
             const len = Math.max(pa.length, pb.length);
             for (let i = 0; i < len; i += 1) {
               const av = Number.isFinite(pa[i]) ? pa[i] : 0;
               const bv = Number.isFinite(pb[i]) ? pb[i] : 0;
               if (av !== bv) return bv - av;
             }
             return 0;
           }

           function detectWebview() {
             try {
               if (process.platform === "linux") {
                 const version =
                   tryExec("pkg-config --modversion webkit2gtk-4.1 2>/dev/null") ??
                   tryExec("pkg-config --modversion webkit2gtk-4.0 2>/dev/null");
                 return { engine: "webkitgtk", version };
               }
               if (process.platform === "darwin") {
                 const plist =
                   "/System/Library/Frameworks/WebKit.framework/Versions/A/Resources/Info.plist";
                 const version =
                   tryExec(`plutil -extract CFBundleShortVersionString raw -o - ${plist} 2>/dev/null`) ??
                   tryExec(`defaults read ${plist} CFBundleShortVersionString 2>/dev/null`);
                 return { engine: "wkwebview", version };
               }
               if (process.platform === "win32") {
                 const roots = [
                   process.env["ProgramFiles(x86)"]
                     ? path.join(process.env["ProgramFiles(x86)"], "Microsoft", "EdgeWebView", "Application")
                     : null,
                   process.env.ProgramFiles
                     ? path.join(process.env.ProgramFiles, "Microsoft", "EdgeWebView", "Application")
                     : null,
                   process.env.LOCALAPPDATA
                     ? path.join(process.env.LOCALAPPDATA, "Microsoft", "EdgeWebView", "Application")
                     : null,
                 ].filter(Boolean);
                 for (const root of roots) {
                   try {
                     const entries = fs.readdirSync(root, { withFileTypes: true });
                     const versions = entries
                       .filter((e) => e.isDirectory() && /^\d+\.\d+\.\d+\.\d+$/.test(e.name))
                       .map((e) => e.name)
                       .sort(compareDottedVersions);
                     if (versions.length > 0) {
                       return { engine: "webview2", version: versions[0], rootDir: root };
                     }
                   } catch {
                     // ignore
                   }
                 }
                 return { engine: "webview2", version: null };
               }
             } catch {
               // ignore
             }
             return null;
           }
          
           const startupColdPath = path.resolve("perf-artifacts/desktop-startup-metrics-cold.json");
           const startupWarmPath = path.resolve("perf-artifacts/desktop-startup-metrics-warm.json");
           const memoryPath = path.resolve("perf-artifacts/desktop-memory-metrics.json");
           const startupCold = readJsonMaybe(startupColdPath);
           const startupWarm = readJsonMaybe(startupWarmPath);
           const idleMemory = readJsonMaybe(memoryPath);
           const webview = detectWebview();
          
          const sha = tryExec("git rev-parse HEAD");
          const ref = tryExec("git rev-parse --abbrev-ref HEAD");
          
           const merged = {
             generatedAt: new Date().toISOString(),
             ci: {
               workflow: process.env.GITHUB_WORKFLOW || null,
               runId: process.env.GITHUB_RUN_ID || null,
              runNumber: process.env.GITHUB_RUN_NUMBER || null,
              attempt: process.env.GITHUB_RUN_ATTEMPT || null,
              job: process.env.GITHUB_JOB || null,
            },
            git: { sha, ref },
            runner: {
              os: process.env.RUNNER_OS || null,
              arch: process.env.RUNNER_ARCH || null,
              name: process.env.RUNNER_NAME || null,
            },
            image: {
              os: process.env.ImageOS || null,
              version: process.env.ImageVersion || null,
              name: process.env.ImageName || null,
            },
             toolchain: {
               node: process.version,
               pnpm: tryExec("pnpm --version"),
               rustc: tryExec("rustc --version"),
               cargo: tryExec("cargo --version"),
               wasmPack: tryExec("wasm-pack --version"),
             },
             webview,
             startupCold,
             startupWarm,
             idleMemory,
           };
          
          fs.writeFileSync(
            path.resolve("perf-artifacts/desktop-perf-metrics.json"),
            JSON.stringify(merged, null, 2),
            "utf8",
          );
          
          const summaryPath = process.env.GITHUB_STEP_SUMMARY;
          if (!summaryPath) process.exit(0);
          
          function fmt(n, digits = 1) {
            if (typeof n !== "number" || !Number.isFinite(n)) return "n/a";
            return n.toFixed(digits);
          }
          
           const lines = [];
           lines.push(`## Desktop perf summary (${process.env.RUNNER_OS ?? "unknown"})`);
           lines.push(`Commit: \`${sha ?? "n/a"}\``);
           if (process.env.ImageOS || process.env.ImageVersion) {
             lines.push(`Runner image: \`${process.env.ImageOS ?? "n/a"}\` \`${process.env.ImageVersion ?? ""}\``);
           }
           if (webview?.engine) {
             lines.push(
               `WebView: \`${webview.engine}\`${webview.version ? ` \`${webview.version}\`` : ""}`,
             );
           }
           lines.push("");
           lines.push("| Metric | p50 | p95 | Notes |");
           lines.push("|---|---:|---:|---|");
          
          if (startupCold?.summary) {
            const s = startupCold.summary;
            lines.push(
              `| startup.cold.windowVisible (ms) | ${fmt(s.windowVisible?.p50)} | ${fmt(s.windowVisible?.p95)} | target=${s.windowVisible?.targetMs ?? "n/a"} enforced=${s.enforce ? 1 : 0} |`,
            );
            lines.push(
              `| startup.cold.firstRender (ms) | ${fmt(s.firstRender?.p50)} | ${fmt(s.firstRender?.p95)} | |`,
            );
            lines.push(
              `| startup.cold.webviewLoaded (ms) | ${fmt(s.webviewLoaded?.p50)} | ${fmt(s.webviewLoaded?.p95)} | target=${s.webviewLoaded?.targetMs ?? "n/a"} |`,
            );
            lines.push(
              `| startup.cold.tti (ms) | ${fmt(s.tti?.p50)} | ${fmt(s.tti?.p95)} | target=${s.tti?.targetMs ?? "n/a"} enforced=${s.enforce ? 1 : 0} |`,
            );
          } else {
            lines.push("| startup.cold | n/a | n/a | missing desktop-startup-metrics-cold.json |");
          }
          
          if (startupWarm?.summary) {
            const s = startupWarm.summary;
            lines.push(
              `| startup.warm.windowVisible (ms) | ${fmt(s.windowVisible?.p50)} | ${fmt(s.windowVisible?.p95)} | target=${s.windowVisible?.targetMs ?? "n/a"} enforced=${s.enforce ? 1 : 0} |`,
            );
            lines.push(
              `| startup.warm.firstRender (ms) | ${fmt(s.firstRender?.p50)} | ${fmt(s.firstRender?.p95)} | |`,
            );
            lines.push(
              `| startup.warm.webviewLoaded (ms) | ${fmt(s.webviewLoaded?.p50)} | ${fmt(s.webviewLoaded?.p95)} | target=${s.webviewLoaded?.targetMs ?? "n/a"} |`,
            );
            lines.push(
              `| startup.warm.tti (ms) | ${fmt(s.tti?.p50)} | ${fmt(s.tti?.p95)} | target=${s.tti?.targetMs ?? "n/a"} enforced=${s.enforce ? 1 : 0} |`,
            );
          } else {
            lines.push("| startup.warm | n/a | n/a | missing desktop-startup-metrics-warm.json |");
          }
          
          if (idleMemory?.summary) {
            const m = idleMemory.summary;
            lines.push(
              `| idleMemory.rss (mb) | ${fmt(m.rssMb?.p50, 1)} | ${fmt(m.rssMb?.p95, 1)} | settleMs=${idleMemory.settleMs ?? "n/a"} kind=${idleMemory.measurement ?? "rss"} |`,
            );
          } else {
            lines.push("| idleMemory | n/a | n/a | missing desktop-memory-metrics.json |");
          }
          
          lines.push("");
          fs.appendFileSync(summaryPath, lines.join("\n") + "\n", "utf8");
          NODE

      - name: Upload desktop perf artifacts
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v4
        with:
          name: desktop-perf-${{ matrix.os }}
          if-no-files-found: warn
          path: |
            perf-artifacts/*.json
            perf-artifacts/*.log

      - name: Enforce perf gate (optional) + report failures
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          node - <<'NODE'
          const fs = require("node:fs");
          
          const rawEnforce = (process.env.FORMULA_ENFORCE_DESKTOP_PLATFORM_MATRIX ?? "").trim().toLowerCase();
          const enforce =
            rawEnforce === "1" || rawEnforce === "true" || rawEnforce === "yes" || rawEnforce === "on";
          
          function readJsonMaybe(p) {
            try {
              return JSON.parse(fs.readFileSync(p, "utf8"));
            } catch {
              return null;
            }
          }
          
          function fmt(n, digits = 0) {
            if (typeof n !== "number" || !Number.isFinite(n)) return "n/a";
            return n.toFixed(digits);
          }
          
          function emitError(msg) {
            // GitHub Actions annotation.
            // eslint-disable-next-line no-console
            console.log(`::error::${msg}`);
          }
          
          function checkOutcome(name, outcome) {
            if (outcome === "success") return false;
            // Treat skipped separately so a prior build failure is less confusing.
            if (outcome === "skipped") {
              emitError(`${name} did not run (outcome=skipped). This usually means an earlier build step failed.`);
            } else {
              emitError(`${name} failed (outcome=${outcome}). See logs/artifacts for details.`);
            }
            return true;
          }
          
          function checkMetric(label, p95, target, unit, digits = 0) {
            if (!enforce) return false;
            if (typeof p95 !== "number" || !Number.isFinite(p95)) return false;
            if (typeof target !== "number" || !Number.isFinite(target)) return false;
            if (p95 <= target) return false;
            emitError(`${label} regression: p95=${fmt(p95, digits)}${unit} > target=${fmt(target, digits)}${unit}`);
            return true;
          }
          
          const startupColdOutcome = process.env.STARTUP_COLD_OUTCOME || "unknown";
          const startupWarmOutcome = process.env.STARTUP_WARM_OUTCOME || "unknown";
          const memoryOutcome = process.env.MEMORY_OUTCOME || "unknown";
          
          let failed = false;
          failed = checkOutcome("desktop startup cold runner", startupColdOutcome) || failed;
          failed = checkOutcome("desktop startup warm runner", startupWarmOutcome) || failed;
          failed = checkOutcome("desktop memory runner", memoryOutcome) || failed;
          
          const cold = readJsonMaybe("perf-artifacts/desktop-startup-metrics-cold.json");
          const warm = readJsonMaybe("perf-artifacts/desktop-startup-metrics-warm.json");
          const mem = readJsonMaybe("perf-artifacts/desktop-memory-metrics.json");
          
          const coldSummary = cold?.summary ?? null;
          const warmSummary = warm?.summary ?? null;
          const memSummary = mem?.summary ?? null;
          
          if (enforce) {
            failed =
              checkMetric(
                "startup.cold.windowVisible",
                coldSummary?.windowVisible?.p95,
                coldSummary?.windowVisible?.targetMs,
                "ms",
                0,
              ) || failed;
            failed =
              checkMetric("startup.cold.tti", coldSummary?.tti?.p95, coldSummary?.tti?.targetMs, "ms", 0) || failed;
            failed =
              checkMetric(
                "startup.cold.webviewLoaded",
                coldSummary?.webviewLoaded?.p95,
                coldSummary?.webviewLoaded?.targetMs,
                "ms",
                0,
              ) || failed;
            failed =
              checkMetric(
                "startup.cold.firstRender",
                coldSummary?.firstRender?.p95,
                coldSummary?.firstRender?.targetMs,
                "ms",
                0,
              ) || failed;
            
            failed =
              checkMetric(
                "startup.warm.windowVisible",
                warmSummary?.windowVisible?.p95,
                warmSummary?.windowVisible?.targetMs,
                "ms",
                0,
              ) || failed;
            failed =
              checkMetric("startup.warm.tti", warmSummary?.tti?.p95, warmSummary?.tti?.targetMs, "ms", 0) || failed;
            failed =
              checkMetric(
                "startup.warm.webviewLoaded",
                warmSummary?.webviewLoaded?.p95,
                warmSummary?.webviewLoaded?.targetMs,
                "ms",
                0,
              ) || failed;
            failed =
              checkMetric(
                "startup.warm.firstRender",
                warmSummary?.firstRender?.p95,
                warmSummary?.firstRender?.targetMs,
                "ms",
                0,
              ) || failed;
            
            failed =
              checkMetric("idleMemory.rss", memSummary?.rssMb?.p95, memSummary?.rssMb?.targetMb, "MB", 1) || failed;
          }
          
          if (failed) process.exitCode = 1;
          NODE
        env:
          STARTUP_COLD_OUTCOME: ${{ steps.startup-cold.outcome }}
          STARTUP_WARM_OUTCOME: ${{ steps.startup-warm.outcome }}
          MEMORY_OUTCOME: ${{ steps.memory.outcome }}

  pr-comment:
    name: PR comment (desktop perf summary)
    needs: [guard, merge]
    if: always() && needs.guard.outputs.should_run == 'true'
    runs-on: ubuntu-24.04
    permissions:
      contents: read
      actions: read
      issues: write
    steps:
      - name: Download merged perf summary artifact
        id: download
        continue-on-error: true
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v4
        with:
          name: desktop-perf-platform-matrix
          path: artifacts/desktop-perf-platform-matrix

      - name: Download per-OS perf artifacts (fallback)
        if: steps.download.outcome != 'success'
        continue-on-error: true
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v4
        with:
          pattern: desktop-perf-*
          path: artifacts/desktop-perf

      - name: Create/update PR comment
        continue-on-error: true
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v7
        with:
          script: |
            const fs = require("node:fs");
            const path = require("node:path");
            
            const marker = "<!-- FORMULA_DESKTOP_PERF_PLATFORM_MATRIX -->";
            const runUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            const headSha = "${{ needs.guard.outputs.head_sha }}";
            const label = "${{ needs.guard.outputs.label }}";
            const rawEnforce = (process.env.FORMULA_ENFORCE_DESKTOP_PLATFORM_MATRIX ?? "").trim().toLowerCase();
            const enforce =
              rawEnforce === "1" || rawEnforce === "true" || rawEnforce === "yes" || rawEnforce === "on";
            
            function readJsonMaybe(p) {
              try {
                return JSON.parse(fs.readFileSync(p, "utf8"));
              } catch {
                return null;
              }
            }
            
            function fmt(n, digits = 0) {
              if (typeof n !== "number" || !Number.isFinite(n)) return "n/a";
              return n.toFixed(digits);
            }
            
            function fmtMetric(value, target, digits = 0) {
              const v = typeof value === "number" && Number.isFinite(value) ? value : null;
              const t = typeof target === "number" && Number.isFinite(target) ? target : null;
              if (v == null && t == null) return "n/a";
              if (v == null) return `n/a (target=${fmt(t, digits)})`;
              if (t == null) return `${fmt(v, digits)}`;
              const ok = v <= t;
              return `${fmt(v, digits)} / ${fmt(t, digits)} ${ok ? "PASS" : "FAIL"}`;
            }
            
            const mergedCandidates = [
              path.join(
                "artifacts",
                "desktop-perf-platform-matrix",
                "merged",
                "desktop-perf-platform-matrix.json",
              ),
              // Some artifact tools flatten single-file uploads; keep a fallback for robustness.
              path.join("artifacts", "desktop-perf-platform-matrix", "desktop-perf-platform-matrix.json"),
            ];
            let merged = null;
            for (const candidate of mergedCandidates) {
              merged = readJsonMaybe(candidate);
              if (merged) break;
            }
            let artifacts = merged?.artifacts ?? null;
            if (!artifacts || typeof artifacts !== "object") {
              // Fallback: read directly from per-OS artifacts if the merged artifact is missing.
              artifacts = {};
              for (const name of [
                "desktop-perf-ubuntu-24.04",
                "desktop-perf-windows-2022",
                "desktop-perf-macos-14",
              ]) {
                const p = path.join("artifacts", "desktop-perf", name, "perf-artifacts", "desktop-perf-metrics.json");
                artifacts[name] = readJsonMaybe(p);
              }
            }
            
            const byOs = [
              { label: "Linux", artifact: "desktop-perf-ubuntu-24.04" },
              { label: "Windows", artifact: "desktop-perf-windows-2022" },
              { label: "macOS", artifact: "desktop-perf-macos-14" },
            ].map((row) => {
              const data = artifacts[row.artifact] ?? null;
              return { ...row, data };
            });
            
            const lines = [];
            lines.push(marker);
            lines.push("### Desktop perf platform matrix (on-demand)");
            lines.push("");
            lines.push(`- Trigger label: \`${label}\``);
            lines.push(`- Commit: \`${headSha}\``);
            lines.push(`- Enforcement: \`${enforce ? "on" : "off"}\` (\`FORMULA_ENFORCE_DESKTOP_PLATFORM_MATRIX=${process.env.FORMULA_ENFORCE_DESKTOP_PLATFORM_MATRIX || ""}\`)`);
            lines.push(`- Run: ${runUrl}`);
             lines.push("");
             lines.push("#### Startup (p95 / target, ms)");
             lines.push("");
             lines.push("| OS | cold windowVisible | cold tti | cold webviewLoaded | warm windowVisible | warm tti | warm webviewLoaded |");
             lines.push("|---|---:|---:|---:|---:|---:|---:|");
             
             for (const row of byOs) {
              const cold = row.data?.startupCold?.summary ?? null;
              const warm = row.data?.startupWarm?.summary ?? null;
              const coldWv = fmtMetric(cold?.windowVisible?.p95, cold?.windowVisible?.targetMs, 0);
              const coldTti = fmtMetric(cold?.tti?.p95, cold?.tti?.targetMs, 0);
              const coldWeb = fmtMetric(cold?.webviewLoaded?.p95, cold?.webviewLoaded?.targetMs, 0);
              const warmWv = fmtMetric(warm?.windowVisible?.p95, warm?.windowVisible?.targetMs, 0);
              const warmTti = fmtMetric(warm?.tti?.p95, warm?.tti?.targetMs, 0);
              const warmWeb = fmtMetric(warm?.webviewLoaded?.p95, warm?.webviewLoaded?.targetMs, 0);
               lines.push(`| ${row.label} | ${coldWv} | ${coldTti} | ${coldWeb} | ${warmWv} | ${warmTti} | ${warmWeb} |`);
             }
             
             lines.push("");
             lines.push("#### WebView runtime");
             lines.push("");
             lines.push("| OS | engine | version |");
             lines.push("|---|---|---|");
             
             for (const row of byOs) {
               const w = row.data?.webview ?? null;
               const engine = w?.engine ?? "n/a";
               const version = w?.version ?? "n/a";
               lines.push(`| ${row.label} | \`${engine}\` | \`${version}\` |`);
             }
             
             lines.push("");
             lines.push("#### Idle memory (p95 / target, MB)");
             lines.push("");
             lines.push("| OS | kind | idle memory |");
             lines.push("|---|---|---:|");
            
            for (const row of byOs) {
              const mem = row.data?.idleMemory ?? null;
              const kind = mem?.measurement ?? "rss";
              const summary = mem?.summary ?? null;
              const val = summary?.rssMb?.p95;
              const tgt = summary?.rssMb?.targetMb;
              const cell = fmtMetric(val, tgt, 1);
              lines.push(`| ${row.label} | \`${kind}\` | ${cell} |`);
            }
            
            lines.push("");
            lines.push("_Artifacts: see the workflow run's **Artifacts** section (one per OS)._");
            
            const body = lines.join("\n");
            const issue_number = context.payload.pull_request.number;
            
            const comments = await github.paginate(github.rest.issues.listComments, {
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number,
              per_page: 100,
            });
            
            const existing = comments.find(
              (c) => c?.user?.login === "github-actions[bot]" && typeof c.body === "string" && c.body.includes(marker),
            );
            
            if (existing) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existing.id,
                body,
              });
              core.info(`Updated existing desktop perf matrix comment (id=${existing.id}).`);
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number,
                body,
              });
              core.info("Created new desktop perf matrix comment.");
            }

  merge:
    name: Desktop perf summary (all OS)
    needs: [guard, desktop-perf]
    if: always() && needs.guard.outputs.should_run == 'true'
    runs-on: ubuntu-24.04
    permissions:
      contents: read
      actions: read
    steps:
      - name: Setup Node
        uses: actions/setup-node@6044e13b5dc448c55e2357c09f80417699197238 # v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Download per-OS perf artifacts
        continue-on-error: true
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v4
        with:
          pattern: desktop-perf-*
          path: artifacts/desktop-perf

      - name: Merge metrics + write summary
        shell: bash
        env:
          PR_NUMBER: ${{ needs.guard.outputs.pr_number }}
          PR_HEAD_SHA: ${{ needs.guard.outputs.head_sha }}
          PR_LABEL: ${{ needs.guard.outputs.label }}
        run: |
          set -euo pipefail
          mkdir -p merged
          node - <<'NODE'
          const fs = require("node:fs");
          const path = require("node:path");
          
          function readJsonMaybe(p) {
            try {
              return JSON.parse(fs.readFileSync(p, "utf8"));
            } catch {
              return null;
            }
          }
          
          function fmt(n, digits = 1) {
            if (typeof n !== "number" || !Number.isFinite(n)) return "n/a";
            return n.toFixed(digits);
          }
          
          const artifactsRoot = path.resolve("artifacts/desktop-perf");
          const entries = fs.existsSync(artifactsRoot)
            ? fs.readdirSync(artifactsRoot, { withFileTypes: true }).filter((e) => e.isDirectory()).map((e) => e.name)
            : [];
          
          /** @type {Record<string, any>} */
          const byArtifact = {};
          for (const name of entries) {
            const p = path.join(artifactsRoot, name, "perf-artifacts", "desktop-perf-metrics.json");
            byArtifact[name] = readJsonMaybe(p);
          }
          
          const merged = {
            generatedAt: new Date().toISOString(),
            pr: {
              number: Number(process.env.PR_NUMBER ?? "") || null,
              label: process.env.PR_LABEL ?? null,
            },
            ci: {
              workflow: process.env.GITHUB_WORKFLOW ?? null,
              runId: process.env.GITHUB_RUN_ID ?? null,
              runNumber: process.env.GITHUB_RUN_NUMBER ?? null,
              attempt: process.env.GITHUB_RUN_ATTEMPT ?? null,
            },
            git: { sha: process.env.PR_HEAD_SHA ?? null, ref: process.env.GITHUB_REF ?? null },
            artifacts: byArtifact,
          };
          
          fs.writeFileSync(path.resolve("merged/desktop-perf-platform-matrix.json"), JSON.stringify(merged, null, 2), "utf8");
          
          const summaryPath = process.env.GITHUB_STEP_SUMMARY;
          if (!summaryPath) process.exit(0);
          
          const rows = [
            { label: "Linux", artifact: "desktop-perf-ubuntu-24.04" },
            { label: "Windows", artifact: "desktop-perf-windows-2022" },
            { label: "macOS", artifact: "desktop-perf-macos-14" },
          ].map((r) => ({ ...r, data: byArtifact[r.artifact] ?? null }));
          
          const lines = [];
          lines.push("## Desktop perf summary (all OS)");
          lines.push("");
          lines.push(`- PR: #${process.env.PR_NUMBER ?? "n/a"}`);
          lines.push(`- Commit: \`${process.env.PR_HEAD_SHA ?? "n/a"}\``);
          lines.push(`- Trigger label: \`${process.env.PR_LABEL ?? "n/a"}\``);
          lines.push(`- Run: https://github.com/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID}`);
          lines.push("");
          
          lines.push("### WebView runtime");
          lines.push("");
          lines.push("| OS | engine | version |");
          lines.push("|---|---|---|");
          for (const row of rows) {
            const w = row.data?.webview ?? null;
            lines.push(`| ${row.label} | \`${w?.engine ?? "n/a"}\` | \`${w?.version ?? "n/a"}\` |`);
          }
          lines.push("");
          
          lines.push("### Startup (p95, ms)");
          lines.push("");
          lines.push("| OS | cold windowVisible | cold tti | warm windowVisible | warm tti |");
          lines.push("|---|---:|---:|---:|---:|");
          for (const row of rows) {
            const cold = row.data?.startupCold?.summary ?? null;
            const warm = row.data?.startupWarm?.summary ?? null;
            lines.push(
              `| ${row.label} | ${fmt(cold?.windowVisible?.p95, 0)} | ${fmt(cold?.tti?.p95, 0)} | ${fmt(warm?.windowVisible?.p95, 0)} | ${fmt(warm?.tti?.p95, 0)} |`,
            );
          }
          lines.push("");
          
          lines.push("### Idle memory (p95, MB)");
          lines.push("");
          lines.push("| OS | kind | idle memory |");
          lines.push("|---|---|---:|");
          for (const row of rows) {
            const mem = row.data?.idleMemory ?? null;
            const kind = mem?.measurement ?? "rss";
            const p95 = mem?.summary?.rssMb?.p95;
            lines.push(`| ${row.label} | \`${kind}\` | ${fmt(p95, 1)} |`);
          }
          lines.push("");
          
          fs.appendFileSync(summaryPath, lines.join("\n") + "\n", "utf8");
          NODE

      - name: Upload merged desktop perf metrics
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v4
        with:
          name: desktop-perf-platform-matrix
          if-no-files-found: warn
          path: |
            merged/desktop-perf-platform-matrix.json
