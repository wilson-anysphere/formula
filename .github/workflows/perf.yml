name: Performance

on:
  push:
    branches: [main]
  pull_request:

env:
  # Keep in sync with release.yml/ci.yml so performance runs don't break when
  # wasm-pack publishes a new incompatible version.
  WASM_PACK_VERSION: 0.13.1

jobs:
  conflict-marker-guard:
    name: "Guard: no merge conflict markers"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Fail if merge conflict markers are present
        run: bash scripts/ci/check-merge-conflict-markers.sh

  benchmark:
    needs: conflict-marker-guard
    # Building + running the real desktop (Tauri) startup benchmark requires
    # WebKit2GTK 4.1 which is available on Ubuntu 24.04 runners.
    runs-on: ubuntu-24.04
    permissions:
      contents: write
      pull-requests: write
    steps:
      - uses: actions/checkout@v4

      - uses: pnpm/action-setup@v4
        with:
          # Pin pnpm patch version for deterministic builds (keep in sync with package.json).
          version: 9.0.0

      - uses: actions/setup-node@v4
        with:
          node-version: 22
          cache: pnpm
          cache-dependency-path: pnpm-lock.yaml

      - uses: dtolnay/rust-toolchain@1.92.0
      - uses: Swatinem/rust-cache@v2

      # Our dev scripts default to a repo-local CARGO_HOME to avoid cross-agent
      # contention on shared ~/.cargo. In GitHub Actions we prefer the default
      # CARGO_HOME so the shared cache action works as intended.
      - name: Use shared Cargo home for CI caching
        run: echo "CARGO_HOME=$HOME/.cargo" >> "$GITHUB_ENV"

      - name: Install JS dependencies
        run: pnpm install --frozen-lockfile

      - name: Detect desktop (Tauri) changes in PRs
        id: desktop_changes
        if: github.event_name == 'pull_request'
        uses: dorny/paths-filter@v3
        with:
          # Default GITHUB_TOKEN has read access to changed files on PRs.
          token: ${{ secrets.GITHUB_TOKEN }}
          filters: |
            tauri:
              - 'apps/desktop/src-tauri/**'
              - 'apps/desktop/src/tauri/**'

      - name: Decide whether to run real desktop startup benchmarks
        id: desktop_bench
        shell: bash
        run: |
          set -euo pipefail
          if [[ "${{ github.event_name }}" == "push" && "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "run=true" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          if [[ "${{ github.event_name }}" == "pull_request" && "${{ steps.desktop_changes.outputs.tauri }}" == "true" ]]; then
            echo "run=true" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          echo "run=false" >> "$GITHUB_OUTPUT"

      - name: Install Linux dependencies (Tauri/WebView + Xvfb)
        if: steps.desktop_bench.outputs.run == 'true'
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            xvfb \
            libgtk-3-dev \
            libwebkit2gtk-4.1-dev \
            libayatana-appindicator3-dev \
            librsvg2-dev \
            libssl-dev \
            patchelf

      - name: Install wasm32 target (required for desktop renderer build)
        if: steps.desktop_bench.outputs.run == 'true'
        run: rustup target add wasm32-unknown-unknown

      - name: Cache wasm-pack binary
        if: steps.desktop_bench.outputs.run == 'true'
        id: wasm-pack-cache
        uses: actions/cache@v4
        with:
          path: ~/.cargo/bin/wasm-pack
          key: wasm-pack-${{ runner.os }}-${{ runner.arch }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-${{ runner.os }}-${{ runner.arch }}-

      - name: Install wasm-pack (required for @formula/engine WASM build)
        if: steps.desktop_bench.outputs.run == 'true' && steps.wasm-pack-cache.outputs.cache-hit != 'true'
        # Pinned to match the tagged release workflow so perf runs don't break
        # when wasm-pack publishes a new incompatible version.
        run: cargo install wasm-pack --version ${{ env.WASM_PACK_VERSION }} --locked

      - name: Build desktop frontend assets (Vite â†’ tauri.conf.json build.frontendDist)
        if: steps.desktop_bench.outputs.run == 'true'
        run: pnpm -C apps/desktop build

      - name: Build desktop binary (Tauri, release)
        if: steps.desktop_bench.outputs.run == 'true'
        run: |
          bash scripts/cargo_agent.sh build \
            -p formula-desktop-tauri \
            --features desktop \
            --bin formula-desktop \
            --release \
            --locked

      - name: Run benchmark suite
        id: perf
        env:
          # Enable the real desktop startup benchmark (Tauri shell) only when
          # building it in this job (push-to-main, or relevant PRs).
          FORMULA_RUN_DESKTOP_STARTUP_BENCH: ${{ steps.desktop_bench.outputs.run == 'true' && '1' || '0' }}
          FORMULA_DESKTOP_STARTUP_RUNS: 7
          FORMULA_DESKTOP_STARTUP_TIMEOUT_MS: 20000
          # Ensure the benchmark runs headless via scripts/xvfb-run-safe.sh.
          # (desktopStartupBench.ts uses Xvfb only when DISPLAY is unset/empty.)
          DISPLAY: ""
        run: pnpm benchmark
        continue-on-error: true
      
      - name: Run TabCompletionEngine benchmark
        if: always()
        run: node packages/ai-completion/bench/tabCompletionEngine.bench.mjs --output benchmark-results.tab-completion.json --details benchmark-details.tab-completion.json

      - name: Merge TabCompletionEngine results into benchmark-results.json
        if: always()
        run: node scripts/merge-benchmark-results.mjs benchmark-results.json benchmark-results.tab-completion.json

      - name: Publish benchmark results
        if: always()
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: customSmallerIsBetter
          output-file-path: benchmark-results.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
          alert-threshold: '120%'
          comment-on-alert: true
          fail-on-alert: true

      - name: Fail on absolute target regression
        if: steps.perf.outcome == 'failure'
        run: exit 1
