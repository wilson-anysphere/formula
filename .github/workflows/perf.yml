name: Performance

on:
  push:
    branches: [main]
  pull_request:
    paths:
      - "apps/desktop/**"
      - "crates/**"
      - "packages/**"
      - "scripts/**"
      - "Cargo.toml"
      - "Cargo.lock"
      - "pnpm-lock.yaml"
      - "package.json"
      - "rust-toolchain.toml"
      - ".github/workflows/perf.yml"

env:
  # Keep Node pinned to the same major as CI/release workflows to reduce drift in
  # scripts and build tooling.
  NODE_VERSION: 22
  # Keep in sync with release.yml/ci.yml so performance runs don't break when
  # wasm-pack publishes a new incompatible version.
  WASM_PACK_VERSION: 0.13.1

jobs:
  conflict-marker-guard:
    name: "Guard: no merge conflict markers"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4
      - name: Fail if merge conflict markers are present
        run: bash scripts/ci/check-merge-conflict-markers.sh
      - name: "Guard: Rust toolchain pins match rust-toolchain.toml"
        run: bash scripts/ci/check-rust-toolchain-pins.sh

  benchmark:
    needs: conflict-marker-guard
    # Desktop startup benchmarks require WebKitGTK 4.1 (Ubuntu 24.04+) and a headless display via Xvfb.
    runs-on: ubuntu-24.04
    timeout-minutes: 45
    permissions:
      contents: write
      pull-requests: write
    env:
      # Desktop idle RSS budget in MB. Override via the repository variable.
      FORMULA_DESKTOP_IDLE_RSS_TARGET_MB: ${{ vars.FORMULA_DESKTOP_IDLE_RSS_TARGET_MB || '100' }}
    steps:
      - uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4

      - uses: pnpm/action-setup@41ff72655975bd51cab0327fa583b6e92b6d3061 # v4
        with:
          # Pin pnpm patch version for deterministic builds (keep in sync with package.json).
          version: 9.0.0

      - uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: pnpm
          cache-dependency-path: pnpm-lock.yaml

      - uses: dtolnay/rust-toolchain@9bc92bc5598b4f3bec5d910d352094982cb0c3b9 # 1.92.0
      - uses: Swatinem/rust-cache@779680da715d629ac1d338a641029a2f4372abb5 # v2

      # Our dev scripts default to a repo-local CARGO_HOME to avoid cross-agent
      # contention on shared ~/.cargo. In GitHub Actions we prefer the default
      # CARGO_HOME so the shared cache action works as intended.
      - name: Use shared Cargo home for CI caching
        run: echo "CARGO_HOME=$HOME/.cargo" >> "$GITHUB_ENV"

      - name: Install JS dependencies
        run: pnpm install --frozen-lockfile

      - name: Decide whether to run real desktop startup benchmarks
        id: desktop_bench
        shell: bash
        run: |
          set -euo pipefail

          # Always run on push-to-main (the performance gate).
          if [[ "${{ github.event_name }}" == "push" && "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "run=true" >> "$GITHUB_OUTPUT"
            echo "runs=10" >> "$GITHUB_OUTPUT"
            # Full app benchmark (requires built frontend assets).
            echo "kind=full" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          # Run on same-repo PRs. Skip fork PRs for security/toolchain stability.
          if [[ "${{ github.event_name }}" == "pull_request" && "${{ github.event.pull_request.head.repo.full_name }}" == "${{ github.repository }}" ]]; then
            echo "run=true" >> "$GITHUB_OUTPUT"
            echo "runs=5" >> "$GITHUB_OUTPUT"
            # Full end-to-end startup benchmark (requires built frontend assets).
            echo "kind=full" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          echo "run=false" >> "$GITHUB_OUTPUT"
          echo "runs=5" >> "$GITHUB_OUTPUT"
          echo "kind=shell" >> "$GITHUB_OUTPUT"

      - name: Install Linux dependencies (Tauri/WebView + Xvfb)
        if: steps.desktop_bench.outputs.run == 'true'
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libgtk-3-dev \
            libwebkit2gtk-4.1-dev \
            libayatana-appindicator3-dev \
            librsvg2-dev \
            libssl-dev \
            patchelf \
            xvfb

      - name: Install wasm32 target (required for desktop renderer build)
        if: steps.desktop_bench.outputs.run == 'true' && steps.desktop_bench.outputs.kind == 'full'
        run: rustup target add wasm32-unknown-unknown

      - name: Cache wasm-pack binary
        if: steps.desktop_bench.outputs.run == 'true' && steps.desktop_bench.outputs.kind == 'full'
        id: wasm-pack-cache
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: ~/.cargo/bin/wasm-pack
          key: wasm-pack-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-

      - name: Cache wasm-pack tool downloads (Linux)
        if: steps.desktop_bench.outputs.run == 'true' && steps.desktop_bench.outputs.kind == 'full'
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          # wasm-pack downloads wasm-bindgen + binaryen (wasm-opt) into this cache dir.
          path: ~/.cache/.wasm-pack
          key: wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-v${{ env.WASM_PACK_VERSION }}
          restore-keys: |
            wasm-pack-tools-${{ runner.os }}-${{ runner.arch }}-

      - name: Install wasm-pack (required for @formula/engine WASM build)
        if: steps.desktop_bench.outputs.run == 'true' && steps.desktop_bench.outputs.kind == 'full' && steps.wasm-pack-cache.outputs.cache-hit != 'true'
        # Pinned to match the tagged release workflow so perf runs don't break
        # when wasm-pack publishes a new incompatible version.
        run: cargo install wasm-pack --version ${{ env.WASM_PACK_VERSION }} --locked

      - name: Verify wasm-pack version
        if: steps.desktop_bench.outputs.run == 'true' && steps.desktop_bench.outputs.kind == 'full'
        shell: bash
        run: |
          set -euo pipefail
          expected="${WASM_PACK_VERSION}"
          actual="$(wasm-pack --version | tr -d '\r' | awk '{print $2}')"
          if [[ "${actual}" != "${expected}" ]]; then
            echo "Expected wasm-pack ${expected}, but found ${actual}." >&2
            exit 1
          fi

      - name: Detect Pyodide version (for caching)
        if: steps.desktop_bench.outputs.run == 'true' && steps.desktop_bench.outputs.kind == 'full'
        id: pyodide
        run: |
          set -euo pipefail
          version="$(node -p 'const fs=require("fs");const src=fs.readFileSync("apps/desktop/scripts/ensure-pyodide-assets.mjs","utf8");const m=src.match(/const\s+PYODIDE_VERSION\s*=\s*[\"\\x27]([^\"\\x27]+)[\"\\x27]/);if(!m){throw new Error("PYODIDE_VERSION not found in ensure-pyodide-assets.mjs");}m[1];')"
          echo "version=$version" >> "$GITHUB_OUTPUT"

      - name: Restore Pyodide asset cache
        if: steps.desktop_bench.outputs.run == 'true' && steps.desktop_bench.outputs.kind == 'full'
        id: pyodide-cache
        uses: actions/cache/restore@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: apps/desktop/public/pyodide/v${{ steps.pyodide.outputs.version }}/full/
          key: pyodide-${{ runner.os }}-${{ steps.pyodide.outputs.version }}-${{ hashFiles('apps/desktop/scripts/ensure-pyodide-assets.mjs') }}

      - name: Ensure Pyodide assets are present (populate cache on miss)
        if: steps.desktop_bench.outputs.run == 'true' && steps.desktop_bench.outputs.kind == 'full'
        run: node apps/desktop/scripts/ensure-pyodide-assets.mjs

      - name: Save Pyodide asset cache
        if: steps.desktop_bench.outputs.run == 'true' && steps.desktop_bench.outputs.kind == 'full' && steps.pyodide-cache.outputs.cache-hit != 'true'
        uses: actions/cache/save@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: apps/desktop/public/pyodide/v${{ steps.pyodide.outputs.version }}/full/
          key: pyodide-${{ runner.os }}-${{ steps.pyodide.outputs.version }}-${{ hashFiles('apps/desktop/scripts/ensure-pyodide-assets.mjs') }}

      - name: Build desktop frontend assets (Vite â†’ tauri.conf.json build.frontendDist)
        if: steps.desktop_bench.outputs.run == 'true' && steps.desktop_bench.outputs.kind == 'full'
        run: pnpm build:desktop

      - name: Desktop dist asset report
        if: steps.desktop_bench.outputs.run == 'true' && steps.desktop_bench.outputs.kind == 'full'
        run: node scripts/desktop_dist_asset_report.mjs --json-out desktop-dist-assets-report.json
        env:
          # Optional: set as GitHub Actions variables to enable gating.
          FORMULA_DESKTOP_DIST_TOTAL_BUDGET_MB: ${{ vars.FORMULA_DESKTOP_DIST_TOTAL_BUDGET_MB }}
          FORMULA_DESKTOP_DIST_SINGLE_FILE_BUDGET_MB: ${{ vars.FORMULA_DESKTOP_DIST_SINGLE_FILE_BUDGET_MB }}

      - name: Upload desktop dist asset report (JSON)
        if: always() && steps.desktop_bench.outputs.run == 'true' && steps.desktop_bench.outputs.kind == 'full'
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: desktop-dist-assets-report
          path: desktop-dist-assets-report.json
          if-no-files-found: ignore

      - name: Build desktop binary (release, desktop feature)
        id: build_desktop_binary
        if: steps.desktop_bench.outputs.run == 'true'
        run: |
          bash scripts/cargo_agent.sh build \
            -p formula-desktop-tauri \
            --features desktop \
            --bin formula-desktop \
            --release \
            --locked

      - name: Cache cargo-bloat binary
        if: steps.desktop_bench.outputs.run == 'true' && steps.desktop_bench.outputs.kind == 'full'
        id: cargo-bloat-cache
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4
        with:
          path: ~/.cargo/bin/cargo-bloat
          key: cargo-bloat-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-locked
          restore-keys: |
            cargo-bloat-${{ runner.os }}-${{ runner.arch }}-${{ hashFiles('rust-toolchain.toml') }}-

      - name: Install cargo-bloat
        if: steps.desktop_bench.outputs.run == 'true' && steps.desktop_bench.outputs.kind == 'full' && steps.cargo-bloat-cache.outputs.cache-hit != 'true'
        continue-on-error: true
        run: cargo install cargo-bloat --locked

      - name: Run benchmark suite
        id: perf
        env:
          # Enable the real desktop startup benchmark (Tauri shell) only when we've built it.
          FORMULA_RUN_DESKTOP_STARTUP_BENCH: ${{ steps.desktop_bench.outputs.run == 'true' && steps.build_desktop_binary.outcome == 'success' && '1' || '0' }}
          # Keep the metric names stable for CI gating by explicitly using cold-start mode
          # (which also produces the legacy `desktop.startup.*` aliases).
          FORMULA_DESKTOP_STARTUP_MODE: cold
          # Enable the optional desktop idle-memory benchmark only when the desktop
          # binary + assets were built in this job.
          FORMULA_RUN_DESKTOP_MEMORY_BENCH: ${{ steps.desktop_bench.outputs.run == 'true' && steps.desktop_bench.outputs.kind == 'full' && steps.build_desktop_binary.outcome == 'success' && '1' || '0' }}
          # Desktop startup benchmark kind: `shell` is lightweight (no apps/desktop/dist required),
          # while `full` measures end-to-end app bootstrap.
          FORMULA_DESKTOP_STARTUP_BENCH_KIND: ${{ steps.desktop_bench.outputs.kind }}
          # Keep PR runtime reasonable; use more iterations on main for stable signals.
          FORMULA_DESKTOP_STARTUP_RUNS: ${{ steps.desktop_bench.outputs.runs }}
          FORMULA_DESKTOP_MEMORY_RUNS: ${{ steps.desktop_bench.outputs.runs }}
          # Extra slack: WebKit startup can occasionally take longer on noisy CI runners.
          FORMULA_DESKTOP_MEMORY_TIMEOUT_MS: 30000
          # Give the app a short window to settle after TTI before sampling RSS.
          FORMULA_DESKTOP_MEMORY_SETTLE_MS: 3000
          FORMULA_DESKTOP_STARTUP_TIMEOUT_MS: 20000
          # Ensure the benchmark runs headless via scripts/xvfb-run-safe.sh.
          # (desktopStartupBench.ts uses Xvfb only when DISPLAY is unset/empty.)
          DISPLAY: ""
        run: pnpm benchmark
        continue-on-error: true

      - name: Verify desktop startup metrics are present
        # If we decided to run the real desktop (Tauri) benchmarks, enforce that the expected
        # metrics were actually produced (so we don't silently skip the perf gate due to a config
        # regression).
        if: always() && steps.desktop_bench.outputs.run == 'true' && steps.build_desktop_binary.outcome == 'success'
        env:
          DESKTOP_STARTUP_BENCH_KIND: ${{ steps.desktop_bench.outputs.kind }}
        run: |
          node - <<'NODE'
          const fs = require('node:fs');
          const path = 'benchmark-results.json';
          if (!fs.existsSync(path)) {
            console.error(`[perf] ${path} not found; desktop startup metrics could not be verified.`);
            process.exit(1);
          }
          const results = JSON.parse(fs.readFileSync(path, 'utf8'));
          if (!Array.isArray(results)) {
            console.error(`[perf] ${path} is not a JSON array; got ${typeof results}`);
            process.exit(1);
          }
          const names = new Set(results.map((r) => r && r.name).filter((n) => typeof n === 'string'));
          const kind = String(process.env.DESKTOP_STARTUP_BENCH_KIND || '').trim().toLowerCase();
          const required =
            kind === 'shell'
              ? ['desktop.shell_startup.window_visible_ms.p95', 'desktop.shell_startup.tti_ms.p95']
              : ['desktop.startup.window_visible_ms.p95', 'desktop.startup.tti_ms.p95'];
          const missing = required.filter((n) => !names.has(n));
          if (missing.length) {
            console.error(`[perf] Missing desktop startup benchmark metrics: ${missing.join(', ')}`);
            console.error(
              `[perf] Startup bench kind=${JSON.stringify(kind || 'full')} (expected metrics: ${required.join(', ')})`,
            );
            console.error('[perf] Ensure FORMULA_RUN_DESKTOP_STARTUP_BENCH=1 and the desktop binary emits [startup] metrics.');
            process.exit(1);
          }
          console.log(`[perf] Desktop startup metrics present: ${required.join(', ')}`);
          NODE
      
      - name: Run TabCompletionEngine benchmark
        if: always()
        run: node packages/ai-completion/bench/tabCompletionEngine.bench.mjs --output benchmark-results.tab-completion.json --details benchmark-details.tab-completion.json

      - name: Merge TabCompletionEngine results into benchmark-results.json
        if: always()
        run: node scripts/merge-benchmark-results.mjs benchmark-results.json benchmark-results.tab-completion.json

      - name: Publish benchmark results
        # Fork PRs get a read-only token; skip publishing/commenting there.
        if: |
          always() && (
            github.event_name == 'push' ||
            (github.event_name == 'pull_request' && github.event.pull_request.head.repo.full_name == github.repository)
          )
        uses: benchmark-action/github-action-benchmark@4bdcce38c94cec68da58d012ac24b7b1155efe8b # v1
        with:
          tool: customSmallerIsBetter
          output-file-path: benchmark-results.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
          alert-threshold: '120%'
          comment-on-alert: true
          fail-on-alert: true

      - name: Enforce desktop idle RSS target (MB)
        if: always() && steps.desktop_bench.outputs.run == 'true' && steps.desktop_bench.outputs.kind == 'full' && steps.build_desktop_binary.outcome == 'success'
        run: |
          node - <<'NODE'
          const fs = require('node:fs');
          const targetRaw =
            process.env.FORMULA_DESKTOP_IDLE_RSS_TARGET_MB ?? process.env.FORMULA_DESKTOP_MEMORY_TARGET_MB;
          const target = Number(targetRaw);
          if (!Number.isFinite(target) || target <= 0) {
            console.log(
              `[perf] FORMULA_DESKTOP_IDLE_RSS_TARGET_MB / FORMULA_DESKTOP_MEMORY_TARGET_MB is not set to a positive number (${JSON.stringify(targetRaw)}); skipping idle RSS gate.`,
            );
            process.exit(0);
          }
          const results = JSON.parse(fs.readFileSync('benchmark-results.json', 'utf8'));
          const metricName = 'desktop.memory.idle_rss_mb.p95';
          const entry = Array.isArray(results) ? results.find((r) => r && r.name === metricName) : null;
          if (!entry) {
            console.error(`[perf] Missing ${metricName} in benchmark-results.json (did the desktop memory benchmark run?).`);
            process.exit(1);
          }
          const value = Number(entry.value);
          if (!Number.isFinite(value)) {
            console.error(`[perf] Invalid ${metricName} value: ${JSON.stringify(entry.value)}`);
            process.exit(1);
          }
          console.log(`[perf] ${metricName}=${value}MB (target=${target}MB)`);
          const summaryPath = process.env.GITHUB_STEP_SUMMARY;
          if (summaryPath) {
            try {
              fs.appendFileSync(
                summaryPath,
                `\n### Desktop idle RSS\n\n- ${metricName}: ${value} MB\n- target: ${target} MB\n`,
              );
            } catch {
              // ignore (summary is best-effort)
            }
          }
          if (value > target) {
            console.error(`[perf] Desktop idle RSS regression: ${value}MB exceeds target ${target}MB`);
            process.exit(1);
          }
          NODE
          
      - name: Report desktop binary size breakdown (cargo-bloat)
        if: always() && steps.desktop_bench.outputs.run == 'true' && steps.desktop_bench.outputs.kind == 'full' && steps.build_desktop_binary.outcome == 'success'
        # Informational by default. To turn this into a gate, set the repo variable
        # `FORMULA_ENFORCE_DESKTOP_BINARY_SIZE=1` (and a `FORMULA_DESKTOP_BINARY_SIZE_LIMIT_MB` budget).
        continue-on-error: ${{ !(vars.FORMULA_ENFORCE_DESKTOP_BINARY_SIZE == '1' || vars.FORMULA_ENFORCE_DESKTOP_BINARY_SIZE == 'true' || vars.FORMULA_ENFORCE_DESKTOP_BINARY_SIZE == 'yes' || vars.FORMULA_ENFORCE_DESKTOP_BINARY_SIZE == 'on') }}
        env:
          FORMULA_ENFORCE_DESKTOP_BINARY_SIZE: ${{ vars.FORMULA_ENFORCE_DESKTOP_BINARY_SIZE }}
          FORMULA_DESKTOP_BINARY_SIZE_LIMIT_MB: ${{ vars.FORMULA_DESKTOP_BINARY_SIZE_LIMIT_MB }}
        run: python3 scripts/desktop_binary_size_report.py --no-build

      - name: Fail on absolute target regression
        if: always() && steps.perf.outcome == 'failure'
        run: exit 1
